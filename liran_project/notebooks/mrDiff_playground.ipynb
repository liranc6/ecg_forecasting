{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import yaml\n",
    "from box import Box\n",
    "\n",
    "# Add the parent directory to the sys.path\n",
    "ProjectPath = os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "sys.path.append(ProjectPath)\n",
    "\n",
    "# Add the directory containing the exp module to the sys.path\n",
    "exp_module_path = os.path.join(ProjectPath, 'mrDiff')\n",
    "sys.path.append(exp_module_path)\n",
    "\n",
    "from mrDiff.exp.exp_main import Exp_Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "{'config_filename': '/home/liranc6/ecg_forecasting/mrDiff/configs/config.yml', 'config': Box({'general': {'random_seed': 2023, 'evaluate': False, 'tag': None, 'dataset': 'ETTm1', 'features': 'S', 'training_mode': 'ONE', 'interval': 1000}, 'optimization': {'learning_rate': 0.001, 'batch_size': 2048, 'test_batch_size': 32, 'patience': 10, 'weight_decay': 1e-05, 'lradj': '3', 'pct_start': 0.3}, 'hardware': {'num_workers': 0, 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0'}, 'paths': {'checkpoints': './checkpoints/', 'train_data': '/home/liranc6/ecg_forecasting/mrDiff/datasets/SCINet_timeseries/ETT-data/ETT'}, 'data': {'freq': 'h', 'embed': 'timeF', 'cols': [], 'target': -1, 'inverse': False, 'individual': True, 'use_ar_init': False, 'use_residual': True, 'uncertainty': False, 'norm_method': 'z_score', 'normtype': 0}, 'training': {'iterations': {'itr': 1, 'pretrain_epochs': 2, 'train_epochs': 2, 'sample_times': 1}, 'identifiers': {'id_worst': -1, 'focus_variate': -1}, 'sequence': {'seq_len': 336, 'label_len': 336, 'pred_len': 96}, 'model': {'opt_loss_type': 'mse', 'model': 'DDPM', 'base_model': 'Linear', 'u_net_type': 'v0'}, 'analysis': {'vis_MTS_analysis': 0, 'use_window_normalization': True, 'use_future_mixup': True, 'use_X0_in_THiDi': False, 'channel_independence': False}, 'smoothing': {'smoothed_factors': [5, 25, 51]}, 'ode': {'ot_ode': True, 'beta_max': 1.0, 't0': '1e-4', 'T': 0.02, 'nfe': 20}, 'ablation_study': {'ablation_study_F_type': 'Linear', 'beta_schedule': 'cosine', 'beta_dist_alpha': -1, 'ablation_study_masking_type': 'none', 'ablation_study_masking_tau': 0.9}, 'diffusion': {'beta_start': 0.0001, 'beta_end': 0.02, 'diff_steps': 100, 'ddpm_inp_embed': 64, 'ddpm_layers_inp': 10, 'ddpm_dim_diff_steps': 256, 'ddpm_channels_conv': 128, 'ddpm_channels_fusion_I': 256, 'ddpm_layers_I': 5, 'ddpm_layers_II': 10, 'kernel_size': 25, 'dec_channel_nums': 256, 'cond_ddpm_num_layers': 5, 'cond_ddpm_channels_conv': 256}, 'sampler': {'type_sampler': 'dpm', 'parameterization': 'x_start', 'our_ddpm_clip': 100}, 'misc': {'affine': 0, 'subtract_last': 1, 'subtract_short_terms': 0}}})}\n",
      "{'num_workers': 0, 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0'}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self, config_filename, cmd_args=None):\n",
    "        assert config_filename.endswith('.yml')\n",
    "        self.config_filename = config_filename\n",
    "        self.config = self.read_config()\n",
    "        self.override_with_cmd_args(cmd_args)\n",
    "        \n",
    "    def read_config(self):\n",
    "        with open(self.config_filename, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        return Box(config)\n",
    "    \n",
    "    def override_with_cmd_args(self, cmd_args):\n",
    "        if cmd_args is not None:\n",
    "            for key, value in vars(cmd_args).items():\n",
    "                if value is not None:\n",
    "                    self.config[key] = value\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.config, name)\n",
    "\n",
    "config_filename = '/home/liranc6/ecg_forecasting/mrDiff/configs/config.yml'\n",
    "args = Args(config_filename)\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(vars(args))\n",
    "\n",
    "# Accessing nested attribute\n",
    "try:\n",
    "    print(args.hardware)\n",
    "    print(args.hardware.gpu)\n",
    "except AttributeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "{'config_filename': '/home/liranc6/ecg_forecasting/mrDiff/configs/config.yml', 'config': Box({'general': {'random_seed': 2023, 'evaluate': False, 'tag': None, 'dataset': 'ETTm1', 'features': 'S', 'training_mode': 'ONE', 'interval': 1000}, 'optimization': {'learning_rate': 0.001, 'batch_size': 2048, 'test_batch_size': 32, 'patience': 10, 'weight_decay': 1e-05, 'lradj': '3', 'pct_start': 0.3}, 'hardware': {'num_workers': 0, 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0'}, 'paths': {'checkpoints': './checkpoints/', 'train_data': '/home/liranc6/ecg_forecasting/mrDiff/datasets/SCINet_timeseries/ETT-data/ETT'}, 'data': {'freq': 'h', 'embed': 'timeF', 'cols': [], 'target': -1, 'inverse': False, 'individual': True, 'use_ar_init': False, 'use_residual': True, 'uncertainty': False, 'norm_method': 'z_score', 'normtype': 0}, 'training': {'iterations': {'itr': 1, 'pretrain_epochs': 2, 'train_epochs': 2, 'sample_times': 1}, 'identifiers': {'id_worst': -1, 'focus_variate': -1}, 'sequence': {'seq_len': 336, 'label_len': 336, 'pred_len': 96}, 'model': {'opt_loss_type': 'mse', 'model': 'DDPM', 'base_model': 'Linear', 'u_net_type': 'v0'}, 'analysis': {'vis_MTS_analysis': 0, 'use_window_normalization': True, 'use_future_mixup': True, 'use_X0_in_THiDi': False, 'channel_independence': False}, 'smoothing': {'smoothed_factors': [5, 25, 51]}, 'ode': {'ot_ode': True, 'beta_max': 1.0, 't0': '1e-4', 'T': 0.02, 'nfe': 20}, 'ablation_study': {'ablation_study_F_type': 'Linear', 'beta_schedule': 'cosine', 'beta_dist_alpha': -1, 'ablation_study_masking_type': 'none', 'ablation_study_masking_tau': 0.9}, 'diffusion': {'beta_start': 0.0001, 'beta_end': 0.02, 'diff_steps': 100, 'ddpm_inp_embed': 64, 'ddpm_layers_inp': 10, 'ddpm_dim_diff_steps': 256, 'ddpm_channels_conv': 128, 'ddpm_channels_fusion_I': 256, 'ddpm_layers_I': 5, 'ddpm_layers_II': 10, 'kernel_size': 25, 'dec_channel_nums': 256, 'cond_ddpm_num_layers': 5, 'cond_ddpm_channels_conv': 256}, 'sampler': {'type_sampler': 'dpm', 'parameterization': 'x_start', 'our_ddpm_clip': 100}, 'misc': {'affine': 0, 'subtract_last': 1, 'subtract_short_terms': 0}}})}\n"
     ]
    }
   ],
   "source": [
    "print('Args in experiment:')\n",
    "print(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set use_gpu based on availability\n",
    "args.config['use_gpu'] = torch.cuda.is_available()\n",
    "\n",
    "# Handle multi-GPU settings\n",
    "if args.config['use_gpu'] and args.config['hardware']['use_multi_gpu']:\n",
    "    args.config['hardware']['devices'] = args.config['hardware']['devices'].replace(' ', '')\n",
    "    device_ids = args.config['hardware']['devices'].split(',')\n",
    "    args.config['hardware']['device_ids'] = [int(id_) for id_ in device_ids]\n",
    "    args.config['hardware']['gpu'] = args.config['hardware']['device_ids'][0]\n",
    "    args.config['optimization']['patience'] = 30\n",
    "else:\n",
    "    args.config['hardware']['device_ids'] = [0]  # Default to single GPU or CPU\n",
    "\n",
    "# Random seed initialization\n",
    "if 'random_seed' in args.config['general']:\n",
    "    fix_seed = args.config['general']['random_seed']\n",
    "    random.seed(fix_seed)\n",
    "    torch.manual_seed(fix_seed)\n",
    "    np.random.seed(fix_seed)\n",
    "\n",
    "# Load the dataset\n",
    "if args.config['general']['dataset'] == 'ETTm1':\n",
    "    args.config['paths']['datasets_dir'] = '/home/liranc6/ecg_forecasting/mrDiff/datasets/SCINet_timeseries/ETT-data/ETT'\n",
    "    args.config['data']['data'] = 'ETTm1'\n",
    "    args.config['paths']['root_path'] = args.config['paths']['datasets_dir']\n",
    "    args.config['paths']['data_path'] = 'ETTm1.csv'\n",
    "    args.config['data']['num_vars'] = 7\n",
    "\n",
    "if args.config['general']['features'] == \"S\":\n",
    "    args.config['data']['num_vars'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>start training : DDPM_ETTm1_ftS_sl336_ll336_pl96_lr0.001_bs2048_invFalse_itr0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34129\n",
      "val 11425\n",
      "test 11425\n",
      "Epoch: 1 cost time: 8.26150631904602\n",
      "Epoch: 1, Steps: 16 | Train Loss: 0.9056404 Vali Loss: 0.0762225\n",
      "Validation loss decreased (inf --> 0.076222).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "Epoch: 2 cost time: 7.661164045333862\n",
      "Epoch: 2, Steps: 16 | Train Loss: 0.6420200 Vali Loss: nan\n",
      "Validation loss decreased (0.076222 --> nan).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      ">>>>>>>testing : DDPM_ETTm1_ftS_sl336_ll336_pl96_lr0.001_bs2048_invFalse_itr0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 11425\n",
      "loading model\n",
      "Elapsed time: 30.75 ms\n",
      "Elapsed time: 29.46 ms\n",
      "Elapsed time: 31.14 ms\n",
      "Elapsed time: 31.63 ms\n",
      "Elapsed time: 31.44 ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m exp\u001b[38;5;241m.\u001b[39mtrain(setting)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>testing : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msetting\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m mae, mse, rmse, mape, mspe, rse, corr, nrmse \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m mae_\u001b[38;5;241m.\u001b[39mappend(mae)\n\u001b[1;32m     49\u001b[0m mse_\u001b[38;5;241m.\u001b[39mappend(mse)\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/exp/exp_main.py:290\u001b[0m, in \u001b[0;36mExp_Main.test\u001b[0;34m(self, setting, test)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# encoder - decoder\u001b[39;00m\n\u001b[1;32m    288\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 290\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x_mark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y_mark\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    293\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(batch_x)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/models_diffusion/DDPM.py:446\u001b[0m, in \u001b[0;36mModel.test_forward\u001b[0;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m         S \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m--> 446\u001b[0m     samples_ddim, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamplers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mconditioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcB\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m                                \u001b[49m\u001b[43munconditional_guidance_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m                                \u001b[49m\u001b[43munconditional_conditioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m                                \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mx_T\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     X1 \u001b[38;5;241m=\u001b[39m samples_ddim\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/models_diffusion/samplers/dpm_sampler.py:81\u001b[0m, in \u001b[0;36mDPMSolverSampler.sample\u001b[0;34m(self, S, batch_size, shape, conditioning, callback, normals_sequence, img_callback, quantize_x0, eta, mask, x0, temperature, noise_dropout, score_corrector, corrector_kwargs, verbose, x_T, log_every_t, unconditional_guidance_scale, unconditional_conditioning, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m model_fn \u001b[38;5;241m=\u001b[39m model_wrapper(\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x, t, c: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(x, t, c),\n\u001b[1;32m     72\u001b[0m     ns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     guidance_scale\u001b[38;5;241m=\u001b[39munconditional_guidance_scale,\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     80\u001b[0m dpm_solver \u001b[38;5;241m=\u001b[39m DPM_Solver(model_fn, ns, predict_x0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, thresholding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 81\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mdpm_solver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime_uniform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmultistep\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower_order_final\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mto(device), \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/models_diffusion/samplers/dpm_solver.py:1105\u001b[0m, in \u001b[0;36mDPM_Solver.sample\u001b[0;34m(self, x, steps, t_start, t_end, order, skip_type, method, lower_order_final, denoise_to_zero, solver_type, atol, rtol)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[38;5;66;03m# We do not need to evaluate the final model value.\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m<\u001b[39m steps:\n\u001b[0;32m-> 1105\u001b[0m                 model_prev_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvec_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msinglestep\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msinglestep_fixed\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msinglestep\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/models_diffusion/samplers/dpm_solver.py:406\u001b[0m, in \u001b[0;36mDPM_Solver.model_fn\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03mConvert the model to the noise prediction model or the data prediction model. \u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_x0:\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_prediction_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_prediction_fn(x, t)\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/models_diffusion/samplers/dpm_solver.py:390\u001b[0m, in \u001b[0;36mDPM_Solver.data_prediction_fn\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_prediction_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[1;32m    387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    Return the data prediction model (with thresholding).\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnoise_prediction_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m     dims \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdim()\n\u001b[1;32m    392\u001b[0m     alpha_t, sigma_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_schedule\u001b[38;5;241m.\u001b[39mmarginal_alpha(t), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_schedule\u001b[38;5;241m.\u001b[39mmarginal_std(t)\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/models_diffusion/samplers/dpm_solver.py:384\u001b[0m, in \u001b[0;36mDPM_Solver.noise_prediction_fn\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnoise_prediction_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[1;32m    381\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m    Return the noise prediction model.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/models_diffusion/samplers/dpm_solver.py:338\u001b[0m, in \u001b[0;36mmodel_wrapper.<locals>.model_fn\u001b[0;34m(x, t_continuous)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m guidance_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier-free\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m guidance_scale \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m unconditional_condition \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnoise_pred_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_continuous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m         x_in \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/models_diffusion/samplers/dpm_solver.py:296\u001b[0m, in \u001b[0;36mmodel_wrapper.<locals>.noise_pred_fn\u001b[0;34m(x, t_continuous, cond)\u001b[0m\n\u001b[1;32m    294\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(x, t_input, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 296\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/models_diffusion/samplers/dpm_sampler.py:71\u001b[0m, in \u001b[0;36mDPMSolverSampler.sample.<locals>.<lambda>\u001b[0;34m(x, t, c)\u001b[0m\n\u001b[1;32m     66\u001b[0m     img \u001b[38;5;241m=\u001b[39m x_T\n\u001b[1;32m     68\u001b[0m ns \u001b[38;5;241m=\u001b[39m NoiseScheduleVP(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscrete\u001b[39m\u001b[38;5;124m'\u001b[39m, alphas_cumprod\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas_cumprod)\n\u001b[1;32m     70\u001b[0m model_fn \u001b[38;5;241m=\u001b[39m model_wrapper(\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x, t, c: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     72\u001b[0m     ns,\n\u001b[1;32m     73\u001b[0m     model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_start\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     74\u001b[0m     guidance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier-free\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     75\u001b[0m     condition\u001b[38;5;241m=\u001b[39mconditioning,\n\u001b[1;32m     76\u001b[0m     unconditional_condition\u001b[38;5;241m=\u001b[39munconditional_conditioning,\n\u001b[1;32m     77\u001b[0m     guidance_scale\u001b[38;5;241m=\u001b[39munconditional_guidance_scale,\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     80\u001b[0m dpm_solver \u001b[38;5;241m=\u001b[39m DPM_Solver(model_fn, ns, predict_x0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, thresholding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     81\u001b[0m x \u001b[38;5;241m=\u001b[39m dpm_solver\u001b[38;5;241m.\u001b[39msample(img, steps\u001b[38;5;241m=\u001b[39mS, skip_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_uniform\u001b[39m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultistep\u001b[39m\u001b[38;5;124m\"\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, lower_order_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/models_diffusion/DDPM_CNNNet.py:372\u001b[0m, in \u001b[0;36mMy_DiffusionUnet_v0.forward\u001b[0;34m(self, xt, timesteps, cond, ar_init, future_gt, mask)\u001b[0m\n\u001b[1;32m    369\u001b[0m         out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([out, pred_out, prev_scale_out], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39muse_residual:\n\u001b[0;32m--> 372\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m pred_out\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    374\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_conv(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ecg_forecasting/mrDiff/models_diffusion/DDPM_CNNNet.py:174\u001b[0m, in \u001b[0;36mInputConvNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    172\u001b[0m out \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet:\n\u001b[0;32m--> 174\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/nn/functional.py:2507\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2495\u001b[0m         batch_norm,\n\u001b[1;32m   2496\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2504\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2505\u001b[0m     )\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m-> 2507\u001b[0m     _verify_batch_size(\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2510\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2511\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Initialize metrics lists\n",
    "mae_, mse_, rmse_, mape_, mspe_, rse_, corr_, nrmse_ = [], [], [], [], [], [], [], []\n",
    "\n",
    "# Ensure the necessary configurations are available\n",
    "iterations = args.config.get('training', {}).get('iterations', {}).get('itr', 1)\n",
    "random_seed = args.config.get('general', {}).get('random_seed', 2023)\n",
    "dataset = args.config.get('general', {}).get('dataset', 'default_dataset')\n",
    "model = args.config.get('training', {}).get('model', {}).get('model', 'default_model')\n",
    "features = args.config.get('general', {}).get('features', 'S')\n",
    "seq_len = args.config.get('training', {}).get('sequence', {}).get('seq_len', 336)\n",
    "label_len = args.config.get('training', {}).get('sequence', {}).get('label_len', 336)\n",
    "pred_len = args.config.get('training', {}).get('sequence', {}).get('pred_len', 96)\n",
    "learning_rate = args.config.get('optimization', {}).get('learning_rate', 0.001)\n",
    "batch_size = args.config.get('optimization', {}).get('batch_size', 64)\n",
    "inverse = args.config.get('data', {}).get('inverse', False)\n",
    "tag = args.config.get('general', {}).get('tag', None)\n",
    "\n",
    "# sourcery skip: assign-if-exp\n",
    "for ii in range(iterations):\n",
    "    # setting record of experiments\n",
    "\n",
    "    # random seed\n",
    "    fix_seed = ii if iterations > 1 else random_seed\n",
    "\n",
    "    random.seed(fix_seed)\n",
    "    torch.manual_seed(fix_seed)\n",
    "    np.random.seed(fix_seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # Can change it to False --> default: False\n",
    "    torch.backends.cudnn.enabled = True\n",
    "\n",
    "    setting = f\"{model}_{dataset}_ft{features}_sl{seq_len}_ll{label_len}_pl{pred_len}_lr{learning_rate}_bs{batch_size}_inv{inverse}_itr{ii}\"\n",
    "    if tag is not None:\n",
    "        setting += f\"_{tag}\"\n",
    "\n",
    "    exp = Exp_Main(args)\n",
    "\n",
    "    print(f'>>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    exp.train(setting)\n",
    "\n",
    "    print(f'>>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    mae, mse, rmse, mape, mspe, rse, corr, nrmse = exp.test(setting, test=1)\n",
    "\n",
    "    mae_.append(mae)\n",
    "    mse_.append(mse)\n",
    "    rmse_.append(rmse)\n",
    "    mape_.append(mape)\n",
    "    mspe_.append(mspe)\n",
    "    rse_.append(rse)\n",
    "    corr_.append(corr)\n",
    "    nrmse_.append(nrmse)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print('Final mean normed: ')\n",
    "print('> mae:{:.4f}, std:{:.4f}'.format(np.mean(mae_), np.std(mae_)))\n",
    "print('> mse:{:.4f}, std:{:.4f}'.format(np.mean(mse_), np.std(mse_)))\n",
    "print('> rmse:{:.4f}, std:{:.4f}'.format(np.mean(rmse_), np.std(rmse_)))\n",
    "print('> mape:{:.4f}, std:{:.4f}'.format(np.mean(mape_), np.std(mape_)))\n",
    "print('> rse:{:.4f}, std:{:.4f}'.format(np.mean(rse_), np.std(rse_)))\n",
    "print('> corr:{:.4f}, std:{:.4f}'.format(np.mean(corr_), np.std(corr_)))\n",
    "print('> nrmse:{:.4f}, std:{:.4f}'.format(np.mean(nrmse_), np.std(nrmse_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
