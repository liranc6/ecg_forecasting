{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import yaml\n",
    "from box import Box\n",
    "from pprint import pprint\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "CONFIG_FILENAME = '/home/liranc6/ecg_forecasting/liran_project/mrdiff/src/config_ecg.yml'\n",
    "\n",
    "assert CONFIG_FILENAME.endswith('.yml')\n",
    "\n",
    "with open(CONFIG_FILENAME, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Add the parent directory to the sys.path\n",
    "ProjectPath = config['project_path']\n",
    "sys.path.append(ProjectPath)\n",
    "\n",
    "from liran_project.mrdiff.src.parser import parse_args\n",
    "from liran_project.utils.dataset_loader import SingleLeadECGDatasetCrops_mrDiff as DataSet\n",
    "from liran_project.utils.util import ecg_signal_difference\n",
    "import liran_project.mrdiff.exp_main\n",
    "# from liran_project.mrdiff.exp_main import Exp_Main\n",
    "from liran_project.utils.common import *\n",
    "\n",
    "# Add the directory containing the exp module to the sys.path\n",
    "exp_module_path = os.path.join(ProjectPath, 'mrDiff')\n",
    "sys.path.append(exp_module_path)\n",
    "\n",
    "# from mrDiff.exp.exp_main import Exp_Main\n",
    "from mrDiff.data_process.etth_dataloader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Wind, Dataset_Caiso, Dataset_Production, Dataset_Caiso_M, Dataset_Production_M\n",
    "from mrDiff.data_process.financial_dataloader import DatasetH\n",
    "from mrDiff.data_process.forecast_dataloader import ForecastDataset\n",
    "from mrDiff.exp.exp_basic import Exp_Basic\n",
    "from mrDiff.models_diffusion import DDPM\n",
    "from mrDiff.utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
    "from mrDiff.utils.metrics import metric\n",
    "\n",
    "from liran_project.mrdiff.src.parser import Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': Box({'project_path': '/home/liranc6/ecg_forecasting', 'tqdm': 'terminal', 'resume': {'resume': True, 'resume_from': False, 'resume_optimizer': True, 'resume_epoch': 'None', 'loss_and_metrics': True, 'resume_scheduler': True, 'resume_configuration': True, 'specific_chpt_path': '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff/DDPM_icentia11k_ftS_sl10_ll105_pl30_lr0.001_bs8_invFalse_itr0/09_10_2024_1143/best_checkpoint.pth', 'was_resumed': False}, 'wandb': {'entity': 'liranc6', 'mode': 'disabled', 'project': 'mrdiff', 'resume': 'None', 'run_name': 'None', 'id': 'None', 'save_code': True, 'resume_from': 'None'}, 'general': {'random_seed': 42, 'evaluate': False, 'tag': None, 'dataset': 'icentia11k', 'features': 'S', 'training_mode': 'ONE', 'interval': 1000}, 'optimization': {'learning_rate': 0.001, 'batch_size': 8, 'test_batch_size': 8, 'patience': 10, 'weight_decay': 1e-05, 'lradj': '3', 'pct_start': 0.3}, 'hardware': {'print_gpu_memory_usage': False, 'num_workers': 0, 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0', 'device_ids': [0]}, 'paths': {'train_data': '/home/liranc6/data/with_R_beats/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes/train/p0_to_p32.h5', 'val_data': '/home/liranc6/data/with_R_beats/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes/val/p33_to_p39.h5', 'test_data': '/home/liranc6/data/with_R_beats/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes/test/p40_to_p46.h5', 'output_dir': '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff', 'checkpoints': '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff', 'model_path': 'None'}, 'data': {'fs': 250, 'freq': 'h', 'embed': 'timeF', 'cols': [], 'target': -1, 'inverse': False, 'individual': True, 'use_ar_init': False, 'use_residual': True, 'uncertainty': False, 'norm_method': 'None', 'normtype': 0, 'num_vars': 1}, 'training': {'logging': {'sample': False, 'log_interval': 5, 'save_interval': 1, 'save_best': True, 'save_dir': '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff'}, 'patients': {'start_patient': 0, 'end_patient': 1}, 'iterations': {'itr': 1, 'pretrain_epochs': 0, 'train_epochs': 1, 'sample_times': 1}, 'identifiers': {'id_worst': -1, 'focus_variate': -1}, 'sequence': {'context_len': 10, 'seq_len': 135, 'label_len': 105, 'pred_len': 30}, 'model_info': {'opt_loss_type': 'mse', 'model': 'DDPM', 'base_model': 'Linear', 'u_net_type': 'v0'}, 'analysis': {'vis_MTS_analysis': 0, 'use_window_normalization': True, 'use_future_mixup': True, 'use_X0_in_THiDi': False, 'channel_independence': False}, 'smoothing': {'smoothed_factors': [5, 25, 51]}, 'ode': {'ot_ode': True, 'beta_max': 1.0, 't0': '1e-4', 'T': 0.02, 'nfe': 20}, 'ablation_study': {'ablation_study_F_type': 'Linear', 'beta_schedule': 'cosine', 'beta_dist_alpha': -1, 'ablation_study_masking_type': 'none', 'ablation_study_masking_tau': 0.9}, 'diffusion': {'beta_start': 0.0001, 'beta_end': 0.02, 'diff_steps': 100, 'ddpm_inp_embed': 64, 'ddpm_layers_inp': 10, 'ddpm_dim_diff_steps': 256, 'ddpm_channels_conv': 128, 'ddpm_channels_fusion_I': 256, 'ddpm_layers_I': 5, 'ddpm_layers_II': 10, 'kernel_size': 25, 'dec_channel_nums': 256, 'cond_ddpm_num_layers': 5, 'cond_ddpm_channels_conv': 256}, 'sampler': {'type_sampler': 'dpm', 'parameterization': 'x_start', 'our_ddpm_clip': 100}, 'misc': {'affine': 0, 'subtract_last': 0, 'subtract_short_terms': 0}}, 'validation': {'patients': {'start_patient': 0, 'end_patient': 1}}, 'testing': {'patients': {'start_patient': 0, 'end_patient': 1}}, 'use_gpu': True}),\n",
      " 'config_filename': '/home/liranc6/ecg_forecasting/liran_project/mrdiff/src/config_ecg.yml'}\n"
     ]
    }
   ],
   "source": [
    "args = Args(CONFIG_FILENAME)\n",
    "\n",
    "# Now you can use args as needed\n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Box object to dictionary\n",
    "config_dict = args.configs.to_dict()\n",
    "\n",
    "# Access the configuration values using dictionary syntax\n",
    "random_seed = config_dict['general']['random_seed']\n",
    "tag = config_dict['general']['tag']\n",
    "dataset = config_dict['general']['dataset']\n",
    "features = config_dict['general']['features']\n",
    "\n",
    "learning_rate = config_dict['optimization']['learning_rate']\n",
    "batch_size = config_dict['optimization']['batch_size']\n",
    "\n",
    "context_len = config_dict['training']['sequence']['context_len']\n",
    "label_len = config_dict['training']['sequence']['label_len']\n",
    "model = config_dict['training']['model_info']['model']\n",
    "pred_len = config_dict['training']['sequence']['pred_len']\n",
    "iterations = config_dict['training']['iterations']['itr']\n",
    "\n",
    "inverse = config_dict['data']['inverse']\n",
    "    \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True  # Can change it to False --> default: False\n",
    "torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': 'liranc6',\n",
       " 'mode': 'disabled',\n",
       " 'project': 'mrdiff',\n",
       " 'save_code': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb\n",
    "wandb_init_config ={\n",
    "        \"entity\": args.wandb.entity,\n",
    "        \"mode\": args.wandb.mode,\n",
    "        \"project\": args.wandb.project,\n",
    "        \"save_code\": args.wandb.save_code,\n",
    "    }\n",
    "wandb_init_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb_project_name = args.wandb.project\n",
    "wandb_id = args.wandb.id if args.wandb.id != \"None\" else None\n",
    "wandb_mode = args.wandb.mode if args.wandb.mode != \"None\" else \"online\"\n",
    "wandb_resume = args.wandb.resume if args.wandb.resume != \"None\" else None\n",
    "wandb.init(project=wandb_project_name, id=wandb_id, resume=wandb_resume, mode=wandb_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New wandb run id: 70w9g6ch\n"
     ]
    }
   ],
   "source": [
    "if args.wandb.resume != \"None\":\n",
    "    wandb_init_config.update({\n",
    "                            \"id\": args.wandb.id,\n",
    "                            \"resume\": args.wandb.resume\n",
    "                            })\n",
    "    \n",
    "    if args.wandb.resume_from != \"None\":\n",
    "        wandb_init_config[\"config\"] = args.wandb.resume_from\n",
    "        \n",
    "    run = wandb.init(**wandb_init_config)\n",
    "    print(f\"Resuming wandb run id: {wandb.run.id}\")\n",
    "    \n",
    "    def log_config_diffs(old_config, new_config, step):\n",
    "        diffs = {}\n",
    "        for key in new_config:\n",
    "            if key not in old_config or old_config[key] != new_config[key]:\n",
    "                diffs[key] = {'old': old_config.get(key), 'new': new_config[key]}\n",
    "    \n",
    "        if diffs:\n",
    "            note = f\"Config changes at step {step}:\\n\"\n",
    "            for key, value in diffs.items():\n",
    "                note += f\"{key}: {value['old']} -> {value['new']}\\n\"\n",
    "            wandb.run.notes = (wandb.run.notes or \"\") + note + \"\\n\\nAdditional information added later:\\n\"\n",
    "    \n",
    "    old_config = wandb.config.copy()\n",
    "    wandb.config.update(args)\n",
    "    new_config = wandb.config.copy()\n",
    "    log_config_diffs(old_config, new_config, step=\"update_args\")           \n",
    "else:\n",
    "    wandb.init(**wandb_init_config, config=args, )\n",
    "    print(f\"New wandb run id: {wandb.run.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DDPM_icentia11k_ftS_sl10_ll105_pl30_lr0.001_bs8_invFalse_itr1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_seed = random_seed\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "iteration = 1\n",
    "# setting\n",
    "setting = f\"{model}_{dataset}_ft{features}_sl{context_len}_ll{label_len}_pl{pred_len}_lr{learning_rate}_bs{batch_size}_inv{inverse}_itr{iteration}\"\n",
    "\n",
    "if tag is not None:\n",
    "    setting += f\"_{tag}\"\n",
    "\n",
    "setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "exp = liran_project.mrdiff.exp_main.Exp_Main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/liranc6/ecg_forecasting/liran_project/mrdiff/src/config_ecg.yml'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.args.configs_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_path': '/home/liranc6/ecg_forecasting',\n",
       " 'tqdm': 'terminal',\n",
       " 'resume': {'resume': True,\n",
       "  'resume_from': False,\n",
       "  'resume_optimizer': True,\n",
       "  'resume_epoch': 'None',\n",
       "  'loss_and_metrics': True,\n",
       "  'resume_scheduler': True,\n",
       "  'resume_configuration': True,\n",
       "  'specific_chpt_path': '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff/DDPM_icentia11k_ftS_sl10_ll105_pl30_lr0.001_bs8_invFalse_itr0/09_10_2024_1143/best_checkpoint.pth',\n",
       "  'was_resumed': False},\n",
       " 'wandb': {'entity': 'liranc6',\n",
       "  'mode': 'disabled',\n",
       "  'project': 'mrdiff',\n",
       "  'resume': 'None',\n",
       "  'run_name': 'None',\n",
       "  'id': 'None',\n",
       "  'save_code': True,\n",
       "  'resume_from': 'None'},\n",
       " 'general': {'random_seed': 42,\n",
       "  'evaluate': False,\n",
       "  'tag': None,\n",
       "  'dataset': 'icentia11k',\n",
       "  'features': 'S',\n",
       "  'training_mode': 'ONE',\n",
       "  'interval': 1000},\n",
       " 'optimization': {'learning_rate': 0.001,\n",
       "  'batch_size': 8,\n",
       "  'test_batch_size': 8,\n",
       "  'patience': 10,\n",
       "  'weight_decay': 1e-05,\n",
       "  'lradj': '3',\n",
       "  'pct_start': 0.3},\n",
       " 'hardware': {'print_gpu_memory_usage': False,\n",
       "  'num_workers': 0,\n",
       "  'use_gpu': True,\n",
       "  'gpu': 0,\n",
       "  'use_multi_gpu': False,\n",
       "  'devices': '0',\n",
       "  'device_ids': [0]},\n",
       " 'paths': {'train_data': '/home/liranc6/data/with_R_beats/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes/train/p0_to_p32.h5',\n",
       "  'val_data': '/home/liranc6/data/with_R_beats/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes/val/p33_to_p39.h5',\n",
       "  'test_data': '/home/liranc6/data/with_R_beats/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes/test/p40_to_p46.h5',\n",
       "  'output_dir': '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff',\n",
       "  'checkpoints': '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff',\n",
       "  'model_path': 'None'},\n",
       " 'data': {'fs': 250,\n",
       "  'freq': 'h',\n",
       "  'embed': 'timeF',\n",
       "  'cols': [],\n",
       "  'target': -1,\n",
       "  'inverse': False,\n",
       "  'individual': True,\n",
       "  'use_ar_init': False,\n",
       "  'use_residual': True,\n",
       "  'uncertainty': False,\n",
       "  'norm_method': 'None',\n",
       "  'normtype': 0,\n",
       "  'num_vars': 1},\n",
       " 'training': {'logging': {'sample': False,\n",
       "   'log_interval': 5,\n",
       "   'save_interval': 1,\n",
       "   'save_best': True,\n",
       "   'save_dir': '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff'},\n",
       "  'patients': {'start_patient': 0, 'end_patient': 1},\n",
       "  'iterations': {'itr': 1,\n",
       "   'pretrain_epochs': 0,\n",
       "   'train_epochs': 1,\n",
       "   'sample_times': 1},\n",
       "  'identifiers': {'id_worst': -1, 'focus_variate': -1},\n",
       "  'sequence': {'context_len': 10,\n",
       "   'seq_len': 135,\n",
       "   'label_len': 105,\n",
       "   'pred_len': 30},\n",
       "  'model_info': {'opt_loss_type': 'mse',\n",
       "   'model': 'DDPM',\n",
       "   'base_model': 'Linear',\n",
       "   'u_net_type': 'v0'},\n",
       "  'analysis': {'vis_MTS_analysis': 0,\n",
       "   'use_window_normalization': True,\n",
       "   'use_future_mixup': True,\n",
       "   'use_X0_in_THiDi': False,\n",
       "   'channel_independence': False},\n",
       "  'smoothing': {'smoothed_factors': [5, 25, 51]},\n",
       "  'ode': {'ot_ode': True, 'beta_max': 1.0, 't0': '1e-4', 'T': 0.02, 'nfe': 20},\n",
       "  'ablation_study': {'ablation_study_F_type': 'Linear',\n",
       "   'beta_schedule': 'cosine',\n",
       "   'beta_dist_alpha': -1,\n",
       "   'ablation_study_masking_type': 'none',\n",
       "   'ablation_study_masking_tau': 0.9},\n",
       "  'diffusion': {'beta_start': 0.0001,\n",
       "   'beta_end': 0.02,\n",
       "   'diff_steps': 100,\n",
       "   'ddpm_inp_embed': 64,\n",
       "   'ddpm_layers_inp': 10,\n",
       "   'ddpm_dim_diff_steps': 256,\n",
       "   'ddpm_channels_conv': 128,\n",
       "   'ddpm_channels_fusion_I': 256,\n",
       "   'ddpm_layers_I': 5,\n",
       "   'ddpm_layers_II': 10,\n",
       "   'kernel_size': 25,\n",
       "   'dec_channel_nums': 256,\n",
       "   'cond_ddpm_num_layers': 5,\n",
       "   'cond_ddpm_channels_conv': 256},\n",
       "  'sampler': {'type_sampler': 'dpm',\n",
       "   'parameterization': 'x_start',\n",
       "   'our_ddpm_clip': 100},\n",
       "  'misc': {'affine': 0, 'subtract_last': 0, 'subtract_short_terms': 0}},\n",
       " 'validation': {'patients': {'start_patient': 0, 'end_patient': 1}},\n",
       " 'testing': {'patients': {'start_patient': 0, 'end_patient': 1}},\n",
       " 'use_gpu': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.args.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading 00000:   0%|          | 0/2 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# exp.read_data('val')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# exp.read_data('test')\u001b[39;00m\n",
      "File \u001b[0;32m~/ecg_forecasting/liran_project/mrdiff/exp_main.py:73\u001b[0m, in \u001b[0;36mExp_Main.read_data\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, flag):\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ecg_forecasting/liran_project/mrdiff/exp_main.py:97\u001b[0m, in \u001b[0;36mExp_Main._get_data\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     94\u001b[0m     start_patiant \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatients\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_patient\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     95\u001b[0m     end_patiant \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatients\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_patient\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 97\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataSet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlabel_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_patiant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_patiant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mend_patiant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_patiant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdata_with_RR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_with_RR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mnormalize_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    108\u001b[0m     shuffle_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \n",
      "File \u001b[0;32m~/ecg_forecasting/liran_project/utils/dataset_loader.py:168\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, context_window_size, label_window_size, h5_filename, start_sample_from, data_with_RR, cache_size, return_with_RR, start_patiant, end_patiant, normalize_method)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys \u001b[38;5;241m=\u001b[39m group_keys[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_patiant:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_patiant\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    167\u001b[0m datasets_sizes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh5_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m h5_file:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys:\n\u001b[1;32m    170\u001b[0m         item \u001b[38;5;241m=\u001b[39m h5_file[key]\n",
      "File \u001b[0;32m~/ecg_forecasting/liran_project/utils/dataset_loader.py:263\u001b[0m, in \u001b[0;36m_get_normalization_statistics\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    260\u001b[0m             y \u001b[38;5;241m=\u001b[39m window[advance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_window_size : advance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_window_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_window_size]\n\u001b[1;32m    261\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache[idx \u001b[38;5;241m+\u001b[39m i] \u001b[38;5;241m=\u001b[39m (x, y)\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_normalization_statistics\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m    264\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    265\u001b[0m     total_num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/h5py/_hl/dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp.read_data('train')\n",
    "exp.read_data('val')\n",
    "exp.read_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mnlp-2080-1                   \u001b[m  Wed Oct  9 13:23:09 2024  \u001b[1m\u001b[30m535.146.02\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 2080 Ti\u001b[m |\u001b[31m 26°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  456\u001b[m / \u001b[33m11264\u001b[m MB | \u001b[1m\u001b[30mliranc6\u001b[m(\u001b[33m200M\u001b[m)\n"
     ]
    }
   ],
   "source": [
    "# Reload the module\n",
    "importlib.reload(liran_project.mrdiff.exp_main)\n",
    "\n",
    "# Assuming `exp` is an existing instance of `Exp_Main`\n",
    "exp.__class__ = liran_project.mrdiff.exp_main.Exp_Main\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "! gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: <liran_project.mrdiff.src.parser.Args object at 0x7fe3d01aab00>\n",
      "device: cuda:0\n",
      "model: Model(\n",
      "  (base_models): ModuleList(\n",
      "    (0-3): 4 x BaseMapping(\n",
      "      (Linear_Trend): ModuleList(\n",
      "        (0): Linear(in_features=10, out_features=30, bias=True)\n",
      "      )\n",
      "      (rev): RevIN()\n",
      "    )\n",
      "  )\n",
      "  (decompsitions): ModuleList(\n",
      "    (0): series_decomp(\n",
      "      (moving_avg): moving_avg(\n",
      "        (avg): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(0,))\n",
      "      )\n",
      "    )\n",
      "    (1): series_decomp(\n",
      "      (moving_avg): moving_avg(\n",
      "        (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
      "      )\n",
      "    )\n",
      "    (2): series_decomp(\n",
      "      (moving_avg): moving_avg(\n",
      "        (avg): AvgPool1d(kernel_size=(51,), stride=(1,), padding=(0,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (u_nets): ModuleList(\n",
      "    (0-2): 3 x My_DiffusionUnet_v0(\n",
      "      (diffusion_embedding): DiffusionEmbedding(\n",
      "        (projection1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (projection2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (input_projection): InputConvNetwork(\n",
      "        (net): ModuleList(\n",
      "          (0): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.1)\n",
      "          (3): Dropout(p=0.1, inplace=True)\n",
      "          (4): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): LeakyReLU(negative_slope=0.1)\n",
      "          (7): Dropout(p=0.1, inplace=True)\n",
      "          (8): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): LeakyReLU(negative_slope=0.1)\n",
      "          (11): Dropout(p=0.1, inplace=True)\n",
      "          (12): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (14): LeakyReLU(negative_slope=0.1)\n",
      "          (15): Dropout(p=0.1, inplace=True)\n",
      "          (16): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (17): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (18): LeakyReLU(negative_slope=0.1)\n",
      "          (19): Dropout(p=0.1, inplace=True)\n",
      "          (20): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (21): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (22): LeakyReLU(negative_slope=0.1)\n",
      "          (23): Dropout(p=0.1, inplace=True)\n",
      "          (24): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (25): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (26): LeakyReLU(negative_slope=0.1)\n",
      "          (27): Dropout(p=0.1, inplace=True)\n",
      "          (28): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (29): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (30): LeakyReLU(negative_slope=0.1)\n",
      "          (31): Dropout(p=0.1, inplace=True)\n",
      "          (32): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (33): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (34): LeakyReLU(negative_slope=0.1)\n",
      "          (35): Dropout(p=0.1, inplace=True)\n",
      "          (36): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (enc_conv): InputConvNetwork(\n",
      "        (net): ModuleList(\n",
      "          (0): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(320, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.1)\n",
      "          (3): Dropout(p=0.1, inplace=True)\n",
      "          (4): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): LeakyReLU(negative_slope=0.1)\n",
      "          (7): Dropout(p=0.1, inplace=True)\n",
      "          (8): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): LeakyReLU(negative_slope=0.1)\n",
      "          (11): Dropout(p=0.1, inplace=True)\n",
      "          (12): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (14): LeakyReLU(negative_slope=0.1)\n",
      "          (15): Dropout(p=0.1, inplace=True)\n",
      "          (16): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (cond_projections): ModuleList(\n",
      "        (0): Linear(in_features=10, out_features=30, bias=True)\n",
      "      )\n",
      "      (combine_conv): InputConvNetwork(\n",
      "        (net): ModuleList(\n",
      "          (0): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(258, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.1)\n",
      "          (3): Dropout(p=0.1, inplace=True)\n",
      "          (4): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): LeakyReLU(negative_slope=0.1)\n",
      "          (7): Dropout(p=0.1, inplace=True)\n",
      "          (8): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): LeakyReLU(negative_slope=0.1)\n",
      "          (11): Dropout(p=0.1, inplace=True)\n",
      "          (12): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (14): LeakyReLU(negative_slope=0.1)\n",
      "          (15): Dropout(p=0.1, inplace=True)\n",
      "          (16): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (17): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (18): LeakyReLU(negative_slope=0.1)\n",
      "          (19): Dropout(p=0.1, inplace=True)\n",
      "          (20): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (21): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (22): LeakyReLU(negative_slope=0.1)\n",
      "          (23): Dropout(p=0.1, inplace=True)\n",
      "          (24): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (25): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (26): LeakyReLU(negative_slope=0.1)\n",
      "          (27): Dropout(p=0.1, inplace=True)\n",
      "          (28): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (29): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (30): LeakyReLU(negative_slope=0.1)\n",
      "          (31): Dropout(p=0.1, inplace=True)\n",
      "          (32): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (33): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (34): LeakyReLU(negative_slope=0.1)\n",
      "          (35): Dropout(p=0.1, inplace=True)\n",
      "          (36): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): My_DiffusionUnet_v0(\n",
      "      (diffusion_embedding): DiffusionEmbedding(\n",
      "        (projection1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (projection2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (input_projection): InputConvNetwork(\n",
      "        (net): ModuleList(\n",
      "          (0): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.1)\n",
      "          (3): Dropout(p=0.1, inplace=True)\n",
      "          (4): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): LeakyReLU(negative_slope=0.1)\n",
      "          (7): Dropout(p=0.1, inplace=True)\n",
      "          (8): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): LeakyReLU(negative_slope=0.1)\n",
      "          (11): Dropout(p=0.1, inplace=True)\n",
      "          (12): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (14): LeakyReLU(negative_slope=0.1)\n",
      "          (15): Dropout(p=0.1, inplace=True)\n",
      "          (16): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (17): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (18): LeakyReLU(negative_slope=0.1)\n",
      "          (19): Dropout(p=0.1, inplace=True)\n",
      "          (20): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (21): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (22): LeakyReLU(negative_slope=0.1)\n",
      "          (23): Dropout(p=0.1, inplace=True)\n",
      "          (24): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (25): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (26): LeakyReLU(negative_slope=0.1)\n",
      "          (27): Dropout(p=0.1, inplace=True)\n",
      "          (28): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (29): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (30): LeakyReLU(negative_slope=0.1)\n",
      "          (31): Dropout(p=0.1, inplace=True)\n",
      "          (32): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (33): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (34): LeakyReLU(negative_slope=0.1)\n",
      "          (35): Dropout(p=0.1, inplace=True)\n",
      "          (36): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (enc_conv): InputConvNetwork(\n",
      "        (net): ModuleList(\n",
      "          (0): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(320, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.1)\n",
      "          (3): Dropout(p=0.1, inplace=True)\n",
      "          (4): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): LeakyReLU(negative_slope=0.1)\n",
      "          (7): Dropout(p=0.1, inplace=True)\n",
      "          (8): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): LeakyReLU(negative_slope=0.1)\n",
      "          (11): Dropout(p=0.1, inplace=True)\n",
      "          (12): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (14): LeakyReLU(negative_slope=0.1)\n",
      "          (15): Dropout(p=0.1, inplace=True)\n",
      "          (16): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (cond_projections): ModuleList(\n",
      "        (0): Linear(in_features=10, out_features=30, bias=True)\n",
      "      )\n",
      "      (combine_conv): InputConvNetwork(\n",
      "        (net): ModuleList(\n",
      "          (0): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(257, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.1)\n",
      "          (3): Dropout(p=0.1, inplace=True)\n",
      "          (4): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): LeakyReLU(negative_slope=0.1)\n",
      "          (7): Dropout(p=0.1, inplace=True)\n",
      "          (8): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): LeakyReLU(negative_slope=0.1)\n",
      "          (11): Dropout(p=0.1, inplace=True)\n",
      "          (12): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (14): LeakyReLU(negative_slope=0.1)\n",
      "          (15): Dropout(p=0.1, inplace=True)\n",
      "          (16): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (17): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (18): LeakyReLU(negative_slope=0.1)\n",
      "          (19): Dropout(p=0.1, inplace=True)\n",
      "          (20): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (21): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (22): LeakyReLU(negative_slope=0.1)\n",
      "          (23): Dropout(p=0.1, inplace=True)\n",
      "          (24): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (25): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (26): LeakyReLU(negative_slope=0.1)\n",
      "          (27): Dropout(p=0.1, inplace=True)\n",
      "          (28): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (29): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (30): LeakyReLU(negative_slope=0.1)\n",
      "          (31): Dropout(p=0.1, inplace=True)\n",
      "          (32): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (33): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (34): LeakyReLU(negative_slope=0.1)\n",
      "          (35): Dropout(p=0.1, inplace=True)\n",
      "          (36): Conv1dWithInitialization(\n",
      "            (conv1d): Conv1d(256, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (diffusion_workers): ModuleList(\n",
      "    (0-2): 3 x Diffusion_Worker(\n",
      "      (net): My_DiffusionUnet_v0(\n",
      "        (diffusion_embedding): DiffusionEmbedding(\n",
      "          (projection1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (projection2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (input_projection): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (17): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (18): LeakyReLU(negative_slope=0.1)\n",
      "            (19): Dropout(p=0.1, inplace=True)\n",
      "            (20): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (21): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (22): LeakyReLU(negative_slope=0.1)\n",
      "            (23): Dropout(p=0.1, inplace=True)\n",
      "            (24): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (25): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (26): LeakyReLU(negative_slope=0.1)\n",
      "            (27): Dropout(p=0.1, inplace=True)\n",
      "            (28): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (29): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (30): LeakyReLU(negative_slope=0.1)\n",
      "            (31): Dropout(p=0.1, inplace=True)\n",
      "            (32): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (33): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (34): LeakyReLU(negative_slope=0.1)\n",
      "            (35): Dropout(p=0.1, inplace=True)\n",
      "            (36): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (enc_conv): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(320, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (cond_projections): ModuleList(\n",
      "          (0): Linear(in_features=10, out_features=30, bias=True)\n",
      "        )\n",
      "        (combine_conv): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(258, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (17): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (18): LeakyReLU(negative_slope=0.1)\n",
      "            (19): Dropout(p=0.1, inplace=True)\n",
      "            (20): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (21): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (22): LeakyReLU(negative_slope=0.1)\n",
      "            (23): Dropout(p=0.1, inplace=True)\n",
      "            (24): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (25): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (26): LeakyReLU(negative_slope=0.1)\n",
      "            (27): Dropout(p=0.1, inplace=True)\n",
      "            (28): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (29): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (30): LeakyReLU(negative_slope=0.1)\n",
      "            (31): Dropout(p=0.1, inplace=True)\n",
      "            (32): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (33): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (34): LeakyReLU(negative_slope=0.1)\n",
      "            (35): Dropout(p=0.1, inplace=True)\n",
      "            (36): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (nn): My_DiffusionUnet_v0(\n",
      "        (diffusion_embedding): DiffusionEmbedding(\n",
      "          (projection1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (projection2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (input_projection): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (17): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (18): LeakyReLU(negative_slope=0.1)\n",
      "            (19): Dropout(p=0.1, inplace=True)\n",
      "            (20): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (21): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (22): LeakyReLU(negative_slope=0.1)\n",
      "            (23): Dropout(p=0.1, inplace=True)\n",
      "            (24): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (25): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (26): LeakyReLU(negative_slope=0.1)\n",
      "            (27): Dropout(p=0.1, inplace=True)\n",
      "            (28): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (29): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (30): LeakyReLU(negative_slope=0.1)\n",
      "            (31): Dropout(p=0.1, inplace=True)\n",
      "            (32): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (33): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (34): LeakyReLU(negative_slope=0.1)\n",
      "            (35): Dropout(p=0.1, inplace=True)\n",
      "            (36): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (enc_conv): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(320, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (cond_projections): ModuleList(\n",
      "          (0): Linear(in_features=10, out_features=30, bias=True)\n",
      "        )\n",
      "        (combine_conv): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(258, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (17): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (18): LeakyReLU(negative_slope=0.1)\n",
      "            (19): Dropout(p=0.1, inplace=True)\n",
      "            (20): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (21): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (22): LeakyReLU(negative_slope=0.1)\n",
      "            (23): Dropout(p=0.1, inplace=True)\n",
      "            (24): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (25): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (26): LeakyReLU(negative_slope=0.1)\n",
      "            (27): Dropout(p=0.1, inplace=True)\n",
      "            (28): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (29): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (30): LeakyReLU(negative_slope=0.1)\n",
      "            (31): Dropout(p=0.1, inplace=True)\n",
      "            (32): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (33): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (34): LeakyReLU(negative_slope=0.1)\n",
      "            (35): Dropout(p=0.1, inplace=True)\n",
      "            (36): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Diffusion_Worker(\n",
      "      (net): My_DiffusionUnet_v0(\n",
      "        (diffusion_embedding): DiffusionEmbedding(\n",
      "          (projection1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (projection2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (input_projection): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (17): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (18): LeakyReLU(negative_slope=0.1)\n",
      "            (19): Dropout(p=0.1, inplace=True)\n",
      "            (20): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (21): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (22): LeakyReLU(negative_slope=0.1)\n",
      "            (23): Dropout(p=0.1, inplace=True)\n",
      "            (24): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (25): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (26): LeakyReLU(negative_slope=0.1)\n",
      "            (27): Dropout(p=0.1, inplace=True)\n",
      "            (28): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (29): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (30): LeakyReLU(negative_slope=0.1)\n",
      "            (31): Dropout(p=0.1, inplace=True)\n",
      "            (32): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (33): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (34): LeakyReLU(negative_slope=0.1)\n",
      "            (35): Dropout(p=0.1, inplace=True)\n",
      "            (36): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (enc_conv): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(320, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (cond_projections): ModuleList(\n",
      "          (0): Linear(in_features=10, out_features=30, bias=True)\n",
      "        )\n",
      "        (combine_conv): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(257, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (17): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (18): LeakyReLU(negative_slope=0.1)\n",
      "            (19): Dropout(p=0.1, inplace=True)\n",
      "            (20): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (21): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (22): LeakyReLU(negative_slope=0.1)\n",
      "            (23): Dropout(p=0.1, inplace=True)\n",
      "            (24): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (25): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (26): LeakyReLU(negative_slope=0.1)\n",
      "            (27): Dropout(p=0.1, inplace=True)\n",
      "            (28): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (29): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (30): LeakyReLU(negative_slope=0.1)\n",
      "            (31): Dropout(p=0.1, inplace=True)\n",
      "            (32): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (33): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (34): LeakyReLU(negative_slope=0.1)\n",
      "            (35): Dropout(p=0.1, inplace=True)\n",
      "            (36): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (nn): My_DiffusionUnet_v0(\n",
      "        (diffusion_embedding): DiffusionEmbedding(\n",
      "          (projection1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (projection2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (input_projection): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (17): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (18): LeakyReLU(negative_slope=0.1)\n",
      "            (19): Dropout(p=0.1, inplace=True)\n",
      "            (20): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (21): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (22): LeakyReLU(negative_slope=0.1)\n",
      "            (23): Dropout(p=0.1, inplace=True)\n",
      "            (24): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (25): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (26): LeakyReLU(negative_slope=0.1)\n",
      "            (27): Dropout(p=0.1, inplace=True)\n",
      "            (28): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (29): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (30): LeakyReLU(negative_slope=0.1)\n",
      "            (31): Dropout(p=0.1, inplace=True)\n",
      "            (32): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (33): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (34): LeakyReLU(negative_slope=0.1)\n",
      "            (35): Dropout(p=0.1, inplace=True)\n",
      "            (36): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (enc_conv): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(320, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (cond_projections): ModuleList(\n",
      "          (0): Linear(in_features=10, out_features=30, bias=True)\n",
      "        )\n",
      "        (combine_conv): InputConvNetwork(\n",
      "          (net): ModuleList(\n",
      "            (0): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(257, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.1)\n",
      "            (3): Dropout(p=0.1, inplace=True)\n",
      "            (4): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.1)\n",
      "            (7): Dropout(p=0.1, inplace=True)\n",
      "            (8): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (10): LeakyReLU(negative_slope=0.1)\n",
      "            (11): Dropout(p=0.1, inplace=True)\n",
      "            (12): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (14): LeakyReLU(negative_slope=0.1)\n",
      "            (15): Dropout(p=0.1, inplace=True)\n",
      "            (16): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (17): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (18): LeakyReLU(negative_slope=0.1)\n",
      "            (19): Dropout(p=0.1, inplace=True)\n",
      "            (20): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (21): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (22): LeakyReLU(negative_slope=0.1)\n",
      "            (23): Dropout(p=0.1, inplace=True)\n",
      "            (24): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (25): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (26): LeakyReLU(negative_slope=0.1)\n",
      "            (27): Dropout(p=0.1, inplace=True)\n",
      "            (28): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (29): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (30): LeakyReLU(negative_slope=0.1)\n",
      "            (31): Dropout(p=0.1, inplace=True)\n",
      "            (32): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (33): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (34): LeakyReLU(negative_slope=0.1)\n",
      "            (35): Dropout(p=0.1, inplace=True)\n",
      "            (36): Conv1dWithInitialization(\n",
      "              (conv1d): Conv1d(256, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (rev): RevIN()\n",
      ")\n",
      "set_models_using_meta: ['PDSB', 'DDPM']\n",
      "datasets: {'train': <liran_project.utils.dataset_loader.SingleLeadECGDatasetCrops_mrDiff object at 0x7fe2b3a63880>, 'val': <liran_project.utils.dataset_loader.SingleLeadECGDatasetCrops_mrDiff object at 0x7fe2b3bb0d30>}\n",
      "dataloaders: {'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe3970f8100>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7fe2befb2ad0>}\n",
      "model_start_training_time: None\n"
     ]
    }
   ],
   "source": [
    "exp.print_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>start training : DDPM_icentia11k_ftS_sl10_ll105_pl30_lr0.001_bs8_invFalse_itr1>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "An error occurred during training: PytorchStreamReader failed locating file data.pkl: file not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-10-08 20:08:25 1504372:1504372 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-10-08 20:08:25 1504372:1504372 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-10-08 20:08:25 1504372:1504372 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "[W collection.cpp:936] Warning: Failed to recover relationship between all profiler and kineto events: 6 vs. 0  reassociated. (function reassociate)\n"
     ]
    }
   ],
   "source": [
    "print(f'>>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "try:\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            # torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    "    ) as prof:\n",
    "        exp.train(setting)\n",
    "except Exception as e:\n",
    "    print(f'An error occurred during training: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us      18.31 Mb      18.31 Mb      78.08 Gb      78.08 Gb          1554  \n",
      "                                        cudaMemcpyAsync         1.23%       6.926ms         1.23%       6.926ms     266.385us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            26  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       1.455ms         0.51%       1.455ms      80.833us           0 b           0 b           0 b           0 b            18  \n",
      "                                  cudaStreamSynchronize        21.49%     121.087ms        21.49%     121.087ms       6.727ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            18  \n",
      "                                       cudaLaunchKernel        30.12%     169.752ms        30.12%     169.752ms     169.922us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           999  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      85.000us         0.03%      85.000us       6.071us           0 b           0 b           0 b           0 b            14  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      58.000us         0.02%      58.000us      11.600us           0 b           0 b           0 b           0 b             5  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.000us         0.00%       5.000us       1.000us           0 b           0 b           0 b           0 b             5  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      10.000us         0.00%      10.000us       2.000us           0 b           0 b           0 b           0 b             5  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      31.349ms        10.92%      31.349ms     265.669us           0 b           0 b           0 b           0 b           118  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 563.570ms\n",
      "Self CUDA time total: 287.026ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming `prof` is your profiler object\n",
    "key_averages = prof.key_averages()\n",
    "\n",
    "# Filter to include only CUDA operations\n",
    "cuda_operations = [item for item in key_averages if 'cuda' in item.key]\n",
    "\n",
    "# Print the filtered table\n",
    "print(key_averages.table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CUDA Memory Usage: 83842590208 bytes\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us      18.31 Mb      18.31 Mb      78.08 Gb      78.08 Gb          1554  \n",
      "                                        cudaMemcpyAsync         1.23%       6.926ms         1.23%       6.926ms     266.385us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            26  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       1.455ms         0.51%       1.455ms      80.833us           0 b           0 b           0 b           0 b            18  \n",
      "                                  cudaStreamSynchronize        21.49%     121.087ms        21.49%     121.087ms       6.727ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            18  \n",
      "                                       cudaLaunchKernel        30.12%     169.752ms        30.12%     169.752ms     169.922us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           999  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      85.000us         0.03%      85.000us       6.071us           0 b           0 b           0 b           0 b            14  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      58.000us         0.02%      58.000us      11.600us           0 b           0 b           0 b           0 b             5  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.000us         0.00%       5.000us       1.000us           0 b           0 b           0 b           0 b             5  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      10.000us         0.00%      10.000us       2.000us           0 b           0 b           0 b           0 b             5  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      31.349ms        10.92%      31.349ms     265.669us           0 b           0 b           0 b           0 b           118  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 563.570ms\n",
      "Self CUDA time total: 287.026ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.profiler\n",
    "\n",
    "# Assuming `prof` is your profiler object\n",
    "key_averages = prof.key_averages()\n",
    "\n",
    "# Total CUDA memory usage\n",
    "total_cuda_memory_usage = sum(item.self_cuda_memory_usage for item in key_averages)\n",
    "print(f\"Total CUDA Memory Usage: {total_cuda_memory_usage} bytes\")\n",
    "\n",
    "# Memory usage by function\n",
    "print(key_averages.table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us      18.31 Mb      18.31 Mb      78.08 Gb      78.08 Gb          1554  \n",
      "                                        cudaMemcpyAsync         1.23%       6.926ms         1.23%       6.926ms     266.385us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            26  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       1.455ms         0.51%       1.455ms      80.833us           0 b           0 b           0 b           0 b            18  \n",
      "                                  cudaStreamSynchronize        21.49%     121.087ms        21.49%     121.087ms       6.727ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            18  \n",
      "                                       cudaLaunchKernel        30.12%     169.752ms        30.12%     169.752ms     169.922us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           999  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      85.000us         0.03%      85.000us       6.071us           0 b           0 b           0 b           0 b            14  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      58.000us         0.02%      58.000us      11.600us           0 b           0 b           0 b           0 b             5  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.000us         0.00%       5.000us       1.000us           0 b           0 b           0 b           0 b             5  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      10.000us         0.00%      10.000us       2.000us           0 b           0 b           0 b           0 b             5  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      31.349ms        10.92%      31.349ms     265.669us           0 b           0 b           0 b           0 b           118  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 563.570ms\n",
      "Self CUDA time total: 287.026ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 25           |        cudaMalloc retries: 26        |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  66618 KiB |  80015 MiB | 104888 MiB | 104823 MiB |\n",
      "|       from large pool |  22384 KiB |  79971 MiB | 104827 MiB | 104805 MiB |\n",
      "|       from small pool |  44234 KiB |     44 MiB |     60 MiB |     17 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  66618 KiB |  80015 MiB | 104888 MiB | 104823 MiB |\n",
      "|       from large pool |  22384 KiB |  79971 MiB | 104827 MiB | 104805 MiB |\n",
      "|       from small pool |  44234 KiB |     44 MiB |     60 MiB |     17 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  66557 KiB |  79929 MiB | 104770 MiB | 104705 MiB |\n",
      "|       from large pool |  22382 KiB |  79886 MiB | 104709 MiB | 104687 MiB |\n",
      "|       from small pool |  44175 KiB |     44 MiB |     60 MiB |     17 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  80472 MiB |  80472 MiB |  80740 MiB | 274432 KiB |\n",
      "|       from large pool |  80426 MiB |  80426 MiB |  80692 MiB | 272384 KiB |\n",
      "|       from small pool |     46 MiB |     48 MiB |     48 MiB |   2048 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  21446 KiB |   1225 MiB |   4167 MiB |   4146 MiB |\n",
      "|       from large pool |  18576 KiB |   1222 MiB |   4118 MiB |   4100 MiB |\n",
      "|       from small pool |   2870 KiB |      4 MiB |     49 MiB |     46 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     743    |    1297    |    1590    |     847    |\n",
      "|       from large pool |       9    |     371    |     573    |     564    |\n",
      "|       from small pool |     734    |     926    |    1017    |     283    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     743    |    1297    |    1590    |     847    |\n",
      "|       from large pool |       9    |     371    |     573    |     564    |\n",
      "|       from small pool |     734    |     926    |    1017    |     283    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     349    |     351    |     352    |       3    |\n",
      "|       from large pool |     326    |     327    |     328    |       2    |\n",
      "|       from small pool |      23    |      24    |      24    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      13    |      50    |     340    |     327    |\n",
      "|       from large pool |       2    |      38    |     173    |     171    |\n",
      "|       from small pool |      11    |      20    |     167    |     156    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.model_start_training_time = \"02_10_2024_135344\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>testing : DDPM_icentia11k_ftS_sl10_ll105000_pl45000_lr0.001_bs8_invFalse_itr1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "loading model\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff/DDPM_icentia11k_ftS_sl10_ll105000_pl45000_lr0.001_bs8_invFalse_itr1/05_10_2024_0030/checkpoint.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>testing : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msetting\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ecg_forecasting/liran_project/mrdiff/exp_main.py:386\u001b[0m, in \u001b[0;36mExp_Main.test\u001b[0;34m(self, setting, time_path, test, visualize)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    385\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpaths\u001b[38;5;241m.\u001b[39mcheckpoints, setting, time_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    388\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    389\u001b[0m trues \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff/DDPM_icentia11k_ftS_sl10_ll105000_pl45000_lr0.001_bs8_invFalse_itr1/05_10_2024_0030/checkpoint.pth'"
     ]
    }
   ],
   "source": [
    "print(f'>>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "exp.test(setting, test=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DDPM_icentia11k_ftS_sl1_ll1500_pl1500_lr0.001_bs8_invFalse_itr0>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading 00001: 100%|██████████| 2/2 [00:24<00:00, 12.28s/it]\n",
      "Reading 00001: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]\n",
      "Reading 00042: 100%|██████████| 3/3 [00:04<00:00,  1.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m exp \u001b[38;5;241m=\u001b[39m Exp_Main(args)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>start training : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msetting\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>testing : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msetting\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m exp\u001b[38;5;241m.\u001b[39mtest(setting, test\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 180\u001b[0m, in \u001b[0;36mExp_Main.train\u001b[0;34m(self, setting)\u001b[0m\n\u001b[1;32m    177\u001b[0m epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    178\u001b[0m results \u001b[38;5;241m=\u001b[39m Metrics(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (batch_x, batch_y, batch_x_mark, batch_y_mark) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_x\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    183\u001b[0m         batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/ecg_forecasting/liran_project/utils/dataset_loader.py:216\u001b[0m, in \u001b[0;36mSingleLeadECGDatasetCrops_mrDiff.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    212\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m h5_file[str_dataset_idx]\n\u001b[1;32m    214\u001b[0m     end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size, \u001b[38;5;28mlen\u001b[39m(dataset)) \n\u001b[0;32m--> 216\u001b[0m     to_cache \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# This is a list of windows, each window is a numpy array with shape (window_size) if no RR data,\u001b[39;00m\n\u001b[1;32m    217\u001b[0m                                             \u001b[38;5;66;03m# or (2, window_size) if there is RR data\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_to_cache(to_cache, idx, advance)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/h5py/_hl/dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(iterations):\n",
    "    # setting record of experiments\n",
    "\n",
    "    # random seed\n",
    "    \n",
    "    # setting\n",
    "    setting = f\"{model}_{dataset}_ft{features}_sl{context_len}_ll{label_len}_pl{pred_len}_lr{learning_rate}_bs{batch_size}_inv{inverse}_itr{iteration}\"\n",
    "    \n",
    "    if tag is not None:\n",
    "        setting += f\"_{tag}\"\n",
    "\n",
    "    exp = Exp_Main(args)\n",
    "\n",
    "    print(f'>>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    exp.train(setting)\n",
    "\n",
    "    print(f'>>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    exp.test(setting, test=1)\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.configs.general.random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_samples = 0\n",
    "\n",
    "with h5py.File(filename, 'r') as h5_file:\n",
    "    num_keys = len(self.keys)\n",
    "    pbar_keys = tqdm(self.keys, total=num_keys, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pbar_keys.set_description(f\"creating_stats\")\n",
    "    for key in pbar_keys:\n",
    "        data = h5_file[key][()][:, 0, :] if self.data_with_RR else h5_file[key][()]\n",
    "            \n",
    "        curr_num_samples = data.shape[0]\n",
    "        total_num_samples += curr_num_samples\n",
    "\n",
    "        max_val = max(max_val, np.max(data))\n",
    "        min_val = min(min_val, np.min(data))\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Update the postfix\n",
    "        pbar_keys.set_postfix({\"time_elapsed\": str(timedelta(seconds=int(elapsed_time)))})\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(iterations, random_seed, model, dataset, features, seq_len,\n",
    "                    label_len, pred_len, learning_rate, batch_size, inverse, tag, args):\n",
    "    mae_ = []\n",
    "    mse_ = []\n",
    "    rmse_ = []\n",
    "    mape_ = []\n",
    "    mspe_ = []\n",
    "    rse_ = []\n",
    "    corr_ = []\n",
    "    nrmse_ = []\n",
    "\n",
    "    for iter in range(iterations):\n",
    "        # setting record of experiments\n",
    "\n",
    "        # random seed\n",
    "        fix_seed = iter if iterations > 1 else random_seed\n",
    "\n",
    "        random.seed(fix_seed)\n",
    "        torch.manual_seed(fix_seed)\n",
    "        np.random.seed(fix_seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True  # Can change it to False --> default: False\n",
    "        torch.backends.cudnn.enabled = True\n",
    "\n",
    "        setting = f\"{model}_{dataset}_ft{features}_sl{seq_len}_ll{label_len}_pl{pred_len}_lr{learning_rate}_bs{batch_size}_inv{inverse}_itr{iter}\"\n",
    "        if tag is not None:\n",
    "            setting += f\"_{tag}\"\n",
    "\n",
    "        exp = Exp_Main(args)\n",
    "\n",
    "        print(f'>>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "        exp.train(setting)\n",
    "\n",
    "        print(f'>>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "        mae, mse, rmse, mape, mspe, rse, corr, nrmse = exp.test(setting, test=1)\n",
    "\n",
    "        mae_.append(mae)\n",
    "        mse_.append(mse)\n",
    "        rmse_.append(rmse)\n",
    "        mape_.append(mape)\n",
    "        mspe_.append(mspe)\n",
    "        rse_.append(rse)\n",
    "        corr_.append(corr)\n",
    "        nrmse_.append(nrmse)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print('Final mean normed: ')\n",
    "    print('> mae:{:.4f}, std:{:.4f}'.format(np.mean(mae_), np.std(mae_)))\n",
    "    print('> mse:{:.4f}, std:{:.4f}'.format(np.mean(mse_), np.std(mse_)))\n",
    "    print('> rmse:{:.4f}, std:{:.4f}'.format(np.mean(rmse_), np.std(rmse_)))\n",
    "    print('> mape:{:.4f}, std:{:.4f}'.format(np.mean(mape_), np.std(mape_)))\n",
    "    print('> rse:{:.4f}, std:{:.4f}'.format(np.mean(rse_), np.std(rse_)))\n",
    "    print('> corr:{:.4f}, std:{:.4f}'.format(np.mean(corr_), np.std(corr_)))\n",
    "    print('> nrmse:{:.4f}, std:{:.4f}'.format(np.mean(nrmse_), np.std(nrmse_)))\n",
    "\n",
    "    return {\n",
    "        'mae': (np.mean(mae_), np.std(mae_)),\n",
    "        'mse': (np.mean(mse_), np.std(mse_)),\n",
    "        'rmse': (np.mean(rmse_), np.std(rmse_)),\n",
    "        'mape': (np.mean(mape_), np.std(mape_)),\n",
    "        'rse': (np.mean(rse_), np.std(rse_)),\n",
    "        'corr': (np.mean(corr_), np.std(corr_)),\n",
    "        'nrmse': (np.mean(nrmse_), np.std(nrmse_))\n",
    "    }\n",
    "    \n",
    "results = run_experiments(iterations, random_seed, model, dataset, features, seq_len,\n",
    "                            label_len, pred_len, learning_rate, batch_size, inverse, tag, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
