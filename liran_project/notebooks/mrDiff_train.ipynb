{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import yaml\n",
    "from box import Box\n",
    "from pprint import pprint\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "CONFIG_FILENAME = '/home/liranc6/ecg_forecasting/liran_project/mrdiff/src/config_ecg.yml'\n",
    "\n",
    "assert CONFIG_FILENAME.endswith('.yml')\n",
    "\n",
    "with open(CONFIG_FILENAME, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Add the parent directory to the sys.path\n",
    "ProjectPath = config['project_path']\n",
    "sys.path.append(ProjectPath)\n",
    "\n",
    "from liran_project.mrdiff.src.parser import parse_args\n",
    "from liran_project.utils.dataset_loader import SingleLeadECGDatasetCrops_mrDiff as DataSet\n",
    "from liran_project.utils.util import ecg_signal_difference\n",
    "import liran_project.mrdiff.exp_main\n",
    "# from liran_project.mrdiff.exp_main import Exp_Main\n",
    "\n",
    "# Add the directory containing the exp module to the sys.path\n",
    "exp_module_path = os.path.join(ProjectPath, 'mrDiff')\n",
    "sys.path.append(exp_module_path)\n",
    "\n",
    "# from mrDiff.exp.exp_main import Exp_Main\n",
    "from mrDiff.data_process.etth_dataloader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Wind, Dataset_Caiso, Dataset_Production, Dataset_Caiso_M, Dataset_Production_M\n",
    "from mrDiff.data_process.financial_dataloader import DatasetH\n",
    "from mrDiff.data_process.forecast_dataloader import ForecastDataset\n",
    "from mrDiff.exp.exp_basic import Exp_Basic\n",
    "from mrDiff.models_diffusion import DDPM\n",
    "from mrDiff.utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
    "from mrDiff.utils.metrics import metric\n",
    "\n",
    "from liran_project.mrdiff.src.parser import Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': Box({'project_path': '/home/liranc6/ecg_forecasting', 'wandb': {'entity': 'liranc6', 'mode': 'disabled', 'project': 'mrdiff', 'resume': 'None', 'run_name': 'first_run_ever', 'id': 'None', 'save_code': True, 'resume_from': 'None'}, 'general': {'random_seed': 42, 'evaluate': False, 'tag': None, 'dataset': 'icentia11k', 'features': 'S', 'training_mode': 'ONE', 'interval': 1000}, 'optimization': {'learning_rate': 0.001, 'batch_size': 16, 'test_batch_size': 8, 'patience': 10, 'weight_decay': 1e-05, 'lradj': '3', 'pct_start': 0.3}, 'hardware': {'print_gpu_memory_usage': True, 'num_workers': 0, 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0', 'device_ids': [0]}, 'paths': {'train_data': '/home/liranc6/data/with_R_beats/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes/train/p0_to_p32.h5', 'validation_data': '/home/liranc6/data/with_R_beats/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes/val/p33_to_p39.h5', 'test_data': '/home/liranc6/data/with_R_beats/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes/test/p40_to_p46.h5', 'output_dir': '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff', 'checkpoints': '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff'}, 'data': {'fs': 250, 'freq': 'h', 'embed': 'timeF', 'cols': [], 'target': -1, 'inverse': False, 'individual': True, 'use_ar_init': False, 'use_residual': True, 'uncertainty': False, 'norm_method': 'z_score', 'normtype': 0, 'num_vars': 1}, 'training': {'logging': {'sample': True, 'log_interval': 100, 'save_interval': 1, 'save_best': True, 'save_dir': '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff'}, 'patients': {'start_patient': 0, 'end_patient': 2}, 'iterations': {'itr': 1, 'pretrain_epochs': 0, 'train_epochs': 2, 'sample_times': 1}, 'identifiers': {'id_worst': -1, 'focus_variate': -1}, 'sequence': {'context_len': 1, 'seq_len': 30000, 'label_len': 15000, 'pred_len': 15000}, 'model_info': {'opt_loss_type': 'mse', 'model': 'DDPM', 'base_model': 'Linear', 'u_net_type': 'v0'}, 'analysis': {'vis_MTS_analysis': 0, 'use_window_normalization': True, 'use_future_mixup': True, 'use_X0_in_THiDi': False, 'channel_independence': False}, 'smoothing': {'smoothed_factors': [5, 25, 51]}, 'ode': {'ot_ode': True, 'beta_max': 1.0, 't0': '1e-4', 'T': 0.02, 'nfe': 20}, 'ablation_study': {'ablation_study_F_type': 'Linear', 'beta_schedule': 'cosine', 'beta_dist_alpha': -1, 'ablation_study_masking_type': 'none', 'ablation_study_masking_tau': 0.9}, 'diffusion': {'beta_start': 0.0001, 'beta_end': 0.02, 'diff_steps': 100, 'ddpm_inp_embed': 64, 'ddpm_layers_inp': 10, 'ddpm_dim_diff_steps': 256, 'ddpm_channels_conv': 128, 'ddpm_channels_fusion_I': 256, 'ddpm_layers_I': 5, 'ddpm_layers_II': 10, 'kernel_size': 25, 'dec_channel_nums': 256, 'cond_ddpm_num_layers': 5, 'cond_ddpm_channels_conv': 256}, 'sampler': {'type_sampler': 'dpm', 'parameterization': 'x_start', 'our_ddpm_clip': 100}, 'misc': {'affine': 0, 'subtract_last': 0, 'subtract_short_terms': 0}}, 'testing': {'patients': {'start_patient': 0, 'end_patient': 1}}, 'use_gpu': True}),\n",
      " 'config_filename': '/home/liranc6/ecg_forecasting/liran_project/mrdiff/src/config_ecg.yml'}\n"
     ]
    }
   ],
   "source": [
    "args = Args(CONFIG_FILENAME)\n",
    "\n",
    "# Now you can use args as needed\n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Box object to dictionary\n",
    "config_dict = args.config.to_dict()\n",
    "\n",
    "# Access the configuration values using dictionary syntax\n",
    "random_seed = config_dict['general']['random_seed']\n",
    "tag = config_dict['general']['tag']\n",
    "dataset = config_dict['general']['dataset']\n",
    "features = config_dict['general']['features']\n",
    "\n",
    "learning_rate = config_dict['optimization']['learning_rate']\n",
    "batch_size = config_dict['optimization']['batch_size']\n",
    "\n",
    "context_len = config_dict['training']['sequence']['context_len']\n",
    "label_len = config_dict['training']['sequence']['label_len']\n",
    "model = config_dict['training']['model_info']['model']\n",
    "pred_len = config_dict['training']['sequence']['pred_len']\n",
    "iterations = config_dict['training']['iterations']['itr']\n",
    "\n",
    "inverse = config_dict['data']['inverse']\n",
    "    \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True  # Can change it to False --> default: False\n",
    "torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mode': 'disabled', 'project': 'mrdiff', 'save_code': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# wandb\n",
    "wandb_init_config ={\n",
    "        \"mode\": args.wandb.mode,\n",
    "        \"project\": args.wandb.project,\n",
    "        \"save_code\": args.wandb.save_code,\n",
    "    }\n",
    "wandb_init_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New wandb run id: n5j4orjo\n"
     ]
    }
   ],
   "source": [
    "if args.wandb.resume != \"None\":\n",
    "    wandb_init_config.update({\n",
    "                            \"id\": args.wandb.resume,\n",
    "                            \"resume\": args.wandb.resume\n",
    "                            })\n",
    "    \n",
    "    if args.wandb.resume_from != \"None\":\n",
    "        wandb_init_config[\"config\"] = args.wandb.resume_from\n",
    "        \n",
    "    run = wandb.init(**wandb_init_config)\n",
    "    print(f\"Resuming wandb run id: {wandb.run.id}\")\n",
    "    \n",
    "    def log_config_diffs(old_config, new_config, step):\n",
    "        diffs = {}\n",
    "        for key in new_config:\n",
    "            if key not in old_config or old_config[key] != new_config[key]:\n",
    "                diffs[key] = {'old': old_config.get(key), 'new': new_config[key]}\n",
    "    \n",
    "        if diffs:\n",
    "            note = f\"Config changes at step {step}:\\n\"\n",
    "            for key, value in diffs.items():\n",
    "                note += f\"{key}: {value['old']} -> {value['new']}\\n\"\n",
    "            wandb.run.notes = (wandb.run.notes or \"\") + note + \"\\n\\nAdditional information added later:\\n\"\n",
    "    \n",
    "    old_config = wandb.config.copy()\n",
    "    wandb.config.update(args)\n",
    "    new_config = wandb.config.copy()\n",
    "    log_config_diffs(old_config, new_config, step=\"update_args\")\n",
    "            \n",
    "else:\n",
    "    wandb.init(**wandb_init_config, config=args, )\n",
    "    print(f\"New wandb run id: {wandb.run.id}\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed = random_seed\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "iteration = 1\n",
    "# setting\n",
    "setting = f\"{model}_{dataset}_ft{features}_sl{context_len}_ll{label_len}_pl{pred_len}_lr{learning_rate}_bs{batch_size}_inv{inverse}_itr{iteration}\"\n",
    "\n",
    "if tag is not None:\n",
    "    setting += f\"_{tag}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'liran_project.mrdiff.exp_main' from '/home/liranc6/ecg_forecasting/liran_project/mrdiff/exp_main.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the module\n",
    "importlib.reload(liran_project.mrdiff.exp_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "exp = liran_project.mrdiff.exp_main.Exp_Main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading 00002: 100%|██████████| 3/3 [00:03<00:00,  1.19s/it]\n",
      "Reading 00002: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it]\n",
      "Reading 00041: 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "exp.read_data('train')\n",
    "exp.read_data('val')\n",
    "exp.read_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the module\n",
    "importlib.reload(liran_project.mrdiff.exp_main)\n",
    "\n",
    "# Assuming `exp` is an existing instance of `Exp_Main`\n",
    "exp.__class__ = liran_project.mrdiff.exp_main.Exp_Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>start training : DDPM_icentia11k_ftS_sl1_ll15000_pl15000_lr0.001_bs16_invFalse_itr1>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Saving model to /home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff/DDPM_icentia11k_ftS_sl1_ll15000_pl15000_lr0.001_bs16_invFalse_itr1/03_10_2024_0742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-10-03 07:42:40 2032846:2032846 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5dafe53bd5464f8ed480b32586cf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epochs_pbar:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9bf7f868e6472f91b89bcda1ed8863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_loader_pbar:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU cuda:0 (NVIDIA A100-SXM4-80GB) Memory Usage:\n",
      "  Total Memory: 79.15 GB\n",
      "  Reserved Memory: 0.04 GB\n",
      "  Allocated Memory: 0.04 GB\n",
      "  Free Memory: 0.00 GB\n",
      "epoch: 0, i: 0{'gpu_name': 'NVIDIA A100-SXM4-80GB', 'total_memory_gb': 79.1510009765625, 'reserved_memory_gb': 0.044921875, 'allocated_memory_gb': 0.04173755645751953, 'free_memory_gb': 0.0031843185424804688}\n",
      "GPU cuda:0 (NVIDIA A100-SXM4-80GB) Memory Usage:\n",
      "  Total Memory: 79.15 GB\n",
      "  Reserved Memory: 0.05 GB\n",
      "  Allocated Memory: 0.04 GB\n",
      "  Free Memory: 0.00 GB\n",
      "gpu_prints=0\n",
      "check_gpu_memory_usage(self.device):\n",
      "{'gpu_name': 'NVIDIA A100-SXM4-80GB', 'total_memory_gb': 79.1510009765625, 'reserved_memory_gb': 0.046875, 'allocated_memory_gb': 0.04352569580078125, 'free_memory_gb': 0.00334930419921875}\n",
      "GPU cuda:0 (NVIDIA A100-SXM4-80GB) Memory Usage:\n",
      "  Total Memory: 79.15 GB\n",
      "  Reserved Memory: 0.06 GB\n",
      "  Allocated Memory: 0.05 GB\n",
      "  Free Memory: 0.01 GB\n",
      "gpu_prints=1\n",
      "check_gpu_memory_usage(self.device):\n",
      "{'gpu_name': 'NVIDIA A100-SXM4-80GB', 'total_memory_gb': 79.1510009765625, 'reserved_memory_gb': 0.056640625, 'allocated_memory_gb': 0.05157327651977539, 'free_memory_gb': 0.005067348480224609}\n",
      "GPU cuda:0 (NVIDIA A100-SXM4-80GB) Memory Usage:\n",
      "  Total Memory: 79.15 GB\n",
      "  Reserved Memory: 0.08 GB\n",
      "  Allocated Memory: 0.06 GB\n",
      "  Free Memory: 0.02 GB\n",
      "gpu_prints=2\n",
      "check_gpu_memory_usage(self.device):\n",
      "{'gpu_name': 'NVIDIA A100-SXM4-80GB', 'total_memory_gb': 79.1510009765625, 'reserved_memory_gb': 0.083984375, 'allocated_memory_gb': 0.06308794021606445, 'free_memory_gb': 0.020896434783935547}\n",
      "GPU cuda:0 (NVIDIA A100-SXM4-80GB) Memory Usage:\n",
      "  Total Memory: 79.15 GB\n",
      "  Reserved Memory: 60.22 GB\n",
      "  Allocated Memory: 59.06 GB\n",
      "  Free Memory: 1.16 GB\n",
      "gpu_prints=3\n",
      "check_gpu_memory_usage(self.device):\n",
      "{'gpu_name': 'NVIDIA A100-SXM4-80GB', 'total_memory_gb': 79.1510009765625, 'reserved_memory_gb': 60.220703125, 'allocated_memory_gb': 59.06318187713623, 'free_memory_gb': 1.1575212478637695}\n",
      "GPU cuda:0 (NVIDIA A100-SXM4-80GB) Memory Usage:\n",
      "  Total Memory: 79.15 GB\n",
      "  Reserved Memory: 61.76 GB\n",
      "  Allocated Memory: 0.18 GB\n",
      "  Free Memory: 61.57 GB\n",
      "epoch: 0, i: 1{'gpu_name': 'NVIDIA A100-SXM4-80GB', 'total_memory_gb': 79.1510009765625, 'reserved_memory_gb': 61.755859375, 'allocated_memory_gb': 0.18155717849731445, 'free_memory_gb': 61.574302196502686}\n",
      "GPU cuda:0 (NVIDIA A100-SXM4-80GB) Memory Usage:\n",
      "  Total Memory: 79.15 GB\n",
      "  Reserved Memory: 61.76 GB\n",
      "  Allocated Memory: 0.14 GB\n",
      "  Free Memory: 61.62 GB\n",
      "gpu_prints=0\n",
      "check_gpu_memory_usage(self.device):\n",
      "{'gpu_name': 'NVIDIA A100-SXM4-80GB', 'total_memory_gb': 79.1510009765625, 'reserved_memory_gb': 61.755859375, 'allocated_memory_gb': 0.1408381462097168, 'free_memory_gb': 61.61502122879028}\n",
      "GPU cuda:0 (NVIDIA A100-SXM4-80GB) Memory Usage:\n",
      "  Total Memory: 79.15 GB\n",
      "  Reserved Memory: 61.76 GB\n",
      "  Allocated Memory: 0.15 GB\n",
      "  Free Memory: 61.61 GB\n",
      "gpu_prints=1\n",
      "check_gpu_memory_usage(self.device):\n",
      "{'gpu_name': 'NVIDIA A100-SXM4-80GB', 'total_memory_gb': 79.1510009765625, 'reserved_memory_gb': 61.755859375, 'allocated_memory_gb': 0.14888477325439453, 'free_memory_gb': 61.606974601745605}\n",
      "GPU cuda:0 (NVIDIA A100-SXM4-80GB) Memory Usage:\n",
      "  Total Memory: 79.15 GB\n",
      "  Reserved Memory: 61.76 GB\n",
      "  Allocated Memory: 0.15 GB\n",
      "  Free Memory: 61.60 GB\n",
      "gpu_prints=2\n",
      "check_gpu_memory_usage(self.device):\n",
      "{'gpu_name': 'NVIDIA A100-SXM4-80GB', 'total_memory_gb': 79.1510009765625, 'reserved_memory_gb': 61.755859375, 'allocated_memory_gb': 0.15246105194091797, 'free_memory_gb': 61.60339832305908}\n",
      "GPU cuda:0 (NVIDIA A100-SXM4-80GB) Memory Usage:\n",
      "  Total Memory: 79.15 GB\n",
      "  Reserved Memory: 61.76 GB\n",
      "  Allocated Memory: 59.15 GB\n",
      "  Free Memory: 2.60 GB\n",
      "gpu_prints=3\n",
      "check_gpu_memory_usage(self.device):\n",
      "{'gpu_name': 'NVIDIA A100-SXM4-80GB', 'total_memory_gb': 79.1510009765625, 'reserved_memory_gb': 61.755859375, 'allocated_memory_gb': 59.15264081954956, 'free_memory_gb': 2.6032185554504395}\n",
      "Epoch: 1 cost time: 22.1587553024292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec74d03b7f6b43ccb7a48bbb21d83dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vali_loader_pbar:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-10-03 07:54:22 2032846:2032846 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-10-03 07:54:24 2032846:2032846 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "[W collection.cpp:936] Warning: Failed to recover relationship between all profiler and kineto events: 3178869 vs. 0  reassociated. (function reassociate)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>start training : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msetting\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\n\u001b[1;32m      3\u001b[0m     activities\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m# torch.profiler.ProfilerActivity.CPU,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     with_stack\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m prof:\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ecg_forecasting/liran_project/mrdiff/exp_main.py:337\u001b[0m, in \u001b[0;36mExp_Main.train\u001b[0;34m(self, setting)\u001b[0m\n\u001b[1;32m    334\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog(log)\n\u001b[1;32m    336\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 337\u001b[0m \u001b[43mepochs_pbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_postfix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime_elapsed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtimedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melapsed_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrain_Loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVali_Loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvali_loss\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m#\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f}\".format(epoch + 1, train_steps, train_loss, vali_loss)\u001b[39;00m\n\u001b[1;32m    345\u001b[0m early_stopping(vali_loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, path)\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/tqdm/std.py:1429\u001b[0m, in \u001b[0;36mtqdm.set_postfix\u001b[0;34m(self, ordered_dict, refresh, **kwargs)\u001b[0m\n\u001b[1;32m   1426\u001b[0m         postfix[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(postfix[key])\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;66;03m# Else if it's a string, don't need to preprocess anything\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;66;03m# Stitch together to get the final postfix\u001b[39;00m\n\u001b[0;32m-> 1429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostfix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpostfix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpostfix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh:\n\u001b[1;32m   1432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh()\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/tqdm/std.py:1429\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1426\u001b[0m         postfix[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(postfix[key])\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;66;03m# Else if it's a string, don't need to preprocess anything\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;66;03m# Stitch together to get the final postfix\u001b[39;00m\n\u001b[0;32m-> 1429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostfix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m \u001b[38;5;241m+\u001b[39m postfix[key]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m   1430\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m postfix\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh:\n\u001b[1;32m   1432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh()\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "print(f'>>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        # torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ],\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as prof:\n",
    "    exp.train(setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prof' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming `prof` is your profiler object\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m key_averages \u001b[38;5;241m=\u001b[39m \u001b[43mprof\u001b[49m\u001b[38;5;241m.\u001b[39mkey_averages()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Filter to include only CUDA operations\u001b[39;00m\n\u001b[1;32m      7\u001b[0m cuda_operations \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m key_averages \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m item\u001b[38;5;241m.\u001b[39mkey]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prof' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming `prof` is your profiler object\n",
    "key_averages = prof.key_averages()\n",
    "\n",
    "# Filter to include only CUDA operations\n",
    "cuda_operations = [item for item in key_averages if 'cuda' in item.key]\n",
    "\n",
    "# Print the filtered table\n",
    "print(torch.profiler.profile.key_averages().table(cuda_operations, sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CUDA Memory Usage: -138416653312 bytes\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       cudaLaunchKernel        10.46%       14.072s        10.46%       14.072s       7.432us       0.000us         0.00%       0.000us       0.000us     -13.89 Mb     -13.89 Mb    7722.14 Gb    7718.10 Gb       1893472  \n",
      "                                    cudaLaunchKernelExC         0.61%     827.294ms         0.61%     827.294ms       9.401us       0.000us         0.00%       0.000us       0.000us           0 b           0 b    4776.58 Gb    4592.65 Gb         88000  \n",
      "                                   cudaFuncSetAttribute         0.09%     117.579ms         0.09%     117.579ms       0.659us       0.000us         0.00%       0.000us       0.000us           0 b           0 b    2028.47 Gb    2028.47 Gb        178408  \n",
      "                                        cudaMemsetAsync         0.79%        1.065s         0.79%        1.065s      43.425us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     416.16 Gb     416.16 Gb         24524  \n",
      "                                  cudaFuncGetAttributes         0.09%     125.793ms         0.09%     125.793ms      34.183us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.26 Gb      85.34 Gb          3680  \n",
      "                                 cudaDeviceGetAttribute         0.00%       3.004ms         0.00%       3.004ms       0.203us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      67.70 Gb      67.70 Gb         14782  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.03%      40.596ms         0.03%      40.596ms      11.011us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      27.84 Gb      27.84 Gb          3687  \n",
      "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.00%       3.109ms         0.00%       3.109ms       6.450us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     256.00 Kb     256.00 Kb           482  \n",
      "                                             cudaMalloc         0.07%      88.572ms         0.07%      88.572ms     191.300us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.00 Kb       2.00 Kb           463  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     443.066ms         0.31%     443.066ms       2.338us           0 b           0 b           0 b           0 b        189468  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 134.550s\n",
      "Self CUDA time total: 141.906s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.profiler\n",
    "\n",
    "# Assuming `prof` is your profiler object\n",
    "key_averages = prof.key_averages()\n",
    "\n",
    "# Total CUDA memory usage\n",
    "total_cuda_memory_usage = sum(item.self_cuda_memory_usage for item in key_averages)\n",
    "print(f\"Total CUDA Memory Usage: {total_cuda_memory_usage} bytes\")\n",
    "\n",
    "# Memory usage by function\n",
    "print(key_averages.table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       cudaLaunchKernel        10.46%       14.072s        10.46%       14.072s       7.432us       0.000us         0.00%       0.000us       0.000us     -13.89 Mb     -13.89 Mb    7722.14 Gb    7718.10 Gb       1893472  \n",
      "                                    cudaLaunchKernelExC         0.61%     827.294ms         0.61%     827.294ms       9.401us       0.000us         0.00%       0.000us       0.000us           0 b           0 b    4776.58 Gb    4592.65 Gb         88000  \n",
      "                                   cudaFuncSetAttribute         0.09%     117.579ms         0.09%     117.579ms       0.659us       0.000us         0.00%       0.000us       0.000us           0 b           0 b    2028.47 Gb    2028.47 Gb        178408  \n",
      "                                        cudaMemsetAsync         0.79%        1.065s         0.79%        1.065s      43.425us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     416.16 Gb     416.16 Gb         24524  \n",
      "                                  cudaFuncGetAttributes         0.09%     125.793ms         0.09%     125.793ms      34.183us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      97.26 Gb      85.34 Gb          3680  \n",
      "                                 cudaDeviceGetAttribute         0.00%       3.004ms         0.00%       3.004ms       0.203us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      67.70 Gb      67.70 Gb         14782  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.03%      40.596ms         0.03%      40.596ms      11.011us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      27.84 Gb      27.84 Gb          3687  \n",
      "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.00%       3.109ms         0.00%       3.109ms       6.450us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     256.00 Kb     256.00 Kb           482  \n",
      "                                             cudaMalloc         0.07%      88.572ms         0.07%      88.572ms     191.300us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.00 Kb       2.00 Kb           463  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     443.066ms         0.31%     443.066ms       2.338us           0 b           0 b           0 b           0 b        189468  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 134.550s\n",
      "Self CUDA time total: 141.906s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      | 103107 KiB |  61048 MiB |  61782 GiB |  61782 GiB |\n",
      "|       from large pool |  16640 KiB |  60893 MiB |  61708 GiB |  61708 GiB |\n",
      "|       from small pool |  86467 KiB |    212 MiB |     74 GiB |     74 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         | 103107 KiB |  61048 MiB |  61782 GiB |  61782 GiB |\n",
      "|       from large pool |  16640 KiB |  60893 MiB |  61708 GiB |  61708 GiB |\n",
      "|       from small pool |  86467 KiB |    212 MiB |     74 GiB |     74 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      | 103037 KiB |  60889 MiB |  61609 GiB |  61609 GiB |\n",
      "|       from large pool |  16640 KiB |  60734 MiB |  61535 GiB |  61535 GiB |\n",
      "|       from small pool |  86397 KiB |    212 MiB |     74 GiB |     73 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  63240 MiB |  63240 MiB |  63240 MiB |      0 B   |\n",
      "|       from large pool |  63018 MiB |  63018 MiB |  63018 MiB |      0 B   |\n",
      "|       from small pool |    222 MiB |    222 MiB |    222 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  38205 KiB | 704351 KiB |    779 GiB |    779 GiB |\n",
      "|       from large pool |   3840 KiB | 696589 KiB |    701 GiB |    701 GiB |\n",
      "|       from small pool |  34365 KiB |  47062 KiB |     77 GiB |     77 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1144    |    2668    |    2017 K  |    2016 K  |\n",
      "|       from large pool |       2    |     367    |     364 K  |     364 K  |\n",
      "|       from small pool |    1142    |    2666    |    1652 K  |    1651 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1144    |    2668    |    2017 K  |    2016 K  |\n",
      "|       from large pool |       2    |     367    |     364 K  |     364 K  |\n",
      "|       from small pool |    1142    |    2666    |    1652 K  |    1651 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     472    |     472    |     472    |       0    |\n",
      "|       from large pool |     361    |     361    |     361    |       0    |\n",
      "|       from small pool |     111    |     111    |     111    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      69    |     211    |     971 K  |     970 K  |\n",
      "|       from large pool |       2    |     161    |     135 K  |     135 K  |\n",
      "|       from small pool |      67    |      87    |     835 K  |     835 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.model_start_training_time = \"02_10_2024_135344\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>testing : DDPM_icentia11k_ftS_sl1_ll15000_pl15000_lr0.001_bs16_invFalse_itr1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "loading model\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff/DDPM_icentia11k_ftS_sl1_ll15000_pl15000_lr0.001_bs16_invFalse_itr1/02_10_2024_135344/checkpoint.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>testing : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msetting\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ecg_forecasting/liran_project/mrdiff/exp_main.py:366\u001b[0m, in \u001b[0;36mExp_Main.test\u001b[0;34m(self, setting, time_path, test, visualize)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    365\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpaths\u001b[38;5;241m.\u001b[39mcheckpoints, setting, time_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    368\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    369\u001b[0m trues \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/liranc6/ecg_forecasting/liran_project/results/icentia11k/mrDiff/DDPM_icentia11k_ftS_sl1_ll15000_pl15000_lr0.001_bs16_invFalse_itr1/02_10_2024_135344/checkpoint.pth'"
     ]
    }
   ],
   "source": [
    "print(f'>>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "exp.test(setting, test=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DDPM_icentia11k_ftS_sl1_ll1500_pl1500_lr0.001_bs8_invFalse_itr0>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading 00001: 100%|██████████| 2/2 [00:24<00:00, 12.28s/it]\n",
      "Reading 00001: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]\n",
      "Reading 00042: 100%|██████████| 3/3 [00:04<00:00,  1.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m exp \u001b[38;5;241m=\u001b[39m Exp_Main(args)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>start training : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msetting\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>testing : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msetting\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m exp\u001b[38;5;241m.\u001b[39mtest(setting, test\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 180\u001b[0m, in \u001b[0;36mExp_Main.train\u001b[0;34m(self, setting)\u001b[0m\n\u001b[1;32m    177\u001b[0m epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    178\u001b[0m results \u001b[38;5;241m=\u001b[39m Metrics(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (batch_x, batch_y, batch_x_mark, batch_y_mark) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_x\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    183\u001b[0m         batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/ecg_forecasting/liran_project/utils/dataset_loader.py:216\u001b[0m, in \u001b[0;36mSingleLeadECGDatasetCrops_mrDiff.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    212\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m h5_file[str_dataset_idx]\n\u001b[1;32m    214\u001b[0m     end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size, \u001b[38;5;28mlen\u001b[39m(dataset)) \n\u001b[0;32m--> 216\u001b[0m     to_cache \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# This is a list of windows, each window is a numpy array with shape (window_size) if no RR data,\u001b[39;00m\n\u001b[1;32m    217\u001b[0m                                             \u001b[38;5;66;03m# or (2, window_size) if there is RR data\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_to_cache(to_cache, idx, advance)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ecg/lib/python3.10/site-packages/h5py/_hl/dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(iterations):\n",
    "    # setting record of experiments\n",
    "\n",
    "    # random seed\n",
    "    \n",
    "    # setting\n",
    "    setting = f\"{model}_{dataset}_ft{features}_sl{context_len}_ll{label_len}_pl{pred_len}_lr{learning_rate}_bs{batch_size}_inv{inverse}_itr{iteration}\"\n",
    "    \n",
    "    if tag is not None:\n",
    "        setting += f\"_{tag}\"\n",
    "\n",
    "    exp = Exp_Main(args)\n",
    "\n",
    "    print(f'>>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    exp.train(setting)\n",
    "\n",
    "    print(f'>>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    exp.test(setting, test=1)\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.config.general.random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(iterations, random_seed, model, dataset, features, seq_len,\n",
    "                    label_len, pred_len, learning_rate, batch_size, inverse, tag, args):\n",
    "    mae_ = []\n",
    "    mse_ = []\n",
    "    rmse_ = []\n",
    "    mape_ = []\n",
    "    mspe_ = []\n",
    "    rse_ = []\n",
    "    corr_ = []\n",
    "    nrmse_ = []\n",
    "\n",
    "    for iter in range(iterations):\n",
    "        # setting record of experiments\n",
    "\n",
    "        # random seed\n",
    "        fix_seed = iter if iterations > 1 else random_seed\n",
    "\n",
    "        random.seed(fix_seed)\n",
    "        torch.manual_seed(fix_seed)\n",
    "        np.random.seed(fix_seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True  # Can change it to False --> default: False\n",
    "        torch.backends.cudnn.enabled = True\n",
    "\n",
    "        setting = f\"{model}_{dataset}_ft{features}_sl{seq_len}_ll{label_len}_pl{pred_len}_lr{learning_rate}_bs{batch_size}_inv{inverse}_itr{iter}\"\n",
    "        if tag is not None:\n",
    "            setting += f\"_{tag}\"\n",
    "\n",
    "        exp = Exp_Main(args)\n",
    "\n",
    "        print(f'>>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "        exp.train(setting)\n",
    "\n",
    "        print(f'>>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "        mae, mse, rmse, mape, mspe, rse, corr, nrmse = exp.test(setting, test=1)\n",
    "\n",
    "        mae_.append(mae)\n",
    "        mse_.append(mse)\n",
    "        rmse_.append(rmse)\n",
    "        mape_.append(mape)\n",
    "        mspe_.append(mspe)\n",
    "        rse_.append(rse)\n",
    "        corr_.append(corr)\n",
    "        nrmse_.append(nrmse)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print('Final mean normed: ')\n",
    "    print('> mae:{:.4f}, std:{:.4f}'.format(np.mean(mae_), np.std(mae_)))\n",
    "    print('> mse:{:.4f}, std:{:.4f}'.format(np.mean(mse_), np.std(mse_)))\n",
    "    print('> rmse:{:.4f}, std:{:.4f}'.format(np.mean(rmse_), np.std(rmse_)))\n",
    "    print('> mape:{:.4f}, std:{:.4f}'.format(np.mean(mape_), np.std(mape_)))\n",
    "    print('> rse:{:.4f}, std:{:.4f}'.format(np.mean(rse_), np.std(rse_)))\n",
    "    print('> corr:{:.4f}, std:{:.4f}'.format(np.mean(corr_), np.std(corr_)))\n",
    "    print('> nrmse:{:.4f}, std:{:.4f}'.format(np.mean(nrmse_), np.std(nrmse_)))\n",
    "\n",
    "    return {\n",
    "        'mae': (np.mean(mae_), np.std(mae_)),\n",
    "        'mse': (np.mean(mse_), np.std(mse_)),\n",
    "        'rmse': (np.mean(rmse_), np.std(rmse_)),\n",
    "        'mape': (np.mean(mape_), np.std(mape_)),\n",
    "        'rse': (np.mean(rse_), np.std(rse_)),\n",
    "        'corr': (np.mean(corr_), np.std(corr_)),\n",
    "        'nrmse': (np.mean(nrmse_), np.std(nrmse_))\n",
    "    }\n",
    "    \n",
    "results = run_experiments(iterations, random_seed, model, dataset, features, seq_len,\n",
    "                            label_len, pred_len, learning_rate, batch_size, inverse, tag, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
