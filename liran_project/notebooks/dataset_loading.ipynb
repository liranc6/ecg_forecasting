{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4249d8a7cbdd5943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T13:54:08.748293Z",
     "start_time": "2024-02-14T13:54:07.566366200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mgalileo2     \u001b[m  Thu Sep 19 19:47:20 2024  \u001b[1m\u001b[30m535.183.01\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA A40\u001b[m |\u001b[31m 18°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    0\u001b[m / \u001b[33m49140\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "import numpy as np\n",
    "import bisect\n",
    "import sys\n",
    "from pickle import FALSE\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "sys.path.append('..')  # Add the parent directory to the sys.path\n",
    "\n",
    "import utils.dataset_loader as dataset_loader\n",
    "\n",
    "! gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99f7248d570f1099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T13:54:27.446783500Z",
     "start_time": "2024-02-14T13:54:19.147073300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key='00003'\n",
      "key='00004'\n",
      "key='00005'\n",
      "key='00006'\n",
      "context.shape=(2, 135000), label.shape=(2, 15000)\n",
      "context.shape=(2, 135000), label.shape=(2, 15000)\n",
      "context.shape=(2, 135000), label.shape=(2, 15000)\n",
      "context.shape=(2, 135000), label.shape=(2, 15000)\n",
      "context.shape=(2, 135000), label.shape=(2, 15000)\n",
      "context.shape=(2, 135000), label.shape=(2, 15000)\n",
      "context.shape=(2, 135000), label.shape=(2, 15000)\n",
      "context.shape=(2, 135000), label.shape=(2, 15000)\n",
      "context.shape=(2, 135000), label.shape=(2, 15000)\n",
      "context.shape=(2, 135000), label.shape=(2, 15000)\n",
      "context.shape=(2, 135000), label.shape=(2, 15000)\n"
     ]
    }
   ],
   "source": [
    "# split the windows to fixed size context and label windows\n",
    "fs = 250\n",
    "context_window_size = 9*60*fs  # minutes * seconds * fs\n",
    "label_window_size = 1*60*fs  # minutes * seconds * fs\n",
    "window_size = context_window_size+label_window_size\n",
    "\n",
    "\n",
    "# split_pSignal_file = '/mnt/qnap/liranc6/data/with_R_beats/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes_window.h5'  # rambo\n",
    "split_pSignal_file = \"/home/liranc6/data/with_R_beats/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes/train/p0_to_p32.h5\"  # newton\n",
    "\n",
    "# Instantiate the class\n",
    "dataset = dataset_loader.SingleLeadECGDatasetCrops_SSSD(context_window_size, label_window_size, split_pSignal_file, start_patiant=3, end_patiant=6, data_with_RR=True, return_with_RR=True)\n",
    "\n",
    "# Loop over the dataset\n",
    "# print(f'{len(dataset)=}')\n",
    "for i in range(len(dataset)):\n",
    "    # print(i)\n",
    "    context, label = dataset.__getitem__(i)\n",
    "    print(f\"{context.shape=}, {label.shape=}\")\n",
    "    # Perform any assertions or checks here\n",
    "    if i >9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6187b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected column:\n",
      "[[[ 9 10 11 12]]\n",
      "\n",
      " [[21 22 23 24]]]\n",
      "\n",
      "Mean of train_data along axis 0:\n",
      "[[15. 16. 17. 18.]]\n",
      "\n",
      "Standard deviation of train_data along axis 0:\n",
      "[[6. 6. 6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a 3D array with shape (2, 3, 4)\n",
    "data = np.array([[[ 1,  2,  3,  4],\n",
    "                  [ 5,  6,  7,  8],\n",
    "                  [ 9, 10, 11, 12]],\n",
    "\n",
    "                 [[13, 14, 15, 16],\n",
    "                  [17, 18, 19, 20],\n",
    "                  [21, 22, 23, 24]]])\n",
    "\n",
    "class Args:\n",
    "    class Data:\n",
    "        target = 2\n",
    "\n",
    "args = Args()\n",
    "args.data = Args.Data()\n",
    "\n",
    "# Select the column specified by args.data.target\n",
    "data = data[:, [args.data.target]]\n",
    "\n",
    "print(\"\\nSelected column:\")\n",
    "print(data)\n",
    "\n",
    "# Calculate the mean along axis 0 (column-wise)\n",
    "train_mean = np.mean(data, axis=0)\n",
    "\n",
    "# Calculate the standard deviation along axis 0 (column-wise)\n",
    "train_std = np.std(data, axis=0)\n",
    "\n",
    "print(\"\\nMean of train_data along axis 0:\")\n",
    "print(train_mean)\n",
    "\n",
    "print(\"\\nStandard deviation of train_data along axis 0:\")\n",
    "print(train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b7fc3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_pSignal_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msplit_pSignal_file\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split_pSignal_file' is not defined"
     ]
    }
   ],
   "source": [
    "split_pSignal_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "def3e3da2f6b5c4e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading 00000:   0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading 00032: 100%|██████████| 32/32 [00:49<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=array([0.09622615, 0.08381402, 0.04730365, ..., 0.00225265, 0.0024922 ,\n",
      "       0.00269125]), std=array([0.32326099, 0.29838442, 0.23312771, ..., 0.09183643, 0.09137844,\n",
      "       0.09245316])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def _get_statistics_for_normalization(filename):\n",
    "    mean = 0\n",
    "    std = 0\n",
    "    with h5py.File(filename, 'r') as h5_file:\n",
    "        keys = list(h5_file.keys())\n",
    "        num_datasets = len(keys)\n",
    "        \n",
    "        #use tqdm to show progress bar\n",
    "        pbar_keys = tqdm(keys, total=num_datasets)\n",
    "        for key, i in enumerate(pbar_keys):\n",
    "            pbar_keys.set_description(f\"Reading {key}\")\n",
    "            data = h5_file[key][()][:, 0, :]\n",
    "            mean += np.mean(data, axis=0)\n",
    "            std += np.std(data, axis=0)\n",
    "            \n",
    "            if i >10:\n",
    "                break\n",
    "            \n",
    "        mean /= len(keys)\n",
    "        std /= len(keys)\n",
    "    return mean, std\n",
    "\n",
    "mean, std = _get_statistics_for_normalization(split_pSignal_file)\n",
    "print(f\"{mean=}, {std=}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b08ae810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape=(165, 2, 150000)\n"
     ]
    }
   ],
   "source": [
    "def show_first_n_samples(dataset, n):\n",
    "    context = dataset[:n][:]\n",
    "        \n",
    "def get_first_dataset_from_file(filename):\n",
    "    with h5py.File(filename, 'r') as h5_file:\n",
    "        key = list(h5_file.keys())[0]\n",
    "        data = h5_file[key][()]\n",
    "    return data\n",
    "\n",
    "data = get_first_dataset_from_file(split_pSignal_file)\n",
    "print(f\"{data.shape=}\")\n",
    "show_first_n_samples(data, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
