{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c94a53c3a1ee253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:14:03.909990700Z",
     "start_time": "2023-12-25T20:13:52.625856600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liranc6/miniconda3/envs/SSSD/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "CUDA extension for cauchy multiplication not found. Install by going to extensions/cauchy/ and running `python setup.py install`. This should speed up end-to-end training by 10-50%\n",
      "Falling back on slow Cauchy kernel. Install at least one of pykeops or the CUDA extension for efficiency.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "ProjectPath = os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "sys.path.append(ProjectPath)  # Add the parent directory to the sys.path\n",
    "\n",
    "import liran_project.utils.dataset_loader as dataset_loader\n",
    "\n",
    "import liran_project.train as liran_train\n",
    "from liran_project.utils.dataset_loader import SingleLeadECGDatasetCrops\n",
    "\n",
    "import liran_project.train as src_train\n",
    "import h5py\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e6e18c12a60ff8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:14:05.123678800Z",
     "start_time": "2023-12-25T20:14:03.927936100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mrambo6                    \u001b[m  Thu Feb 15 23:52:55 2024  \u001b[1m\u001b[30m525.116.04\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 65°C\u001b[m, \u001b[1m\u001b[32m 71 %\u001b[m | \u001b[1m\u001b[33m11077\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30myinong\u001b[m(\u001b[33m11074M\u001b[m)\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 36°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    2\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[2]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 34°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    3\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[3]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 34°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    3\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[4]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 30°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    3\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[5]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 33°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    3\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 31°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    3\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 33°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    3\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[8]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 32°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    3\u001b[m / \u001b[33m24576\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "! gpustat\n",
    "\n",
    "subset_data_dir = \"/mnt/qnap/liranc6/data/icentia11k-continuous-ecg_normal_sinus_subset/\" #patients 0-8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5259350125576ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:14:05.144593700Z",
     "start_time": "2023-12-25T20:14:05.126649800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append('../SSSD_main')\n",
    "\n",
    "from SSSD_main.src.utils.util import find_max_epoch, print_size, calc_diffusion_hyperparams #, training_loss\n",
    "from SSSD_main.src.utils.util import get_mask_mnr, get_mask_bm, get_mask_rm, get_mask_fm\n",
    "import SSSD_main.src.utils.util as util\n",
    "from SSSD_main.src.imputers.DiffWaveImputer import DiffWaveImputer\n",
    "from SSSD_main.src.imputers.SSSDSAImputer import SSSDSAImputer\n",
    "from SSSD_main.src.imputers.SSSDS4Imputer import SSSDS4Imputer\n",
    "\n",
    "# Import your custom dataset class here\n",
    "from liran_project.utils.dataset_loader import SingleLeadECGDatasetCrops as CustomDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca56c6c474d36303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:14:05.207417300Z",
     "start_time": "2023-12-25T20:14:05.136606700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the windows to fixed size context and label windows\n",
    "fs = 250\n",
    "context_window_size = 9*60*fs  # minutes * seconds * fs\n",
    "label_window_size = 1*60*fs  # minutes * seconds * fs\n",
    "window_size = context_window_size+label_window_size\n",
    "\n",
    "\n",
    "ten_minutes_window_file = '/mnt/qnap/liranc6/data/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes_window.h5'\n",
    "\n",
    "# Instantiate the class\n",
    "dataset = dataset_loader.SingleLeadECGDatasetCrops(context_window_size, label_window_size, ten_minutes_window_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed2dc154f57f7b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:14:23.460577600Z",
     "start_time": "2023-12-25T20:14:05.208418100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liranc6/miniconda3/envs/SSSD/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "/home/liranc6/miniconda3/envs/SSSD/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration files\n",
    "config_SSSDS4_path = os.path.join(ProjectPath, 'SSSD_main', 'src','config','config_SSSDS4.json') \n",
    "config_SSSDSA_path = os.path.join(ProjectPath, 'SSSD_main', 'src','config','config_SSSDSA.json') \n",
    "\n",
    "with open(config_SSSDS4_path) as f:\n",
    "    config_SSSDS4 = json.load(f)\n",
    "\n",
    "# with open(config_SSSDSA_path) as f:\n",
    "#     config_SSSDSA = json.load(f)\n",
    "\n",
    "# Parse necessary configurations for SSSDS4\n",
    "gen_config_SSSDS4 = config_SSSDS4['gen_config']\n",
    "train_config_SSSDS4 = config_SSSDS4['train_config']\n",
    "trainset_config_SSSDS4 = config_SSSDS4['trainset_config']\n",
    "diffusion_config_SSSDS4 = config_SSSDS4['diffusion_config']\n",
    "wavenet_config_SSSDS4 = config_SSSDS4['wavenet_config']\n",
    "\n",
    "in_channels = 65000\n",
    "wavenet_config_SSSDS4[\"in_channels\"]=in_channels\n",
    "wavenet_config_SSSDS4[\"out_channels\"]=in_channels\n",
    "\n",
    "# Parse necessary configurations for SSSDSA\n",
    "# gen_config_SSSDSA = config_SSSDSA['gen_config']\n",
    "# train_config_SSSDSA = config_SSSDSA['train_config']\n",
    "# trainset_config_SSSDSA = config_SSSDSA['trainset_config']\n",
    "# diffusion_config_SSSDSA = config_SSSDSA['diffusion_config']\n",
    "# sashimi_config_SSSDSA = config_SSSDSA['sashimi_config']\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "# Load your custom datasets\n",
    "# train_dataset_SSSDS4 = dataset\n",
    "# train_loader_SSSDS4 = DataLoader(train_dataset_SSSDS4, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# train_dataset_SSSDSA = dataset\n",
    "# train_loader_SSSDSA = DataLoader(train_dataset_SSSDSA, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Initialize your models and optimizers based on the chosen 'use_model'\n",
    "net_SSSDS4 = SSSDS4Imputer(**wavenet_config_SSSDS4).cuda()\n",
    "optimizer_SSSDS4 = torch.optim.Adam(net_SSSDS4.parameters(), lr=train_config_SSSDS4['learning_rate'])\n",
    "\n",
    "# net_SSSDSA = SSSDSAImputer(**sashimi_config_SSSDSA).cuda()\n",
    "# optimizer_SSSDSA = torch.optim.Adam(net_SSSDSA.parameters(), lr=train_config_SSSDSA['learning_rate'])\n",
    "\n",
    "# # Load checkpoints if available for both models\n",
    "# ckpt_path_SSSDS4 = os.path.join(train_config_SSSDS4[\"output_directory\"], \"T{}_beta0{}_betaT{}\".format(\n",
    "#     diffusion_config_SSSDS4[\"T\"], diffusion_config_SSSDS4[\"beta_0\"], diffusion_config_SSSDS4[\"beta_T\"]))\n",
    "# ckpt_path_SSSDSA = train_config_SSSDSA[\"output_directory\"]\n",
    "\n",
    "# args = type('Arguments', (object,), {'ckpt_iter': 'max'})  # Mock argparse arguments\n",
    "# args.ckpt_iter = 'max'\n",
    "\n",
    "# model_path_SSSDS4 = os.path.join(ckpt_path_SSSDS4, '{}.pkl'.format(args.ckpt_iter))\n",
    "# model_path_SSSDSA = os.path.join(ckpt_path_SSSDSA, '{}.pkl'.format(args.ckpt_iter))\n",
    "\n",
    "# try:\n",
    "#     checkpoint_SSSDS4 = torch.load(model_path_SSSDS4, map_location='cpu')\n",
    "#     net_SSSDS4.load_state_dict(checkpoint_SSSDS4['model_state_dict'])\n",
    "#     optimizer_SSSDS4.load_state_dict(checkpoint_SSSDS4['optimizer_state_dict'])\n",
    "#     print('Successfully loaded SSSDS4 model at iteration {}'.format(args.ckpt_iter))\n",
    "# except:\n",
    "#     print('No valid SSSDS4 model found. Initializing from scratch.')\n",
    "# try:\n",
    "#     checkpoint_SSSDSA = torch.load(model_path_SSSDSA, map_location='cpu')\n",
    "#     net_SSSDSA.load_state_dict(checkpoint_SSSDSA['model_state_dict'])\n",
    "#     optimizer_SSSDSA.load_state_dict(checkpoint_SSSDSA['optimizer_state_dict'])\n",
    "#     print('Successfully loaded SSSDSA model at iteration {}'.format(args.ckpt_iter))\n",
    "# except:\n",
    "#     print('No valid SSSDSA model found. Initializing from scratch.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f48ddf579b006a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:28:44.078783200Z",
     "start_time": "2023-12-25T20:28:44.019745200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#working train, but it load all the data in one time and causing out of storage, (works for small samples or small number of samples)\n",
    "# def train(output_directory,\n",
    "#           ckpt_iter, \n",
    "#           n_iters, \n",
    "#           iters_per_ckpt,\n",
    "#           iters_per_logging,\n",
    "#           learning_rate,\n",
    "#           only_generate_missing,\n",
    "#           masking,\n",
    "#           missing_k,\n",
    "#           net,\n",
    "#           diffusion_config,\n",
    "#           diffusion_hyperparams,\n",
    "#           trainset_config,\n",
    "#           context_size,\n",
    "#           label_size,\n",
    "#           **kwargs):\n",
    "#     \"\"\"\n",
    "#     Train Diffusion Models\n",
    "\n",
    "#     This function trains diffusion models using the given parameters.\n",
    "\n",
    "#     Parameters:\n",
    "#     output_directory (str):         Path to save model checkpoints.\n",
    "#     ckpt_iter (int or 'max'):       The pretrained checkpoint to be loaded. \n",
    "#                                     If 'max' is selected, it automatically selects the maximum iteration.\n",
    "#     n_iters (int):                  Number of iterations to train.\n",
    "#     iters_per_ckpt (int):           Number of iterations to save checkpoint. \n",
    "#                                     Default is 10k, for models with residual_channel=64 this number can be larger.\n",
    "#     iters_per_logging (int):        Number of iterations to save training log and compute validation loss. Default is 100.\n",
    "#     learning_rate (float):          Learning rate.\n",
    "#     use_model (int):                Model selection:\n",
    "#                                     0: DiffWave.\n",
    "#                                     1: SSSDSA.\n",
    "#                                     2: SSSDS4.\n",
    "#     only_generate_missing (int):    0: Apply diffusion to all samples.\n",
    "#                                     1: Only apply diffusion to missing portions of the signal.\n",
    "#     masking (str):                  Masking strategy:\n",
    "#                                     'mnr': Missing not at random.\n",
    "#                                     'bm': Blackout missing.\n",
    "#                                     'rm': Random missing.\n",
    "#     missing_k (int):                Number of missing time steps for each feature across the sample length.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # generate experiment (local) path\n",
    "#     local_path = \"T{}_beta0{}_betaT{}\".format(diffusion_config[\"T\"],\n",
    "#                                               diffusion_config[\"beta_0\"],\n",
    "#                                               diffusion_config[\"beta_T\"])\n",
    "\n",
    "#     # Get shared output_directory ready\n",
    "#     output_directory = os.path.join(output_directory, local_path)\n",
    "#     if not os.path.isdir(output_directory):\n",
    "#         os.makedirs(output_directory)\n",
    "#         os.chmod(output_directory, 0o775)\n",
    "#     print(\"output directory\", output_directory, flush=True)\n",
    "\n",
    "#     # map diffusion hyperparameters to gpu\n",
    "#     for key in diffusion_hyperparams:\n",
    "#         if key != \"T\":\n",
    "#             diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "#     # predefine model\n",
    "#     net = net.cuda()\n",
    "\n",
    "#     # define optimizer\n",
    "#     optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "#     # load checkpoint\n",
    "#     if ckpt_iter == 'max':\n",
    "#         ckpt_iter = find_max_epoch(output_directory)\n",
    "#     if ckpt_iter >= 0:\n",
    "#         try:\n",
    "#             # load checkpoint file\n",
    "#             model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n",
    "#             checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "#             # feed model dict and optimizer state\n",
    "#             net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#             if 'optimizer_state_dict' in checkpoint:\n",
    "#                 optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "#             print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n",
    "#         except:\n",
    "#             ckpt_iter = -1\n",
    "#             print('No valid checkpoint model found, start training from initialization try.')\n",
    "#     else:\n",
    "#         ckpt_iter = -1\n",
    "#         print('No valid checkpoint model found, start training from initialization.')\n",
    "\n",
    "    \n",
    "#     def load_first_dataset(file_path):\n",
    "#         print(f\"{file_path=}\")\n",
    "#         \"\"\"Load data from the first dataset of an H5 file.\"\"\"\n",
    "#         with h5py.File(file_path, 'r') as h5_file:\n",
    "#             # Check if '/00000' dataset exists\n",
    "#             if '/00000' in h5_file:\n",
    "#                 first_dataset = h5_file['/00000'][()]\n",
    "#             else:\n",
    "#                 # If '/00000' does not exist, print the name of the first dataset\n",
    "#                 first_dataset_name = list(h5_file.keys())[0]\n",
    "#                 print(f\"The '/00000' dataset does not exist. The first dataset is: {first_dataset_name}\")\n",
    "#                 first_dataset = h5_file[first_dataset_name][()]\n",
    "#         return first_dataset\n",
    "    \n",
    "#     # Specify the path to the H5 file\n",
    "#     file_path = '/mnt/qnap/liranc6/data/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes_window.h5'\n",
    "#     # Load data from the first dataset\n",
    "#     first_dataset = load_first_dataset(file_path)\n",
    "    \n",
    "#     # Convert the NumPy array to a PyTorch tensor, make it a float tensor,\n",
    "#     # and move it to the GPU if available\n",
    "#     training_data = torch.from_numpy(first_dataset).float().cuda()\n",
    "#     # print(f'{training_data.shape=}')\n",
    "#     training_data = training_data[:200, :wavenet_config_SSSDS4[\"in_channels\"]] # [:x, :y] take only the first x patients and y time steps to save memory\n",
    "#     training_data.unsqueeze_(0) #split the data to batches of size 1\n",
    "#     training_data.unsqueeze_(-1) #add a channel dimension\n",
    "    \n",
    "#     training_data = training_data.permute(0, 1, 3, 2) # the code expects the data to be in the shape of (batch_size, sequence_length, channels)\n",
    "    \n",
    "#     print(f'{training_data.shape=}')\n",
    "    \n",
    "    \n",
    "#     # ### Custom data loading and reshaping ###\n",
    "#     # training_data = np.load(trainset_config['train_data_path'])\n",
    "#     # \n",
    "#     # training_data = np.split(training_data, 160, 0) # Split the array into 160 equal sub-arrays along the first axis\n",
    "#     #                                                 # If the array cannot be evenly divided into 160 sub-arrays, a ValueError will be raised.\n",
    "#     # \n",
    "#     # training_data = np.array(training_data) # Convert the list of NumPy arrays into a single multi-dim NumPy array\n",
    "#     # training_data = torch.from_numpy(training_data).float().cuda() # Convert the NumPy array to a PyTorch tensor, make it a float tensor, and move it to the GPU if available\n",
    "#     print('Data loaded')\n",
    "\n",
    "#     # training\n",
    "#     n_iter = ckpt_iter + 1\n",
    "#     n_iters = 50\n",
    "#     pbar_outer = tqdm(total=n_iters, initial=ckpt_iter, position=0, leave=True)\n",
    "#     while n_iter < n_iters + 1:\n",
    "#         pbar_inner = tqdm(enumerate(training_data), total=len(training_data), position=1, leave=True)\n",
    "#         for i, batch in pbar_inner:\n",
    "#             print(f\"{batch.size()=}\")\n",
    "#             # print(f\"{batch.size()=}\")\n",
    "#             if n_iter % 50 == 0:\n",
    "#                 print(f'{n_iter=}')\n",
    "#             # if i % 10 == 0:\n",
    "#             #     print(f'{i=}')\n",
    "\n",
    "#             # TODO: what is the porpuse and use of the masking in here?\n",
    "#             \"\"\"\n",
    "#             copilot answer:\n",
    "#             In this code, masking is used to selectively ignore or pay attention to certain elements of the data during the training process.\n",
    "#             The mask is a tensor of the same shape as the input data, where each element of the mask corresponds to an element of the input data. \n",
    "\n",
    "#             The type of mask applied depends on the `masking` variable, which can be 'rm', 'mnr', or 'bm'. Each of these values corresponds to a\n",
    "#             different masking strategy, implemented by the `get_mask_rm`, `get_mask_mnr`, and `get_mask_bm` functions respectively.\n",
    "\n",
    "#             Once the mask is created, it is permuted, repeated across the batch size, and converted to a float tensor on the GPU with `.float().cuda()`.\n",
    "#             The `loss_mask` is the logical negation of `mask`, converted to a boolean tensor with `.bool()`. \n",
    "#             This means that wherever `mask` is True, `loss_mask` is False, and vice versa.\n",
    "\n",
    "#             The `mask` and `loss_mask` are then used in the `training_loss` function. While the exact usage depends on the implementation of\n",
    "#             `training_loss`, typically, elements of the input data where `mask` is True are ignored or treated differently during the computation\n",
    "#             of the loss. Conversely, elements where `loss_mask` is True are used normally. This allows the model to focus on certain parts of the\n",
    "#             data while ignoring others, which can be useful in many machine learning tasks.\n",
    "#             \"\"\"\n",
    "#             transposed_mask = None\n",
    "#             print(f\"{masking=}, {batch[0].size()=}\")\n",
    "#             if masking == 'rm':\n",
    "#                 transposed_mask = get_mask_rm(batch[0], missing_k)\n",
    "#             elif masking == 'mnr':\n",
    "#                 transposed_mask = get_mask_mnr(batch[0], missing_k)\n",
    "#             elif masking == 'bm':\n",
    "#                 transposed_mask = get_mask_bm(batch[0], missing_k)\n",
    "#             elif masking == 'fm':\n",
    "#                 transposed_mask = get_mask_fm(batch[0], context_size, label_size)\n",
    "\n",
    "#             assert transposed_mask is not None, \"Masking strategy not found\"\n",
    "#             mask = transposed_mask.permute(1, 0)\n",
    "#             mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n",
    "#             loss_mask = ~mask.bool()\n",
    "#             batch = batch.permute(0, 2, 1)\n",
    "\n",
    "#             assert batch.size() == mask.size() == loss_mask.size(), f'{batch.size()=} {mask.size()=} {loss_mask.size()=}'\n",
    "            \n",
    "#             # print(f\"{batch.size()=} == {mask.size()=} == {loss_mask.size()=}\")\n",
    "#             # assert transposed_mask is not None, \"Masking strategy not found\"\n",
    "#             # mask = transposed_mask.permute(0, 2, 1)  # Changed this line\n",
    "#             # mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n",
    "#             # loss_mask = ~mask.bool()\n",
    "#             # batch = batch.permute(0, 2, 1)\n",
    "#             # \n",
    "#             # assert batch.size() == mask.size() == loss_mask.size(), f'{batch.size()=} {mask.size()=} {loss_mask.size()=}'\n",
    "\n",
    "#             # back-propagation\n",
    "#             optimizer.zero_grad()\n",
    "#             X = batch, batch, mask, loss_mask #audio = X[0], cond = X[1], mask = X[2], loss_mask = X[3]\n",
    "            \n",
    "#             loss = src_train.training_loss(net, nn.MSELoss(), X, diffusion_hyperparams,\n",
    "#                                  only_generate_missing=only_generate_missing)\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if n_iter % iters_per_logging == 0:\n",
    "#                 print(\"iteration: {} \\tloss: {}\".format(n_iter, loss.item()))\n",
    "\n",
    "#             # save checkpoint\n",
    "#             if n_iter > 0 and n_iter % iters_per_ckpt == 0:\n",
    "#                 checkpoint_name = '{}.pkl'.format(n_iter)\n",
    "#                 torch.save({'model_state_dict': net.state_dict(),\n",
    "#                             'optimizer_state_dict': optimizer.state_dict()},\n",
    "#                            os.path.join(output_directory, checkpoint_name))\n",
    "#                 print('model at iteration %s is saved' % n_iter)\n",
    "\n",
    "#             n_iter += 1\n",
    "#             # pbar_inner.set_description(f'Processing batch {i+1}')\n",
    "#             # pbar_inner.update()\n",
    "#         pbar_outer.update()\n",
    "#     pbar_outer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c94652695b25f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:28:44.725747500Z",
     "start_time": "2023-12-25T20:28:44.644148300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using dataset and dataloader, code with chatGPT\n",
    "\n",
    "# def train(output_directory,\n",
    "#           ckpt_iter,\n",
    "#           n_iters,\n",
    "#           iters_per_ckpt,\n",
    "#           iters_per_logging,\n",
    "#           learning_rate,\n",
    "#           only_generate_missing,\n",
    "#           masking,\n",
    "#           missing_k,\n",
    "#           net,\n",
    "#           diffusion_config,\n",
    "#           diffusion_hyperparams,\n",
    "#           trainset_config,\n",
    "#           context_size,\n",
    "#           label_size,\n",
    "#           **kwargs):\n",
    "#     # Generate experiment (local) path\n",
    "#     local_path = \"T{}_beta0{}_betaT{}\".format(diffusion_config[\"T\"],\n",
    "#                                               diffusion_config[\"beta_0\"],\n",
    "#                                               diffusion_config[\"beta_T\"])\n",
    "\n",
    "#     # Get shared output_directory ready\n",
    "#     output_directory = os.path.join(output_directory, local_path)\n",
    "#     if not os.path.isdir(output_directory):\n",
    "#         os.makedirs(output_directory)\n",
    "#         os.chmod(output_directory, 0o775)\n",
    "#     print(\"output directory\", output_directory, flush=True)\n",
    "\n",
    "#     # Map diffusion hyperparameters to GPU\n",
    "#     for key in diffusion_hyperparams:\n",
    "#         if key != \"T\":\n",
    "#             diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "#     # Predefine model\n",
    "#     net = net.cuda()\n",
    "\n",
    "#     # Define optimizer\n",
    "#     optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "#     # Load checkpoint\n",
    "#     if ckpt_iter == 'max':\n",
    "#         ckpt_iter = find_max_epoch(output_directory)\n",
    "#     if ckpt_iter >= 0:\n",
    "#         try:\n",
    "#             # Load checkpoint file\n",
    "#             model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n",
    "#             checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "#             # Feed model dict and optimizer state\n",
    "#             net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#             if 'optimizer_state_dict' in checkpoint:\n",
    "#                 optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "#             print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n",
    "#         except:\n",
    "#             ckpt_iter = -1\n",
    "#             print('No valid checkpoint model found, start training from initialization try.')\n",
    "#     else:\n",
    "#         ckpt_iter = -1\n",
    "#         print('No valid checkpoint model found, start training from initialization.')\n",
    "\n",
    "#     # Create an instance of your custom dataset\n",
    "#     h5_filename = '/mnt/qnap/liranc6/data/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes_window.h5'\n",
    "#     dataset = SingleLeadECGDatasetCrops(context_size, label_size, h5_filename)\n",
    "\n",
    "#     print(f\"{len(dataset)=}\")\n",
    "#     # Use DataLoader to handle batching and shuffling\n",
    "#     batch_size = 1  # Adjust the batch size as per your requirements\n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#     n_iter = ckpt_iter + 1\n",
    "#     pbar_outer = tqdm(total=n_iters, initial=ckpt_iter, position=0, leave=True)\n",
    "\n",
    "#     while n_iter < n_iters + 1:\n",
    "#         pbar_inner = tqdm(enumerate(dataloader), total=len(dataloader), position=1, leave=True)\n",
    "\n",
    "#         for i, batch in pbar_inner:\n",
    "#             x, y = batch\n",
    "#             x, y = x.cuda(), y.cuda()\n",
    "\n",
    "#             # Your existing code for masking and preprocessing goes here\n",
    "\n",
    "#             # Back-propagation\n",
    "#             optimizer.zero_grad()\n",
    "#             X = x, y, mask, loss_mask  # Assuming X[0] is input, X[1] is target, X[2] is mask, and X[3] is loss_mask\n",
    "\n",
    "#             loss = src_train.training_loss(net, nn.MSELoss(), X, diffusion_hyperparams,\n",
    "#                                            only_generate_missing=only_generate_missing)\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if n_iter % iters_per_logging == 0:\n",
    "#                 print(\"iteration: {} \\tloss: {}\".format(n_iter, loss.item()))\n",
    "\n",
    "#             # Save checkpoint\n",
    "#             if n_iter > 0 and n_iter % iters_per_ckpt == 0:\n",
    "#                 checkpoint_name = '{}.pkl'.format(n_iter)\n",
    "#                 torch.save({'model_state_dict': net.state_dict(),\n",
    "#                             'optimizer_state_dict': optimizer.state_dict()},\n",
    "#                            os.path.join(output_directory, checkpoint_name))\n",
    "#                 print('model at iteration %s is saved' % n_iter)\n",
    "\n",
    "#             n_iter += 1\n",
    "\n",
    "#         pbar_outer.update()\n",
    "\n",
    "#     pbar_outer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d8af0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working train, tries to use my castume dataset\n",
    "#working for in_channels =65000 (which is a bit over 4.3 minuts in total, context+pred)\n",
    "#I interapted bc it has 788 samples and I didnt want to wait, next task will be to check if I can run it fully to the end.\n",
    "def train(output_directory,\n",
    "          ckpt_iter, \n",
    "          n_iters, \n",
    "          iters_per_ckpt,\n",
    "          iters_per_logging,\n",
    "          learning_rate,\n",
    "          only_generate_missing,\n",
    "          masking,\n",
    "          missing_k,\n",
    "          net,\n",
    "          diffusion_config,\n",
    "          diffusion_hyperparams,\n",
    "          trainset_config,\n",
    "          context_size,\n",
    "          label_size,\n",
    "          **kwargs):\n",
    "    \"\"\"\n",
    "    Train Diffusion Models\n",
    "\n",
    "    This function trains diffusion models using the given parameters.\n",
    "\n",
    "    Parameters:\n",
    "    output_directory (str):         Path to save model checkpoints.\n",
    "    ckpt_iter (int or 'max'):       The pretrained checkpoint to be loaded. \n",
    "                                    If 'max' is selected, it automatically selects the maximum iteration.\n",
    "    n_iters (int):                  Number of iterations to train.\n",
    "    iters_per_ckpt (int):           Number of iterations to save checkpoint. \n",
    "                                    Default is 10k, for models with residual_channel=64 this number can be larger.\n",
    "    iters_per_logging (int):        Number of iterations to save training log and compute validation loss. Default is 100.\n",
    "    learning_rate (float):          Learning rate.\n",
    "    use_model (int):                Model selection:\n",
    "                                    0: DiffWave.\n",
    "                                    1: SSSDSA.\n",
    "                                    2: SSSDS4.\n",
    "    only_generate_missing (int):    0: Apply diffusion to all samples.\n",
    "                                    1: Only apply diffusion to missing portions of the signal.\n",
    "    masking (str):                  Masking strategy:\n",
    "                                    'mnr': Missing not at random.\n",
    "                                    'bm': Blackout missing.\n",
    "                                    'rm': Random missing.\n",
    "    missing_k (int):                Number of missing time steps for each feature across the sample length.\n",
    "    \"\"\"\n",
    "\n",
    "    # generate experiment (local) path\n",
    "    local_path = \"T{}_beta0{}_betaT{}\".format(diffusion_config[\"T\"],\n",
    "                                              diffusion_config[\"beta_0\"],\n",
    "                                              diffusion_config[\"beta_T\"])\n",
    "\n",
    "    # Get shared output_directory ready\n",
    "    output_directory = os.path.join(output_directory, local_path)\n",
    "    if not os.path.isdir(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "        os.chmod(output_directory, 0o775)\n",
    "    print(\"output directory\", output_directory, flush=True)\n",
    "\n",
    "    # map diffusion hyperparameters to gpu\n",
    "    for key in diffusion_hyperparams:\n",
    "        if key != \"T\":\n",
    "            diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "    # predefine model\n",
    "    net = net.cuda()\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # load checkpoint\n",
    "    if ckpt_iter == 'max':\n",
    "        ckpt_iter = find_max_epoch(output_directory)\n",
    "    if ckpt_iter >= 0:\n",
    "        try:\n",
    "            # load checkpoint file\n",
    "            model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n",
    "            checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "            # feed model dict and optimizer state\n",
    "            net.load_state_dict(checkpoint['model_state_dict'])\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "            print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n",
    "        except:\n",
    "            ckpt_iter = -1\n",
    "            print('No valid checkpoint model found, start training from initialization try.')\n",
    "    else:\n",
    "        ckpt_iter = -1\n",
    "        print('No valid checkpoint model found, start training from initialization.')\n",
    "\n",
    "    \n",
    "    def load_first_dataset(file_path):\n",
    "        print(f\"{file_path=}\")\n",
    "        \"\"\"Load data from the first dataset of an H5 file.\"\"\"\n",
    "        with h5py.File(file_path, 'r') as h5_file:\n",
    "            # Check if '/00000' dataset exists\n",
    "            if '/00000' in h5_file:\n",
    "                first_dataset = h5_file['/00000'][()]\n",
    "            else:\n",
    "                # If '/00000' does not exist, print the name of the first dataset\n",
    "                first_dataset_name = list(h5_file.keys())[0]\n",
    "                print(f\"The '/00000' dataset does not exist. The first dataset is: {first_dataset_name}\")\n",
    "                first_dataset = h5_file[first_dataset_name][()]\n",
    "        return first_dataset\n",
    "    \n",
    "    # Specify the path to the H5 file\n",
    "    file_path = '/mnt/qnap/liranc6/data/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes_window.h5'\n",
    "    # Load data from the first dataset\n",
    "    dataset = SingleLeadECGDatasetCrops(context_size, label_size, file_path)\n",
    "    # Use DataLoader to handle batching and shuffling\n",
    "    batch_size = 1  \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # # Convert the NumPy array to a PyTorch tensor, make it a float tensor,\n",
    "    # # and move it to the GPU if available\n",
    "    # training_data = torch.from_numpy(first_dataset).float().cuda()\n",
    "    # # print(f'{training_data.shape=}')\n",
    "    # training_data = training_data[:200, :wavenet_config_SSSDS4[\"in_channels\"]] # [:x, :y] take only the first x patients and y time steps to save memory\n",
    "    # training_data.unsqueeze_(0) #split the data to batches of size 1\n",
    "    # training_data.unsqueeze_(-1) #add a channel dimension\n",
    "    \n",
    "    # training_data = training_data.permute(0, 1, 3, 2) # the code expects the data to be in the shape of (batch_size, sequence_length, channels)\n",
    "    \n",
    "    # print(f'{training_data.shape=}')\n",
    "    \n",
    "\n",
    "    # training\n",
    "    n_iter = ckpt_iter + 1\n",
    "    n_iters = 3\n",
    "    pbar_outer = tqdm(total=n_iters, initial=ckpt_iter, position=0, leave=True)\n",
    "    # with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    while n_iter < n_iters + 1:\n",
    "        pbar_inner = tqdm(enumerate(dataloader), total=len(dataloader), position=1, leave=True)\n",
    "        for i, batch in pbar_inner:\n",
    "\n",
    "            # Concatenate tensors along the last dimension\n",
    "            concatenated_batch = torch.cat(batch, dim=-1)\n",
    "\n",
    "            # Reshape to the desired shape\n",
    "            batch = concatenated_batch.unsqueeze(0)[:, :, 0-in_channels:].float().to(device)\n",
    "\n",
    "            # print(f\"{batch=}\\n\"\n",
    "            #     f\"{len(batch)=}\\n\"\n",
    "            #     f\"{batch.size()=}\")\n",
    "\n",
    "\n",
    "            if n_iter % 50 == 0:\n",
    "                print(f'{n_iter=}')\n",
    "            # if i % 10 == 0:\n",
    "            #     print(f'{i=}')\n",
    "\n",
    "            # TODO: what is the porpuse and use of the masking in here?\n",
    "            \"\"\"\n",
    "            copilot answer:\n",
    "            In this code, masking is used to selectively ignore or pay attention to certain elements of the data during the training process.\n",
    "            The mask is a tensor of the same shape as the input data, where each element of the mask corresponds to an element of the input data. \n",
    "\n",
    "            The type of mask applied depends on the `masking` variable, which can be 'rm', 'mnr', or 'bm'. Each of these values corresponds to a\n",
    "            different masking strategy, implemented by the `get_mask_rm`, `get_mask_mnr`, and `get_mask_bm` functions respectively.\n",
    "\n",
    "            Once the mask is created, it is permuted, repeated across the batch size, and converted to a float tensor on the GPU with `.float().cuda()`.\n",
    "            The `loss_mask` is the logical negation of `mask`, converted to a boolean tensor with `.bool()`. \n",
    "            This means that wherever `mask` is True, `loss_mask` is False, and vice versa.\n",
    "\n",
    "            The `mask` and `loss_mask` are then used in the `training_loss` function. While the exact usage depends on the implementation of\n",
    "            `training_loss`, typically, elements of the input data where `mask` is True are ignored or treated differently during the computation\n",
    "            of the loss. Conversely, elements where `loss_mask` is True are used normally. This allows the model to focus on certain parts of the\n",
    "            data while ignoring others, which can be useful in many machine learning tasks.\n",
    "            \"\"\"\n",
    "            transposed_mask = None\n",
    "            if masking == 'rm':\n",
    "                transposed_mask = get_mask_rm(batch[0], missing_k) # batch[0] is the first sample\n",
    "            elif masking == 'mnr':\n",
    "                transposed_mask = get_mask_mnr(batch[0], missing_k)\n",
    "            elif masking == 'bm':\n",
    "                transposed_mask = get_mask_bm(batch[0], missing_k)\n",
    "            elif masking == 'fm':\n",
    "                transposed_mask = get_mask_fm(batch[0], context_size, label_size)\n",
    "\n",
    "            assert transposed_mask is not None, \"Masking strategy not found\"\n",
    "            mask = transposed_mask.permute(1, 0)\n",
    "            mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n",
    "            loss_mask = ~mask.bool()\n",
    "            batch = batch.permute(0, 2, 1)\n",
    "\n",
    "            assert batch.size() == mask.size() == loss_mask.size(), f'{batch.size()=} {mask.size()=} {loss_mask.size()=}'\n",
    "            \n",
    "            print(f\"{batch.size()=} == {mask.size()=} == {loss_mask.size()=}\")\n",
    "            # assert transposed_mask is not None, \"Masking strategy not found\"\n",
    "            # mask = transposed_mask.permute(0, 2, 1)  # Changed this line\n",
    "            # mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n",
    "            # loss_mask = ~mask.bool()\n",
    "            # batch = batch.permute(0, 2, 1)\n",
    "            # \n",
    "            # assert batch.size() == mask.size() == loss_mask.size(), f'{batch.size()=} {mask.size()=} {loss_mask.size()=}'\n",
    "\n",
    "            # back-propagation\n",
    "            optimizer.zero_grad()\n",
    "            X = batch, batch, mask, loss_mask #audio = X[0], cond = X[1], mask = X[2], loss_mask = X[3]\n",
    "            \n",
    "            loss = src_train.training_loss(net, nn.MSELoss(), X, diffusion_hyperparams,\n",
    "                                only_generate_missing=only_generate_missing)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if n_iter % iters_per_logging == 0:\n",
    "                print(\"iteration: {} \\tloss: {}\".format(n_iter, loss.item()))\n",
    "\n",
    "            # save checkpoint\n",
    "            if n_iter > 0 and n_iter % iters_per_ckpt == 0:\n",
    "                checkpoint_name = '{}.pkl'.format(n_iter)\n",
    "                torch.save({'model_state_dict': net.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict()},\n",
    "                        os.path.join(output_directory, checkpoint_name))\n",
    "                print('model at iteration %s is saved' % n_iter)\n",
    "\n",
    "            n_iter += 1\n",
    "            pbar_inner.set_description(f'Processing batch {i+1}')\n",
    "            pbar_inner.update()\n",
    "        pbar_outer.update()\n",
    "    pbar_outer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f443654cd37673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:29:04.639885300Z",
     "start_time": "2023-12-25T20:28:45.049652200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output directory ./results/mujoco/90/T200_beta00.0001_betaT0.02\n",
      "No valid checkpoint model found, start training from initialization try.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liranc6/miniconda3/envs/SSSD/lib/python3.9/site-packages/tqdm/std.py:636: TqdmWarning: clamping frac to range [0, 1]\n",
      "  full_bar = Bar(frac,\n",
      "-33%|          | -1/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 \tloss: 1.0016721487045288\n",
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter=50\n",
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.size()=torch.Size([1, 65000, 1]) == mask.size()=torch.Size([1, 65000, 1]) == loss_mask.size()=torch.Size([1, 65000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 73:   9%|▉         | 73/788 [01:57<19:10,  1.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mglobal\u001b[39;00m diffusion_hyperparams\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m diffusion_hyperparams \u001b[39m=\u001b[39m calc_diffusion_hyperparams(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdiffusion_config_SSSDS4)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m train(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     output_directory\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m\"\u001b[39;49m\u001b[39moutput_directory\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     ckpt_iter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     n_iters\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39mn_iters\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     iters_per_ckpt\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39miters_per_ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     iters_per_logging\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39miters_per_logging\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     only_generate_missing\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39monly_generate_missing\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     masking\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39mmasking\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     missing_k\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39mmissing_k\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     net\u001b[39m=\u001b[39;49mnet_SSSDS4,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     diffusion_config\u001b[39m=\u001b[39;49mdiffusion_config_SSSDS4,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     diffusion_hyperparams \u001b[39m=\u001b[39;49m calc_diffusion_hyperparams(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdiffusion_config_SSSDS4),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     trainset_config \u001b[39m=\u001b[39;49m trainset_config_SSSDS4,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     context_size\u001b[39m=\u001b[39;49mcontext_window_size,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     label_size\u001b[39m=\u001b[39;49mlabel_window_size\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     )\n",
      "\u001b[1;32m/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=197'>198</a>\u001b[0m X \u001b[39m=\u001b[39m batch, batch, mask, loss_mask \u001b[39m#audio = X[0], cond = X[1], mask = X[2], loss_mask = X[3]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=199'>200</a>\u001b[0m loss \u001b[39m=\u001b[39m src_train\u001b[39m.\u001b[39mtraining_loss(net, nn\u001b[39m.\u001b[39mMSELoss(), X, diffusion_hyperparams,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=200'>201</a>\u001b[0m                     only_generate_missing\u001b[39m=\u001b[39monly_generate_missing)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=202'>203</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=203'>204</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=205'>206</a>\u001b[0m \u001b[39mif\u001b[39;00m n_iter \u001b[39m%\u001b[39m iters_per_logging \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/SSSD/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/SSSD/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global diffusion_hyperparams\n",
    "diffusion_hyperparams = calc_diffusion_hyperparams(**diffusion_config_SSSDS4)\n",
    "\n",
    "train(\n",
    "    output_directory=train_config_SSSDS4[\"output_directory\"],\n",
    "    ckpt_iter='max',\n",
    "    n_iters=train_config_SSSDS4['n_iters'],\n",
    "    iters_per_ckpt=train_config_SSSDS4['iters_per_ckpt'],\n",
    "    iters_per_logging=train_config_SSSDS4['iters_per_logging'],\n",
    "    learning_rate=train_config_SSSDS4['learning_rate'],\n",
    "    only_generate_missing=train_config_SSSDS4['only_generate_missing'],\n",
    "    masking=train_config_SSSDS4['masking'],\n",
    "    missing_k=train_config_SSSDS4['missing_k'],\n",
    "    net=net_SSSDS4,\n",
    "    diffusion_config=diffusion_config_SSSDS4,\n",
    "    diffusion_hyperparams = calc_diffusion_hyperparams(**diffusion_config_SSSDS4),\n",
    "    trainset_config = trainset_config_SSSDS4,\n",
    "    context_size=context_window_size,\n",
    "    label_size=label_window_size\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f6569d653e280",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-25T20:15:36.528554100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train(train_loader_SSSDS4, net_SSSDS4, optimizer_SSSDS4, calc_diffusion_hyperparams(**diffusion_config_SSSDS4),\n",
    "      train_config_SSSDS4, iters_per_logging=train_config_SSSDS4['iters_per_logging'],\n",
    "      iters_per_ckpt=train_config_SSSDS4['iters_per_ckpt'],\n",
    "      output_directory=train_config_SSSDS4[\"output_directory\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e9bd9dc963ac1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-25T20:15:36.530544300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Test the train function for SSSDSA\n",
    "train(train_loader_SSSDSA, net_SSSDSA, optimizer_SSSDSA, calc_diffusion_hyperparams(**diffusion_config_SSSDSA),\n",
    "      train_config_SSSDSA, iters_per_logging=trainset_config_SSSDSA['iters_per_logging'],\n",
    "      iters_per_ckpt=trainset_config_SSSDSA['iters_per_ckpt'],\n",
    "      output_directory=trainset_config_SSSDSA[\"output_directory\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2862732f813c6d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-25T20:15:36.571995200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
