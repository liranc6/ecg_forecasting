{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c94a53c3a1ee253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:14:03.909990700Z",
     "start_time": "2023-12-25T20:13:52.625856600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension for cauchy multiplication not found. Install by going to extensions/cauchy/ and running `python setup.py install`. This should speed up end-to-end training by 10-50%\n",
      "Falling back on slow Cauchy kernel. Install at least one of pykeops or the CUDA extension for efficiency.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "ProjectPath = os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "sys.path.append(ProjectPath)  # Add the parent directory to the sys.path\n",
    "\n",
    "import liran_project.utils.dataset_loader as dataset_loader\n",
    "\n",
    "import liran_project.train as liran_train\n",
    "from liran_project.utils.dataset_loader import SingleLeadECGDatasetCrops\n",
    "\n",
    "import liran_project.train as src_train\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a437114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e6e18c12a60ff8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:14:05.123678800Z",
     "start_time": "2023-12-25T20:14:03.927936100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad6b554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mrambo6                    \u001b[m  Wed Mar 13 09:30:20 2024  \u001b[1m\u001b[30m525.147.05\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 49°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m18751\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30myinong\u001b[m(\u001b[33m18748M\u001b[m)\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 52°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m18707\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30myinong\u001b[m(\u001b[33m18704M\u001b[m)\n",
      "\u001b[36m[2]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 52°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m18751\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30myinong\u001b[m(\u001b[33m18748M\u001b[m)\n",
      "\u001b[36m[3]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 45°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m18707\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30myinong\u001b[m(\u001b[33m18704M\u001b[m)\n",
      "\u001b[36m[4]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 24°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    3\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[5]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 25°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    3\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 25°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    3\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 24°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    3\u001b[m / \u001b[33m24576\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "! gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec8f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data_dir = \"/mnt/qnap/liranc6/data/icentia11k-continuous-ecg_normal_sinus_subset/\" #patients 0-8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5259350125576ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:14:05.144593700Z",
     "start_time": "2023-12-25T20:14:05.126649800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append('../SSSD_main')\n",
    "\n",
    "from SSSD_main.src.utils.util import find_max_epoch, print_size, calc_diffusion_hyperparams #, training_loss\n",
    "from SSSD_main.src.utils.util import get_mask_mnr, get_mask_bm, get_mask_rm, get_mask_pred\n",
    "import SSSD_main.src.utils.util as util\n",
    "from SSSD_main.src.imputers.DiffWaveImputer import DiffWaveImputer\n",
    "from SSSD_main.src.imputers.SSSDSAImputer import SSSDSAImputer\n",
    "from SSSD_main.src.imputers.SSSDS4Imputer import SSSDS4Imputer\n",
    "\n",
    "# Import your custom dataset class here\n",
    "from liran_project.utils.dataset_loader import SingleLeadECGDatasetCrops as CustomDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca56c6c474d36303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:14:05.207417300Z",
     "start_time": "2023-12-25T20:14:05.136606700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels=60000\n",
      "batch_size=16\n"
     ]
    }
   ],
   "source": [
    "# split the windows to fixed size context and label windows\n",
    "fs = 250\n",
    "context_num_minutes = 0\n",
    "context_num_secondes = 8\n",
    "label_window_num_minutes = 0\n",
    "label_window_num_secondes = 2\n",
    "\n",
    "context_window_size = (context_num_minutes*60 + context_num_secondes) * fs  # minutes * seconds * fs\n",
    "label_window_size = (label_window_num_minutes*60 + label_window_num_secondes) * fs  # minutes * seconds * fs\n",
    "window_size = context_window_size+label_window_size\n",
    "\n",
    "\n",
    "\n",
    "ten_minutes_window_file = '/mnt/qnap/liranc6/data/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes_window.h5'\n",
    "\n",
    "# Instantiate the class\n",
    "dataset = dataset_loader.SingleLeadECGDatasetCrops(context_window_size, label_window_size, ten_minutes_window_file)\n",
    "max_len = 65000\n",
    "in_channels = min(max_len, window_size)\n",
    "print(f\"{in_channels=}\")\n",
    "batch_size = 16\n",
    "print(f\"{batch_size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed2dc154f57f7b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:14:23.460577600Z",
     "start_time": "2023-12-25T20:14:05.208418100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liranc6/miniconda3/envs/SSSD/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liranc6/miniconda3/envs/SSSD/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n",
      "2*self.res_channels=200 s4_lmax=100 s4_d_state=64 s4_dropout=0.0 s4_bidirectional=1 s4_layernorm=1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m wavenet_config_SSSDS4[\u001b[39m\"\u001b[39m\u001b[39mout_channels\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39min_channels\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# # Parse necessary configurations for SSSDSA\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# gen_config_SSSDSA = config_SSSDSA['gen_config']\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# train_config_SSSDSA = config_SSSDSA['train_config']\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Initialize your models and optimizers based on the chosen 'use_model'\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m net_SSSDS4 \u001b[39m=\u001b[39m SSSDS4Imputer(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mwavenet_config_SSSDS4)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m optimizer_SSSDS4 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(net_SSSDS4\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mtrain_config_SSSDS4[\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# net_SSSDSA = SSSDSAImputer(**sashimi_config_SSSDSA).cuda()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# optimizer_SSSDSA = torch.optim.Adam(net_SSSDSA.parameters(), lr=train_config_SSSDSA['learning_rate'])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# except:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m#     print('No valid SSSDSA model found. Initializing from scratch.')\u001b[39;00m\n",
      "File \u001b[0;32m~/ecg/ecg_forecasting/SSSD_main/src/imputers/SSSDS4Imputer.py:183\u001b[0m, in \u001b[0;36mSSSDS4Imputer.__init__\u001b[0;34m(self, in_channels, res_channels, skip_channels, out_channels, num_res_layers, diffusion_step_embed_dim_in, diffusion_step_embed_dim_mid, diffusion_step_embed_dim_out, s4_lmax, s4_d_state, s4_dropout, s4_bidirectional, s4_layernorm)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39msuper\u001b[39m(SSSDS4Imputer, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m    181\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_conv \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(Conv(in_channels, res_channels, kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), nn\u001b[39m.\u001b[39mReLU())\n\u001b[0;32m--> 183\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresidual_layer \u001b[39m=\u001b[39m Residual_group(res_channels\u001b[39m=\u001b[39;49mres_channels,\n\u001b[1;32m    184\u001b[0m                                      skip_channels\u001b[39m=\u001b[39;49mskip_channels,\n\u001b[1;32m    185\u001b[0m                                      num_res_layers\u001b[39m=\u001b[39;49mnum_res_layers,\n\u001b[1;32m    186\u001b[0m                                      diffusion_step_embed_dim_in\u001b[39m=\u001b[39;49mdiffusion_step_embed_dim_in,\n\u001b[1;32m    187\u001b[0m                                      diffusion_step_embed_dim_mid\u001b[39m=\u001b[39;49mdiffusion_step_embed_dim_mid,\n\u001b[1;32m    188\u001b[0m                                      diffusion_step_embed_dim_out\u001b[39m=\u001b[39;49mdiffusion_step_embed_dim_out,\n\u001b[1;32m    189\u001b[0m                                      in_channels\u001b[39m=\u001b[39;49min_channels,\n\u001b[1;32m    190\u001b[0m                                      s4_lmax\u001b[39m=\u001b[39;49ms4_lmax,\n\u001b[1;32m    191\u001b[0m                                      s4_d_state\u001b[39m=\u001b[39;49ms4_d_state,\n\u001b[1;32m    192\u001b[0m                                      s4_dropout\u001b[39m=\u001b[39;49ms4_dropout,\n\u001b[1;32m    193\u001b[0m                                      s4_bidirectional\u001b[39m=\u001b[39;49ms4_bidirectional,\n\u001b[1;32m    194\u001b[0m                                      s4_layernorm\u001b[39m=\u001b[39;49ms4_layernorm)\n\u001b[1;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_conv \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(Conv(skip_channels, skip_channels, kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    197\u001b[0m                                 nn\u001b[39m.\u001b[39mReLU(),\n\u001b[1;32m    198\u001b[0m                                 ZeroConv1d(skip_channels, out_channels))\n",
      "File \u001b[0;32m~/ecg/ecg_forecasting/SSSD_main/src/imputers/SSSDS4Imputer.py:129\u001b[0m, in \u001b[0;36mResidual_group.__init__\u001b[0;34m(self, res_channels, skip_channels, num_res_layers, diffusion_step_embed_dim_in, diffusion_step_embed_dim_mid, diffusion_step_embed_dim_out, in_channels, s4_lmax, s4_d_state, s4_dropout, s4_bidirectional, s4_layernorm)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresidual_blocks \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList()\n\u001b[1;32m    128\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_res_layers):\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresidual_blocks\u001b[39m.\u001b[39mappend(Residual_block(res_channels, skip_channels,\n\u001b[1;32m    130\u001b[0m                                                diffusion_step_embed_dim_out\u001b[39m=\u001b[39;49mdiffusion_step_embed_dim_out,\n\u001b[1;32m    131\u001b[0m                                                in_channels\u001b[39m=\u001b[39;49min_channels,\n\u001b[1;32m    132\u001b[0m                                                s4_lmax\u001b[39m=\u001b[39;49ms4_lmax,\n\u001b[1;32m    133\u001b[0m                                                s4_d_state\u001b[39m=\u001b[39;49ms4_d_state,\n\u001b[1;32m    134\u001b[0m                                                s4_dropout\u001b[39m=\u001b[39;49ms4_dropout,\n\u001b[1;32m    135\u001b[0m                                                s4_bidirectional\u001b[39m=\u001b[39;49ms4_bidirectional,\n\u001b[1;32m    136\u001b[0m                                                s4_layernorm\u001b[39m=\u001b[39;49ms4_layernorm))\n",
      "File \u001b[0;32m~/ecg/ecg_forecasting/SSSD_main/src/imputers/SSSDS4Imputer.py:64\u001b[0m, in \u001b[0;36mResidual_block.__init__\u001b[0;34m(self, res_channels, skip_channels, diffusion_step_embed_dim_out, in_channels, s4_lmax, s4_d_state, s4_dropout, s4_bidirectional, s4_layernorm)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mS41 \u001b[39m=\u001b[39m S4Layer(features\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_channels,\n\u001b[1;32m     56\u001b[0m                    lmax\u001b[39m=\u001b[39ms4_lmax,\n\u001b[1;32m     57\u001b[0m                    N\u001b[39m=\u001b[39ms4_d_state,\n\u001b[1;32m     58\u001b[0m                    dropout\u001b[39m=\u001b[39ms4_dropout,\n\u001b[1;32m     59\u001b[0m                    bidirectional\u001b[39m=\u001b[39ms4_bidirectional,\n\u001b[1;32m     60\u001b[0m                    layer_norm\u001b[39m=\u001b[39ms4_layernorm)\n\u001b[1;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_layer \u001b[39m=\u001b[39m Conv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_channels, \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_channels, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mS42 \u001b[39m=\u001b[39m S4Layer(features\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mres_channels,\n\u001b[1;32m     65\u001b[0m                    lmax\u001b[39m=\u001b[39;49ms4_lmax,\n\u001b[1;32m     66\u001b[0m                    N\u001b[39m=\u001b[39;49ms4_d_state,\n\u001b[1;32m     67\u001b[0m                    dropout\u001b[39m=\u001b[39;49ms4_dropout,\n\u001b[1;32m     68\u001b[0m                    bidirectional\u001b[39m=\u001b[39;49ms4_bidirectional,\n\u001b[1;32m     69\u001b[0m                    layer_norm\u001b[39m=\u001b[39;49ms4_layernorm)\n\u001b[1;32m     71\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcond_conv \u001b[39m=\u001b[39m Conv(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39min_channels, \u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_channels, kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_conv \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv1d(res_channels, res_channels, kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/ecg/ecg_forecasting/SSSD_main/src/imputers/S4Model.py:1188\u001b[0m, in \u001b[0;36mS4Layer.__init__\u001b[0;34m(self, features, lmax, N, dropout, bidirectional, layer_norm)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, features, lmax, N\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, dropout\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, bidirectional\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, layer_norm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1187\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m-> 1188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms4_layer  \u001b[39m=\u001b[39m S4(d_model\u001b[39m=\u001b[39;49mfeatures, \n\u001b[1;32m   1189\u001b[0m                         d_state\u001b[39m=\u001b[39;49mN, \n\u001b[1;32m   1190\u001b[0m                         l_max\u001b[39m=\u001b[39;49mlmax, \n\u001b[1;32m   1191\u001b[0m                         bidirectional\u001b[39m=\u001b[39;49mbidirectional)\n\u001b[1;32m   1193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm_layer \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(features) \u001b[39mif\u001b[39;00m layer_norm \u001b[39melse\u001b[39;00m nn\u001b[39m.\u001b[39mIdentity() \n\u001b[1;32m   1194\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDropout2d(dropout) \u001b[39mif\u001b[39;00m dropout\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m nn\u001b[39m.\u001b[39mIdentity()\n",
      "File \u001b[0;32m~/ecg/ecg_forecasting/SSSD_main/src/imputers/S4Model.py:1075\u001b[0m, in \u001b[0;36mS4.__init__\u001b[0;34m(self, d_model, d_state, l_max, channels, bidirectional, activation, postact, initializer, weight_norm, hyper_act, dropout, transposed, verbose, **kernel_args)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     channels \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m   1074\u001b[0m \u001b[39m# SSM Kernel\u001b[39;00m\n\u001b[0;32m-> 1075\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m HippoSSKernel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mh, N\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn, L\u001b[39m=\u001b[39;49ml_max, channels\u001b[39m=\u001b[39;49mchannels, verbose\u001b[39m=\u001b[39;49mverbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkernel_args)\n\u001b[1;32m   1077\u001b[0m \u001b[39m# Pointwise\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation \u001b[39m=\u001b[39m Activation(activation)\n",
      "File \u001b[0;32m~/ecg/ecg_forecasting/SSSD_main/src/imputers/S4Model.py:977\u001b[0m, in \u001b[0;36mHippoSSKernel.__init__\u001b[0;34m(self, H, N, L, measure, rank, channels, dt_min, dt_max, trainable, lr, length_correction, hurwitz, tie_state, precision, resample, verbose)\u001b[0m\n\u001b[1;32m    975\u001b[0m w, p, B, _ \u001b[39m=\u001b[39m nplr(measure, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN, rank, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    976\u001b[0m C \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(channels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, dtype\u001b[39m=\u001b[39mcdtype)\n\u001b[0;32m--> 977\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m SSKernelNPLR(\n\u001b[1;32m    978\u001b[0m     L, w, p, B, C,\n\u001b[1;32m    979\u001b[0m     log_dt,\n\u001b[1;32m    980\u001b[0m     hurwitz\u001b[39m=\u001b[39;49mhurwitz,\n\u001b[1;32m    981\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    982\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    983\u001b[0m     tie_state\u001b[39m=\u001b[39;49mtie_state,\n\u001b[1;32m    984\u001b[0m     length_correction\u001b[39m=\u001b[39;49mlength_correction,\n\u001b[1;32m    985\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    986\u001b[0m )\n",
      "File \u001b[0;32m~/ecg/ecg_forecasting/SSSD_main/src/imputers/S4Model.py:602\u001b[0m, in \u001b[0;36mSSKernelNPLR.__init__\u001b[0;34m(self, L, w, P, B, C, log_dt, hurwitz, trainable, lr, tie_state, length_correction, verbose)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister(\u001b[39m\"\u001b[39m\u001b[39mQ\u001b[39m\u001b[39m\"\u001b[39m, _c2r(Q), trainable\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mP\u001b[39m\u001b[39m'\u001b[39m, train), lr, \u001b[39m0.0\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[39mif\u001b[39;00m length_correction:\n\u001b[0;32m--> 602\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_C()\n",
      "File \u001b[0;32m~/miniconda3/envs/SSSD/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/ecg/ecg_forecasting/SSSD_main/src/imputers/S4Model.py:499\u001b[0m, in \u001b[0;36mSSKernelNPLR._setup_C\u001b[0;34m(self, double_length)\u001b[0m\n\u001b[1;32m    497\u001b[0m C \u001b[39m=\u001b[39m _r2c(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC)\n\u001b[1;32m    498\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_state()\n\u001b[0;32m--> 499\u001b[0m dA_L \u001b[39m=\u001b[39m power(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mL, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdA)\n\u001b[1;32m    500\u001b[0m \u001b[39m# Multiply C by I - dA_L\u001b[39;00m\n\u001b[1;32m    501\u001b[0m C_ \u001b[39m=\u001b[39m _conj(C)\n",
      "File \u001b[0;32m~/ecg/ecg_forecasting/SSSD_main/src/imputers/S4Model.py:282\u001b[0m, in \u001b[0;36mpower\u001b[0;34m(L, A, v)\u001b[0m\n\u001b[1;32m    280\u001b[0m l \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    281\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     \u001b[39mif\u001b[39;00m L \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m: I \u001b[39m=\u001b[39m powers[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m] \u001b[39m@\u001b[39;49m I\n\u001b[1;32m    283\u001b[0m     L \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    284\u001b[0m     \u001b[39mif\u001b[39;00m L \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the configuration files\n",
    "config_SSSDS4_path = os.path.join(ProjectPath, 'SSSD_main', 'src','config','config_SSSDS4.json') \n",
    "config_SSSDSA_path = os.path.join(ProjectPath, 'SSSD_main', 'src','config','config_SSSDSA.json') \n",
    "\n",
    "with open(config_SSSDS4_path) as f:\n",
    "    config_SSSDS4 = json.load(f)\n",
    "\n",
    "with open(config_SSSDSA_path) as f:\n",
    "    config_SSSDSA = json.load(f)\n",
    "\n",
    "# Parse necessary configurations for SSSDS4\n",
    "gen_config_SSSDS4 = config_SSSDS4['gen_config']\n",
    "train_config_SSSDS4 = config_SSSDS4['train_config']\n",
    "trainset_config_SSSDS4 = config_SSSDS4['trainset_config']\n",
    "diffusion_config_SSSDS4 = config_SSSDS4['diffusion_config']\n",
    "wavenet_config_SSSDS4 = config_SSSDS4['wavenet_config']\n",
    "\n",
    "wavenet_config_SSSDS4[\"in_channels\"]=in_channels\n",
    "wavenet_config_SSSDS4[\"out_channels\"]=in_channels\n",
    "\n",
    "# # Parse necessary configurations for SSSDSA\n",
    "# gen_config_SSSDSA = config_SSSDSA['gen_config']\n",
    "# train_config_SSSDSA = config_SSSDSA['train_config']\n",
    "# trainset_config_SSSDSA = config_SSSDSA['trainset_config']\n",
    "# diffusion_config_SSSDSA = config_SSSDSA['diffusion_config']\n",
    "# sashimi_config_SSSDSA = config_SSSDSA['sashimi_config']\n",
    "\n",
    "# Load your custom datasets\n",
    "# train_dataset_SSSDS4 = dataset\n",
    "# train_loader_SSSDS4 = DataLoader(train_dataset_SSSDS4, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# train_dataset_SSSDSA = dataset\n",
    "# train_loader_SSSDSA = DataLoader(train_dataset_SSSDSA, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Initialize your models and optimizers based on the chosen 'use_model'\n",
    "net_SSSDS4 = SSSDS4Imputer(**wavenet_config_SSSDS4).cuda()\n",
    "optimizer_SSSDS4 = torch.optim.Adam(net_SSSDS4.parameters(), lr=train_config_SSSDS4['learning_rate'])\n",
    "\n",
    "# net_SSSDSA = SSSDSAImputer(**sashimi_config_SSSDSA).cuda()\n",
    "# optimizer_SSSDSA = torch.optim.Adam(net_SSSDSA.parameters(), lr=train_config_SSSDSA['learning_rate'])\n",
    "\n",
    "# # Load checkpoints if available for both models\n",
    "# ckpt_path_SSSDS4 = os.path.join(train_config_SSSDS4[\"output_directory\"], \"T{}_beta0{}_betaT{}\".format(\n",
    "#     diffusion_config_SSSDS4[\"T\"], diffusion_config_SSSDS4[\"beta_0\"], diffusion_config_SSSDS4[\"beta_T\"]))\n",
    "# ckpt_path_SSSDSA = train_config_SSSDSA[\"output_directory\"]\n",
    "\n",
    "# args = type('Arguments', (object,), {'ckpt_iter': 'max'})  # Mock argparse arguments\n",
    "# args.ckpt_iter = 'max'\n",
    "\n",
    "# model_path_SSSDS4 = os.path.join(ckpt_path_SSSDS4, '{}.pkl'.format(args.ckpt_iter))\n",
    "# model_path_SSSDSA = os.path.join(ckpt_path_SSSDSA, '{}.pkl'.format(args.ckpt_iter))\n",
    "\n",
    "# try:\n",
    "#     checkpoint_SSSDS4 = torch.load(model_path_SSSDS4, map_location='cpu')\n",
    "#     net_SSSDS4.load_state_dict(checkpoint_SSSDS4['model_state_dict'])\n",
    "#     optimizer_SSSDS4.load_state_dict(checkpoint_SSSDS4['optimizer_state_dict'])\n",
    "#     print('Successfully loaded SSSDS4 model at iteration {}'.format(args.ckpt_iter))\n",
    "# except:\n",
    "#     print('No valid SSSDS4 model found. Initializing from scratch.')\n",
    "# try:\n",
    "#     checkpoint_SSSDSA = torch.load(model_path_SSSDSA, map_location='cpu')\n",
    "#     net_SSSDSA.load_state_dict(checkpoint_SSSDSA['model_state_dict'])\n",
    "#     optimizer_SSSDSA.load_state_dict(checkpoint_SSSDSA['optimizer_state_dict'])\n",
    "#     print('Successfully loaded SSSDSA model at iteration {}'.format(args.ckpt_iter))\n",
    "# except:\n",
    "#     print('No valid SSSDSA model found. Initializing from scratch.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f48ddf579b006a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:28:44.078783200Z",
     "start_time": "2023-12-25T20:28:44.019745200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# working train, but it load all the data in one time and causing out of storage, (works for small samples or small number of samples)\n",
    "# def train(output_directory,\n",
    "#           ckpt_iter, \n",
    "#           n_iters, \n",
    "#           iters_per_ckpt,\n",
    "#           iters_per_logging,\n",
    "#           learning_rate,\n",
    "#           only_generate_missing,\n",
    "#           masking,\n",
    "#           missing_k,\n",
    "#           net,\n",
    "#           diffusion_config,\n",
    "#           diffusion_hyperparams,\n",
    "#           trainset_config,\n",
    "#           context_size,\n",
    "#           label_size,\n",
    "#           **kwargs):\n",
    "#     \"\"\"\n",
    "#     Train Diffusion Models\n",
    "\n",
    "#     This function trains diffusion models using the given parameters.\n",
    "\n",
    "#     Parameters:\n",
    "#     output_directory (str):         Path to save model checkpoints.\n",
    "#     ckpt_iter (int or 'max'):       The pretrained checkpoint to be loaded. \n",
    "#                                     If 'max' is selected, it automatically selects the maximum iteration.\n",
    "#     n_iters (int):                  Number of iterations to train.\n",
    "#     iters_per_ckpt (int):           Number of iterations to save checkpoint. \n",
    "#                                     Default is 10k, for models with residual_channel=64 this number can be larger.\n",
    "#     iters_per_logging (int):        Number of iterations to save training log and compute validation loss. Default is 100.\n",
    "#     learning_rate (float):          Learning rate.\n",
    "#     use_model (int):                Model selection:\n",
    "#                                     0: DiffWave.\n",
    "#                                     1: SSSDSA.\n",
    "#                                     2: SSSDS4.\n",
    "#     only_generate_missing (int):    0: Apply diffusion to all samples.\n",
    "#                                     1: Only apply diffusion to missing portions of the signal.\n",
    "#     masking (str):                  Masking strategy:\n",
    "#                                     'mnr': Missing not at random.\n",
    "#                                     'bm': Blackout missing.\n",
    "#                                     'rm': Random missing.\n",
    "#     missing_k (int):                Number of missing time steps for each feature across the sample length.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # generate experiment (local) path\n",
    "#     local_path = \"T{}_beta0{}_betaT{}\".format(diffusion_config[\"T\"],\n",
    "#                                               diffusion_config[\"beta_0\"],\n",
    "#                                               diffusion_config[\"beta_T\"])\n",
    "\n",
    "#     # Get shared output_directory ready\n",
    "#     output_directory = os.path.join(output_directory, local_path)\n",
    "#     if not os.path.isdir(output_directory):\n",
    "#         os.makedirs(output_directory)\n",
    "#         os.chmod(output_directory, 0o775)\n",
    "#     print(\"output directory\", output_directory, flush=True)\n",
    "\n",
    "#     # map diffusion hyperparameters to gpu\n",
    "#     for key in diffusion_hyperparams:\n",
    "#         if key != \"T\":\n",
    "#             diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "#     # predefine model\n",
    "#     net = net.cuda()\n",
    "\n",
    "#     # define optimizer\n",
    "#     optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "#     # load checkpoint\n",
    "#     if ckpt_iter == 'max':\n",
    "#         ckpt_iter = find_max_epoch(output_directory)\n",
    "#     if ckpt_iter >= 0:\n",
    "#         try:\n",
    "#             # load checkpoint file\n",
    "#             model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n",
    "#             checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "#             # feed model dict and optimizer state\n",
    "#             net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#             if 'optimizer_state_dict' in checkpoint:\n",
    "#                 optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "#             print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n",
    "#         except:\n",
    "#             ckpt_iter = -1\n",
    "#             print('No valid checkpoint model found, start training from initialization try.')\n",
    "#     else:\n",
    "#         ckpt_iter = -1\n",
    "#         print('No valid checkpoint model found, start training from initialization.')\n",
    "\n",
    "    \n",
    "#     def load_first_dataset(file_path):\n",
    "#         print(f\"{file_path=}\")\n",
    "#         \"\"\"Load data from the first dataset of an H5 file.\"\"\"\n",
    "#         with h5py.File(file_path, 'r') as h5_file:\n",
    "#             # Check if '/00000' dataset exists\n",
    "#             if '/00000' in h5_file:\n",
    "#                 first_dataset = h5_file['/00000'][()]\n",
    "#             else:\n",
    "#                 # If '/00000' does not exist, print the name of the first dataset\n",
    "#                 first_dataset_name = list(h5_file.keys())[0]\n",
    "#                 print(f\"The '/00000' dataset does not exist. The first dataset is: {first_dataset_name}\")\n",
    "#                 first_dataset = h5_file[first_dataset_name][()]\n",
    "#         return first_dataset\n",
    "    \n",
    "#     # Specify the path to the H5 file\n",
    "#     file_path = '/mnt/qnap/liranc6/data/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes_window.h5'\n",
    "#     # Load data from the first dataset\n",
    "#     first_dataset = load_first_dataset(file_path)\n",
    "    \n",
    "#     # Convert the NumPy array to a PyTorch tensor, make it a float tensor,\n",
    "#     # and move it to the GPU if available\n",
    "#     training_data = torch.from_numpy(first_dataset).float().cuda()\n",
    "#     # print(f'{training_data.shape=}')\n",
    "#     training_data = training_data[:200, :wavenet_config_SSSDS4[\"in_channels\"]] # [:x, :y] take only the first x patients and y time steps to save memory\n",
    "#     training_data.unsqueeze_(0) #split the data to batches of size 1\n",
    "#     training_data.unsqueeze_(-1) #add a channel dimension\n",
    "    \n",
    "#     training_data = training_data.permute(0, 1, 3, 2) # the code expects the data to be in the shape of (batch_size, sequence_length, channels)\n",
    "    \n",
    "#     print(f'{training_data.shape=}')\n",
    "    \n",
    "    \n",
    "#     # ### Custom data loading and reshaping ###\n",
    "#     # training_data = np.load(trainset_config['train_data_path'])\n",
    "#     # \n",
    "#     # training_data = np.split(training_data, 160, 0) # Split the array into 160 equal sub-arrays along the first axis\n",
    "#     #                                                 # If the array cannot be evenly divided into 160 sub-arrays, a ValueError will be raised.\n",
    "#     # \n",
    "#     # training_data = np.array(training_data) # Convert the list of NumPy arrays into a single multi-dim NumPy array\n",
    "#     # training_data = torch.from_numpy(training_data).float().cuda() # Convert the NumPy array to a PyTorch tensor, make it a float tensor, and move it to the GPU if available\n",
    "#     print('Data loaded')\n",
    "\n",
    "#     # training\n",
    "#     n_iter = ckpt_iter + 1\n",
    "#     n_iters = 50\n",
    "#     pbar_outer = tqdm(total=n_iters, initial=ckpt_iter, position=0, leave=True)\n",
    "#     while n_iter < n_iters + 1:\n",
    "#         pbar_inner = tqdm(enumerate(training_data), total=len(training_data), position=1, leave=True)\n",
    "#         for i, batch in pbar_inner:\n",
    "#             print(f\"{batch.size()=}\")\n",
    "#             # print(f\"{batch.size()=}\")\n",
    "#             if n_iter % 50 == 0:\n",
    "#                 print(f'{n_iter=}')\n",
    "#             # if i % 10 == 0:\n",
    "#             #     print(f'{i=}')\n",
    "\n",
    "#             # TODO: what is the porpuse and use of the masking in here?\n",
    "#             \"\"\"\n",
    "#             copilot answer:\n",
    "#             In this code, masking is used to selectively ignore or pay attention to certain elements of the data during the training process.\n",
    "#             The mask is a tensor of the same shape as the input data, where each element of the mask corresponds to an element of the input data. \n",
    "\n",
    "#             The type of mask applied depends on the `masking` variable, which can be 'rm', 'mnr', or 'bm'. Each of these values corresponds to a\n",
    "#             different masking strategy, implemented by the `get_mask_rm`, `get_mask_mnr`, and `get_mask_bm` functions respectively.\n",
    "\n",
    "#             Once the mask is created, it is permuted, repeated across the batch size, and converted to a float tensor on the GPU with `.float().cuda()`.\n",
    "#             The `loss_mask` is the logical negation of `mask`, converted to a boolean tensor with `.bool()`. \n",
    "#             This means that wherever `mask` is True, `loss_mask` is False, and vice versa.\n",
    "\n",
    "#             The `mask` and `loss_mask` are then used in the `training_loss` function. While the exact usage depends on the implementation of\n",
    "#             `training_loss`, typically, elements of the input data where `mask` is True are ignored or treated differently during the computation\n",
    "#             of the loss. Conversely, elements where `loss_mask` is True are used normally. This allows the model to focus on certain parts of the\n",
    "#             data while ignoring others, which can be useful in many machine learning tasks.\n",
    "#             \"\"\"\n",
    "#             transposed_mask = None\n",
    "#             print(f\"{masking=}, {batch[0].size()=}\")\n",
    "#             if masking == 'rm':\n",
    "#                 transposed_mask = get_mask_rm(batch[0], missing_k)\n",
    "#             elif masking == 'mnr':\n",
    "#                 transposed_mask = get_mask_mnr(batch[0], missing_k)\n",
    "#             elif masking == 'bm':\n",
    "#                 transposed_mask = get_mask_bm(batch[0], missing_k)\n",
    "#             elif masking == 'fm':\n",
    "#                 transposed_mask = get_mask_fm(batch[0], context_size, label_size)\n",
    "\n",
    "#             assert transposed_mask is not None, \"Masking strategy not found\"\n",
    "#             mask = transposed_mask.permute(1, 0)\n",
    "#             mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n",
    "#             loss_mask = ~mask.bool()\n",
    "#             batch = batch.permute(0, 2, 1)\n",
    "\n",
    "#             assert batch.size() == mask.size() == loss_mask.size(), f'{batch.size()=} {mask.size()=} {loss_mask.size()=}'\n",
    "            \n",
    "#             # print(f\"{batch.size()=} == {mask.size()=} == {loss_mask.size()=}\")\n",
    "#             # assert transposed_mask is not None, \"Masking strategy not found\"\n",
    "#             # mask = transposed_mask.permute(0, 2, 1)  # Changed this line\n",
    "#             # mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n",
    "#             # loss_mask = ~mask.bool()\n",
    "#             # batch = batch.permute(0, 2, 1)\n",
    "#             # \n",
    "#             # assert batch.size() == mask.size() == loss_mask.size(), f'{batch.size()=} {mask.size()=} {loss_mask.size()=}'\n",
    "\n",
    "#             # back-propagation\n",
    "#             optimizer.zero_grad()\n",
    "#             X = batch, batch, mask, loss_mask #audio = X[0], cond = X[1], mask = X[2], loss_mask = X[3]\n",
    "            \n",
    "#             loss = src_train.training_loss(net, nn.MSELoss(), X, diffusion_hyperparams,\n",
    "#                                  only_generate_missing=only_generate_missing)\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if n_iter % iters_per_logging == 0:\n",
    "#                 print(\"iteration: {} \\tloss: {}\".format(n_iter, loss.item()))\n",
    "\n",
    "#             # save checkpoint\n",
    "#             if n_iter > 0 and n_iter % iters_per_ckpt == 0:\n",
    "#                 checkpoint_name = '{}.pkl'.format(n_iter)\n",
    "#                 torch.save({'model_state_dict': net.state_dict(),\n",
    "#                             'optimizer_state_dict': optimizer.state_dict()},\n",
    "#                            os.path.join(output_directory, checkpoint_name))\n",
    "#                 print('model at iteration %s is saved' % n_iter)\n",
    "\n",
    "#             n_iter += 1\n",
    "#             # pbar_inner.set_description(f'Processing batch {i+1}')\n",
    "#             # pbar_inner.update()\n",
    "#         pbar_outer.update()\n",
    "#     pbar_outer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c94652695b25f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:28:44.725747500Z",
     "start_time": "2023-12-25T20:28:44.644148300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using dataset and dataloader, code with chatGPT\n",
    "\n",
    "# def train(output_directory,\n",
    "#           ckpt_iter,\n",
    "#           n_iters,\n",
    "#           iters_per_ckpt,\n",
    "#           iters_per_logging,\n",
    "#           learning_rate,\n",
    "#           only_generate_missing,\n",
    "#           masking,\n",
    "#           missing_k,\n",
    "#           net,\n",
    "#           diffusion_config,\n",
    "#           diffusion_hyperparams,\n",
    "#           trainset_config,\n",
    "#           context_size,\n",
    "#           label_size,\n",
    "#           **kwargs):\n",
    "#     # Generate experiment (local) path\n",
    "#     local_path = \"T{}_beta0{}_betaT{}\".format(diffusion_config[\"T\"],\n",
    "#                                               diffusion_config[\"beta_0\"],\n",
    "#                                               diffusion_config[\"beta_T\"])\n",
    "\n",
    "#     # Get shared output_directory ready\n",
    "#     output_directory = os.path.join(output_directory, local_path)\n",
    "#     if not os.path.isdir(output_directory):\n",
    "#         os.makedirs(output_directory)\n",
    "#         os.chmod(output_directory, 0o775)\n",
    "#     print(\"output directory\", output_directory, flush=True)\n",
    "\n",
    "#     # Map diffusion hyperparameters to GPU\n",
    "#     for key in diffusion_hyperparams:\n",
    "#         if key != \"T\":\n",
    "#             diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "#     # Predefine model\n",
    "#     net = net.cuda()\n",
    "\n",
    "#     # Define optimizer\n",
    "#     optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "#     # Load checkpoint\n",
    "#     if ckpt_iter == 'max':\n",
    "#         ckpt_iter = find_max_epoch(output_directory)\n",
    "#     if ckpt_iter >= 0:\n",
    "#         try:\n",
    "#             # Load checkpoint file\n",
    "#             model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n",
    "#             checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "#             # Feed model dict and optimizer state\n",
    "#             net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#             if 'optimizer_state_dict' in checkpoint:\n",
    "#                 optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "#             print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n",
    "#         except:\n",
    "#             ckpt_iter = -1\n",
    "#             print('No valid checkpoint model found, start training from initialization try.')\n",
    "#     else:\n",
    "#         ckpt_iter = -1\n",
    "#         print('No valid checkpoint model found, start training from initialization.')\n",
    "\n",
    "#     # Create an instance of your custom dataset\n",
    "#     h5_filename = '/mnt/qnap/liranc6/data/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes_window.h5'\n",
    "#     dataset = SingleLeadECGDatasetCrops(context_size, label_size, h5_filename)\n",
    "\n",
    "#     print(f\"{len(dataset)=}\")\n",
    "#     # Use DataLoader to handle batching and shuffling\n",
    "#     batch_size = 1  # Adjust the batch size as per your requirements\n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#     n_iter = ckpt_iter + 1\n",
    "#     pbar_outer = tqdm(total=n_iters, initial=ckpt_iter, position=0, leave=True)\n",
    "\n",
    "#     while n_iter < n_iters + 1:\n",
    "#         pbar_inner = tqdm(enumerate(dataloader), total=len(dataloader), position=1, leave=True)\n",
    "\n",
    "#         for i, batch in pbar_inner:\n",
    "#             x, y = batch\n",
    "#             x, y = x.cuda(), y.cuda()\n",
    "\n",
    "#             # Your existing code for masking and preprocessing goes here\n",
    "\n",
    "#             # Back-propagation\n",
    "#             optimizer.zero_grad()\n",
    "#             X = x, y, mask, loss_mask  # Assuming X[0] is input, X[1] is target, X[2] is mask, and X[3] is loss_mask\n",
    "\n",
    "#             loss = src_train.training_loss(net, nn.MSELoss(), X, diffusion_hyperparams,\n",
    "#                                            only_generate_missing=only_generate_missing)\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if n_iter % iters_per_logging == 0:\n",
    "#                 print(\"iteration: {} \\tloss: {}\".format(n_iter, loss.item()))\n",
    "\n",
    "#             # Save checkpoint\n",
    "#             if n_iter > 0 and n_iter % iters_per_ckpt == 0:\n",
    "#                 checkpoint_name = '{}.pkl'.format(n_iter)\n",
    "#                 torch.save({'model_state_dict': net.state_dict(),\n",
    "#                             'optimizer_state_dict': optimizer.state_dict()},\n",
    "#                            os.path.join(output_directory, checkpoint_name))\n",
    "#                 print('model at iteration %s is saved' % n_iter)\n",
    "\n",
    "#             n_iter += 1\n",
    "\n",
    "#         pbar_outer.update()\n",
    "\n",
    "#     pbar_outer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8af0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #working train, tries to use my castume dataset\n",
    "# #working for in_channels =65000 (which is a bit over 4.3 minuts in total, context+pred)\n",
    "# #I interapted bc it has 788 samples and I didnt want to wait, next task will be to check if I can run it fully to the end.\n",
    "# def train(output_directory,\n",
    "#           ckpt_iter, \n",
    "#           n_iters, \n",
    "#           iters_per_ckpt,\n",
    "#           iters_per_logging,\n",
    "#           learning_rate,\n",
    "#           only_generate_missing,\n",
    "#           masking,\n",
    "#           missing_k,\n",
    "#           net,\n",
    "#           diffusion_config,\n",
    "#           diffusion_hyperparams,\n",
    "#           trainset_config,\n",
    "#           context_size,\n",
    "#           label_size,\n",
    "#           **kwargs):\n",
    "#     \"\"\"\n",
    "#     Train Diffusion Models\n",
    "\n",
    "#     This function trains diffusion models using the given parameters.\n",
    "\n",
    "#     Parameters:\n",
    "#     output_directory (str):         Path to save model checkpoints.\n",
    "#     ckpt_iter (int or 'max'):       The pretrained checkpoint to be loaded. \n",
    "#                                     If 'max' is selected, it automatically selects the maximum iteration.\n",
    "#     n_iters (int):                  Number of iterations to train.\n",
    "#     iters_per_ckpt (int):           Number of iterations to save checkpoint. \n",
    "#                                     Default is 10k, for models with residual_channel=64 this number can be larger.\n",
    "#     iters_per_logging (int):        Number of iterations to save training log and compute validation loss. Default is 100.\n",
    "#     learning_rate (float):          Learning rate.\n",
    "#     use_model (int):                Model selection:\n",
    "#                                     0: DiffWave.\n",
    "#                                     1: SSSDSA.\n",
    "#                                     2: SSSDS4.\n",
    "#     only_generate_missing (int):    0: Apply diffusion to all samples.\n",
    "#                                     1: Only apply diffusion to missing portions of the signal.\n",
    "#     masking (str):                  Masking strategy:\n",
    "#                                     'mnr': Missing not at random.\n",
    "#                                     'bm': Blackout missing.\n",
    "#                                     'rm': Random missing.\n",
    "#     missing_k (int):                Number of missing time steps for each feature across the sample length.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # generate experiment (local) path\n",
    "#     local_path = \"T{}_beta0{}_betaT{}\".format(diffusion_config[\"T\"],\n",
    "#                                               diffusion_config[\"beta_0\"],\n",
    "#                                               diffusion_config[\"beta_T\"])\n",
    "\n",
    "#     # Get shared output_directory ready\n",
    "#     output_directory = os.path.join(output_directory, local_path)\n",
    "#     if not os.path.isdir(output_directory):\n",
    "#         os.makedirs(output_directory)\n",
    "#         os.chmod(output_directory, 0o775)\n",
    "#     print(\"output directory\", output_directory, flush=True)\n",
    "\n",
    "#     # map diffusion hyperparameters to gpu\n",
    "#     for key in diffusion_hyperparams:\n",
    "#         if key != \"T\":\n",
    "#             diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "#     # predefine model\n",
    "#     net = net.cuda()\n",
    "\n",
    "#     # define optimizer\n",
    "#     optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "#     # load checkpoint\n",
    "#     if ckpt_iter == 'max':\n",
    "#         ckpt_iter = find_max_epoch(output_directory)\n",
    "#     if ckpt_iter >= 0:\n",
    "#         try:\n",
    "#             # load checkpoint file\n",
    "#             model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n",
    "#             checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "#             # feed model dict and optimizer state\n",
    "#             net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#             if 'optimizer_state_dict' in checkpoint:\n",
    "#                 optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "#             print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n",
    "#         except:\n",
    "#             ckpt_iter = -1\n",
    "#             print('No valid checkpoint model found, start training from initialization try.')\n",
    "#     else:\n",
    "#         ckpt_iter = -1\n",
    "#         print('No valid checkpoint model found, start training from initialization.')\n",
    "    \n",
    "#     # Specify the path to the H5 file\n",
    "#     file_path = '/mnt/qnap/liranc6/data/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes_window.h5'\n",
    "#     # Load data from the first dataset\n",
    "#     dataset = SingleLeadECGDatasetCrops(context_size, label_size, file_path)\n",
    "#     # Use DataLoader to handle batching and shuffling\n",
    "#     batch_size = 3  \n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "#     # # Convert the NumPy array to a PyTorch tensor, make it a float tensor,\n",
    "#     # # and move it to the GPU if available\n",
    "#     # training_data = torch.from_numpy(first_dataset).float().cuda()\n",
    "#     # # print(f'{training_data.shape=}')\n",
    "#     # training_data = training_data[:200, :wavenet_config_SSSDS4[\"in_channels\"]] # [:x, :y] take only the first x patients and y time steps to save memory\n",
    "#     # training_data.unsqueeze_(0) #split the data to batches of size 1\n",
    "#     # training_data.unsqueeze_(-1) #add a channel dimension\n",
    "    \n",
    "#     # training_data = training_data.permute(0, 1, 3, 2) # the code expects the data to be in the shape of (batch_size, sequence_length, channels)\n",
    "    \n",
    "#     # print(f'{training_data.shape=}')\n",
    "    \n",
    "\n",
    "#     # training\n",
    "#     n_iter = ckpt_iter + 1\n",
    "#     n_iters = 100\n",
    "#     pbar_outer = tqdm(total=n_iters, initial=ckpt_iter, position=0, leave=True)\n",
    "#     # with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "#     while n_iter < n_iters + 1:\n",
    "#         pbar_inner = tqdm(enumerate(dataloader), total=len(dataloader), position=1, leave=True)\n",
    "#         for i, batch in pbar_inner:\n",
    "\n",
    "#             # Concatenate tensors along the last dimension\n",
    "#             concatenated_batch = torch.cat(batch, dim=-1)\n",
    "\n",
    "#             # Reshape to the desired shape\n",
    "#             batch = concatenated_batch.unsqueeze(0)[:, :, 0-in_channels:].float().to(device)\n",
    "\n",
    "#             # print(f\"{batch=}\\n\"\n",
    "#             #     f\"{len(batch)=}\\n\"\n",
    "#             #     f\"{batch.size()=}\")\n",
    "\n",
    "\n",
    "#             # if n_iter % 50 == 0:\n",
    "#             #     print(f'{n_iter=}')\n",
    "#             # if i % 10 == 0:\n",
    "#             #     print(f'{i=}')\n",
    "\n",
    "#             # TODO: what is the porpuse and use of the masking in here?\n",
    "#             \"\"\"\n",
    "#             copilot answer:\n",
    "#             In this code, masking is used to selectively ignore or pay attention to certain elements of the data during the training process.\n",
    "#             The mask is a tensor of the same shape as the input data, where each element of the mask corresponds to an element of the input data. \n",
    "\n",
    "#             The type of mask applied depends on the `masking` variable, which can be 'rm', 'mnr', or 'bm'. Each of these values corresponds to a\n",
    "#             different masking strategy, implemented by the `get_mask_rm`, `get_mask_mnr`, and `get_mask_bm` functions respectively.\n",
    "\n",
    "#             Once the mask is created, it is permuted, repeated across the batch size, and converted to a float tensor on the GPU with `.float().cuda()`.\n",
    "#             The `loss_mask` is the logical negation of `mask`, converted to a boolean tensor with `.bool()`. \n",
    "#             This means that wherever `mask` is True, `loss_mask` is False, and vice versa.\n",
    "\n",
    "#             The `mask` and `loss_mask` are then used in the `training_loss` function. While the exact usage depends on the implementation of\n",
    "#             `training_loss`, typically, elements of the input data where `mask` is True are ignored or treated differently during the computation\n",
    "#             of the loss. Conversely, elements where `loss_mask` is True are used normally. This allows the model to focus on certain parts of the\n",
    "#             data while ignoring others, which can be useful in many machine learning tasks.\n",
    "#             \"\"\"\n",
    "#             transposed_mask = None\n",
    "#             if masking == 'rm':\n",
    "#                 transposed_mask = get_mask_rm(batch[0], missing_k) # batch[0] is the first sample\n",
    "#             elif masking == 'mnr':\n",
    "#                 transposed_mask = get_mask_mnr(batch[0], missing_k)\n",
    "#             elif masking == 'bm':\n",
    "#                 transposed_mask = get_mask_bm(batch[0], missing_k)\n",
    "#             elif masking == 'fm':\n",
    "#                 transposed_mask = get_mask_fm(batch[0], context_size, label_size)\n",
    "\n",
    "#             assert transposed_mask is not None, \"Masking strategy not found\"\n",
    "#             mask = transposed_mask.permute(1, 0)\n",
    "#             mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n",
    "#             loss_mask = ~mask.bool()\n",
    "#             batch = batch.permute(0, 2, 1)\n",
    "\n",
    "#             assert batch.size() == mask.size() == loss_mask.size(), f'{batch.size()=} {mask.size()=} {loss_mask.size()=}'\n",
    "            \n",
    "#             # print(f\"{batch.size()=} == {mask.size()=} == {loss_mask.size()=}\")\n",
    "#             # assert transposed_mask is not None, \"Masking strategy not found\"\n",
    "#             # mask = transposed_mask.permute(0, 2, 1)  # Changed this line\n",
    "#             # mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n",
    "#             # loss_mask = ~mask.bool()\n",
    "#             # batch = batch.permute(0, 2, 1)\n",
    "#             # \n",
    "#             # assert batch.size() == mask.size() == loss_mask.size(), f'{batch.size()=} {mask.size()=} {loss_mask.size()=}'\n",
    "\n",
    "#             # back-propagation\n",
    "#             optimizer.zero_grad()\n",
    "#             X = batch, batch, mask, loss_mask #audio = X[0], cond = X[1], mask = X[2], loss_mask = X[3]\n",
    "            \n",
    "#             loss = src_train.training_loss(net, nn.MSELoss(), X, diffusion_hyperparams,\n",
    "#                                 only_generate_missing=only_generate_missing)\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if n_iter % iters_per_logging == 0:\n",
    "#                 print(\"iteration: {} \\tloss: {}\".format(n_iter, loss.item()))\n",
    "\n",
    "#             # save checkpoint\n",
    "#             if n_iter > 0 and n_iter % iters_per_ckpt == 0:\n",
    "#                 checkpoint_name = '{}.pkl'.format(n_iter)\n",
    "#                 torch.save({'model_state_dict': net.state_dict(),\n",
    "#                             'optimizer_state_dict': optimizer.state_dict()},\n",
    "#                         os.path.join(output_directory, checkpoint_name))\n",
    "#                 print('model at iteration %s is saved' % n_iter)\n",
    "\n",
    "#             n_iter += 1\n",
    "#             pbar_inner.set_description(f'Processing batch {i+1}')\n",
    "#             pbar_inner.update()\n",
    "#         pbar_outer.update()\n",
    "#     pbar_outer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working train, tries to use my castume dataset\n",
    "#working for in_channels =65000 (which is a bit over 4.3 minuts in total, context+pred)\n",
    "#I interapted bc it has 788 samples and I didnt want to wait, next task will be to check if I can run it fully to the end.\n",
    "def train_new(output_directory,\n",
    "          ckpt_iter, \n",
    "          n_iters, \n",
    "          iters_per_ckpt,\n",
    "          iters_per_logging,\n",
    "          learning_rate,\n",
    "          only_generate_missing,\n",
    "          masking,\n",
    "          missing_k,\n",
    "          net,\n",
    "          diffusion_config,\n",
    "          diffusion_hyperparams,\n",
    "          trainset_config,\n",
    "          context_size,\n",
    "          label_size,\n",
    "          **kwargs):\n",
    "    \"\"\"\n",
    "    Train Diffusion Models\n",
    "\n",
    "    This function trains diffusion models using the given parameters.\n",
    "\n",
    "    Parameters:\n",
    "    output_directory (str):         Path to save model checkpoints.\n",
    "    ckpt_iter (int or 'max'):       The pretrained checkpoint to be loaded. \n",
    "                                    If 'max' is selected, it automatically selects the maximum iteration.\n",
    "    n_iters (int):                  Number of iterations to train.\n",
    "    iters_per_ckpt (int):           Number of iterations to save checkpoint. \n",
    "                                    Default is 10k, for models with residual_channel=64 this number can be larger.\n",
    "    iters_per_logging (int):        Number of iterations to save training log and compute validation loss. Default is 100.\n",
    "    learning_rate (float):          Learning rate.\n",
    "    use_model (int):                Model selection:\n",
    "                                    0: DiffWave.\n",
    "                                    1: SSSDSA.\n",
    "                                    2: SSSDS4.\n",
    "    only_generate_missing (int):    0: Apply diffusion to all samples.\n",
    "                                    1: Only apply diffusion to missing portions of the signal.\n",
    "    masking (str):                  Masking strategy:\n",
    "                                    'mnr': Missing not at random.\n",
    "                                    'bm': Blackout missing.\n",
    "                                    'rm': Random missing.\n",
    "    missing_k (int):                Number of missing time steps for each feature across the sample length.\n",
    "    \"\"\"\n",
    "\n",
    "    # generate experiment (local) path\n",
    "    local_path = \"T{}_beta0{}_betaT{}\".format(diffusion_config[\"T\"],\n",
    "                                              diffusion_config[\"beta_0\"],\n",
    "                                              diffusion_config[\"beta_T\"])\n",
    "\n",
    "    # Get shared output_directory ready\n",
    "    output_directory = os.path.join(output_directory, local_path)\n",
    "    if not os.path.isdir(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "        os.chmod(output_directory, 0o775)\n",
    "    print(\"output directory\", output_directory, flush=True)\n",
    "\n",
    "    # map diffusion hyperparameters to gpu\n",
    "    for key in diffusion_hyperparams:\n",
    "        if key != \"T\":\n",
    "            diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "    # predefine model\n",
    "    net = net.cuda()\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # load checkpoint\n",
    "    if ckpt_iter == 'max':\n",
    "        ckpt_iter = find_max_epoch(output_directory)\n",
    "    if ckpt_iter >= 0:\n",
    "        try:\n",
    "            # load checkpoint file\n",
    "            model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n",
    "            checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "            # feed model dict and optimizer state\n",
    "            net.load_state_dict(checkpoint['model_state_dict'])\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "            print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n",
    "        except:\n",
    "            ckpt_iter = -1\n",
    "            print('No valid checkpoint model found, start training from initialization try.')\n",
    "    else:\n",
    "        ckpt_iter = -1\n",
    "        print('No valid checkpoint model found, start training from initialization.')\n",
    "\n",
    "\n",
    "    # Specify the path to the H5 file\n",
    "    file_path = \"/mnt/qnap/liranc6/data/icentia11k-continuous-ecg_new_subsets/icentia11k-continuous-ecg_normal_sinus_subset_npArrays_splits/10minutes_window.h5\"\n",
    "    # Load data from the first dataset\n",
    "    dataset = SingleLeadECGDatasetCrops(context_size, label_size, file_path)\n",
    "    # Use DataLoader to handle batching and shuffling\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # # Convert the NumPy array to a PyTorch tensor, make it a float tensor,\n",
    "    # # and move it to the GPU if available\n",
    "    # training_data = torch.from_numpy(first_dataset).float().cuda()\n",
    "    # # print(f'{training_data.shape=}')\n",
    "    # training_data = training_data[:200, :wavenet_config_SSSDS4[\"in_channels\"]] # [:x, :y] take only the first x patients and y time steps to save memory\n",
    "    # training_data.unsqueeze_(0) #split the data to batches of size 1\n",
    "    # training_data.unsqueeze_(-1) #add a channel dimension\n",
    "    \n",
    "    # training_data = training_data.permute(0, 1, 3, 2) # the code expects the data to be in the shape of (batch_size, sequence_length, channels)\n",
    "    \n",
    "    # print(f'{training_data.shape=}')\n",
    "    \n",
    "\n",
    "    # training\n",
    "    n_iter = ckpt_iter + 1\n",
    "    pbar_outer = tqdm(total=n_iters, initial=ckpt_iter, position=0, leave=True)\n",
    "    while n_iter < n_iters + 1:\n",
    "        if n_iter % 50 == 0:\n",
    "            tqdm.write(f'n_iter: {n_iter}')\n",
    "        pbar_inner = tqdm(dataloader, total=len(dataloader), position=1, leave=True)\n",
    "        for batch in pbar_inner:\n",
    "\n",
    "            # Concatenate tensors along the last dimension\n",
    "            concatenated_batch = torch.cat(batch, dim=-1)\n",
    "\n",
    "            # Reshape to the desired shape\n",
    "            batch = concatenated_batch.unsqueeze(0)[:, :, :in_channels].float().to(device)\n",
    "\n",
    "            # print(f\"{batch=}\\n\"\n",
    "            #     f\"{len(batch)=}\\n\"\n",
    "            #     f\"{batch.size()=}\")\n",
    "\n",
    "            # if i % 10 == 0:\n",
    "            #     print(f'{i=}')\n",
    "\n",
    "            # TODO: what is the porpuse and use of the masking in here?\n",
    "            \"\"\"\n",
    "            copilot answer:\n",
    "            In this code, masking is used to selectively ignore or pay attention to certain elements of the data during the training process.\n",
    "            The mask is a tensor of the same shape as the input data, where each element of the mask corresponds to an element of the input data. \n",
    "\n",
    "            The type of mask applied depends on the `masking` variable, which can be 'rm', 'mnr', or 'bm'. Each of these values corresponds to a\n",
    "            different masking strategy, implemented by the `get_mask_rm`, `get_mask_mnr`, and `get_mask_bm` functions respectively.\n",
    "\n",
    "            Once the mask is created, it is permuted, repeated across the batch size, and converted to a float tensor on the GPU with `.float().cuda()`.\n",
    "            The `loss_mask` is the logical negation of `mask`, converted to a boolean tensor with `.bool()`. \n",
    "            This means that wherever `mask` is True, `loss_mask` is False, and vice versa.\n",
    "\n",
    "            The `mask` and `loss_mask` are then used in the `training_loss` function. While the exact usage depends on the implementation of\n",
    "            `training_loss`, typically, elements of the input data where `mask` is True are ignored or treated differently during the computation\n",
    "            of the loss. Conversely, elements where `loss_mask` is True are used normally. This allows the model to focus on certain parts of the\n",
    "            data while ignoring others, which can be useful in many machine learning tasks.\n",
    "            \"\"\"\n",
    "\n",
    "            transposed_mask = None\n",
    "            if masking == 'rm':\n",
    "                transposed_mask = get_mask_rm(batch[0], missing_k) # batch[0] is the first sample\n",
    "            elif masking == 'mnr':\n",
    "                transposed_mask = get_mask_mnr(batch[0], missing_k)\n",
    "            elif masking == 'bm':\n",
    "                transposed_mask = get_mask_bm(batch[0], missing_k)\n",
    "            elif masking == 'pred':\n",
    "                transposed_mask = get_mask_pred(batch[0], context_size, label_size)\n",
    "\n",
    "            assert transposed_mask is not None, \"Masking strategy not found\"\n",
    "            mask = transposed_mask.permute(1, 0)\n",
    "            mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n",
    "            loss_mask = ~mask.bool()\n",
    "            batch = batch.permute(0, 2, 1)\n",
    "\n",
    "            assert batch.size() == mask.size() == loss_mask.size(), f'{batch.size()=} {mask.size()=} {loss_mask.size()=}'\n",
    "            \n",
    "            # tqdm.write(f\"{batch.size()=} == {mask.size()=} == {loss_mask.size()=}\")\n",
    "            # assert transposed_mask is not None, \"Masking strategy not found\"\n",
    "            # mask = transposed_mask.permute(0, 2, 1)  # Changed this line\n",
    "            # mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n",
    "            # loss_mask = ~mask.bool()\n",
    "            # batch = batch.permute(0, 2, 1)\n",
    "            # \n",
    "            # assert batch.size() == mask.size() == loss_mask.size(), f'{batch.size()=} {mask.size()=} {loss_mask.size()=}'\n",
    "\n",
    "            # back-propagation\n",
    "            optimizer.zero_grad()\n",
    "            X = batch, batch, mask, loss_mask #audio = X[0], cond = X[1], mask = X[2], loss_mask = X[3]\n",
    "            \n",
    "            loss = src_train.training_loss(net, nn.MSELoss(), X, diffusion_hyperparams,\n",
    "                                only_generate_missing=only_generate_missing)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            # pbar_inner.set_description(f'Processing batch {i+1}')\n",
    "            pbar_inner.set_postfix({\"loss\": loss.item()})\n",
    "            pbar_inner.update()\n",
    "        \n",
    "\n",
    "        final_wavenet_config = {\n",
    "        \"in_channels\": net.wavenet.in_channels,\n",
    "        \"out_channels\": net.wavenet.out_channels,\n",
    "        \"num_res_layers\": net.wavenet.num_res_layers,\n",
    "        \"res_channels\": net.wavenet.res_channels,\n",
    "        \"skip_channels\": net.wavenet.skip_channels,\n",
    "        \"diffusion_step_embed_dim_in\": net.wavenet.diffusion_step_embed_dim_in,\n",
    "        \"diffusion_step_embed_dim_mid\": net.wavenet.diffusion_step_embed_dim_mid,\n",
    "        \"diffusion_step_embed_dim_out\": net.wavenet.diffusion_step_embed_dim_out,\n",
    "        \"s4_lmax\": net.residual_layer.residual_blocks[35].S42.s4_layer.kernel.kernel.z.shape[0],  # Adjust as needed\n",
    "        \"s4_d_state\": net.residual_layer.residual_blocks[35].S42.s4_layer.kernel.kernel.z.shape[1],  # Adjust as needed\n",
    "        \"s4_dropout\": net.residual_layer.residual_blocks[35].S42.s4_layer.kernel.kernel.dropout,  # Adjust as needed\n",
    "        \"s4_bidirectional\": net.residual_layer.residual_blocks[35].S42.s4_layer.kernel.kernel.bidirectional,  # Adjust as needed\n",
    "        \"s4_layernorm\": net.residual_layer.residual_blocks[35].S42.s4_layer.kernel.kernel.layernorm,  # Adjust as needed\n",
    "        }\n",
    "\n",
    "        # Print or save the final_wavenet_config\n",
    "        print(\"Final WaveNet Config:\")\n",
    "        print(final_wavenet_config)\n",
    "\n",
    "        # save checkpoint\n",
    "        if n_iter > 0 and n_iter % iters_per_ckpt == 0:\n",
    "            checkpoint_name = '{}.pkl'.format(n_iter)\n",
    "            torch.save({'model_state_dict': net.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict()},\n",
    "                    os.path.join(output_directory, checkpoint_name))\n",
    "            tqdm.write(f'model at iteration {n_iter} is saved')\n",
    "\n",
    "        if n_iter % iters_per_logging == 0:\n",
    "                tqdm.write(f'iteration: {n_iter} \\tloss: {loss.item()}')\n",
    "        n_iter += 1\n",
    "        pbar_outer.update()\n",
    "    pbar_outer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f443654cd37673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T20:29:04.639885300Z",
     "start_time": "2023-12-25T20:28:45.049652200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output directory ./results/mujoco/90/T200_beta00.0001_betaT0.02\n",
      "No valid checkpoint model found, start training from initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liranc6/miniconda3/envs/SSSD/lib/python3.9/site-packages/tqdm/std.py:636: TqdmWarning: clamping frac to range [0, 1]\n",
      "  full_bar = Bar(frac,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9259b926b9384391a7b5ac23ab911606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-50%|          | -1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3cbae83931e42818169a0d342ca39d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/339 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.65 GiB memory in use. Of the allocated memory 22.07 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mglobal\u001b[39;00m diffusion_hyperparams\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m diffusion_hyperparams \u001b[39m=\u001b[39m calc_diffusion_hyperparams(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdiffusion_config_SSSDS4)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m train_new(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     output_directory\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m\"\u001b[39;49m\u001b[39moutput_directory\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     ckpt_iter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     n_iters\u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m, \u001b[39m# train_config_SSSDS4['n_iters'],\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     iters_per_ckpt\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39miters_per_ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     iters_per_logging\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39miters_per_logging\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     only_generate_missing\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39monly_generate_missing\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     masking\u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mpred\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m#train_config_SSSDS4['masking'],\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     missing_k\u001b[39m=\u001b[39;49mtrain_config_SSSDS4[\u001b[39m'\u001b[39;49m\u001b[39mmissing_k\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     net\u001b[39m=\u001b[39;49mnet_SSSDS4,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     diffusion_config\u001b[39m=\u001b[39;49mdiffusion_config_SSSDS4,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     diffusion_hyperparams \u001b[39m=\u001b[39;49m calc_diffusion_hyperparams(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdiffusion_config_SSSDS4),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     trainset_config \u001b[39m=\u001b[39;49m trainset_config_SSSDS4,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     context_size\u001b[39m=\u001b[39;49mcontext_window_size,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     label_size\u001b[39m=\u001b[39;49mlabel_window_size\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     )\n",
      "\u001b[1;32m/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=184'>185</a>\u001b[0m loss \u001b[39m=\u001b[39m src_train\u001b[39m.\u001b[39mtraining_loss(net, nn\u001b[39m.\u001b[39mMSELoss(), X, diffusion_hyperparams,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=185'>186</a>\u001b[0m                     only_generate_missing\u001b[39m=\u001b[39monly_generate_missing)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=187'>188</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=188'>189</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=190'>191</a>\u001b[0m \u001b[39m# save checkpoint\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Brambo6/home/liranc6/ecg/ecg_forecasting/liran_project/notebooks/train.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=191'>192</a>\u001b[0m \u001b[39mif\u001b[39;00m n_iter \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m n_iter \u001b[39m%\u001b[39m iters_per_ckpt \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/SSSD/lib/python3.9/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    386\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SSSD/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/SSSD/lib/python3.9/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    154\u001b[0m     state_steps \u001b[39m=\u001b[39m []\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 157\u001b[0m     has_complex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[1;32m    160\u001b[0m         grads,\n\u001b[1;32m    161\u001b[0m         exp_avgs,\n\u001b[1;32m    162\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[1;32m    166\u001b[0m     adam(\n\u001b[1;32m    167\u001b[0m         params_with_grad,\n\u001b[1;32m    168\u001b[0m         grads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m         found_inf\u001b[39m=\u001b[39m\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfound_inf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/SSSD/lib/python3.9/site-packages/torch/optim/adam.py:111\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[0;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    105\u001b[0m state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[1;32m    106\u001b[0m     torch\u001b[39m.\u001b[39mzeros((), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, device\u001b[39m=\u001b[39mp\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m group[\u001b[39m'\u001b[39m\u001b[39mcapturable\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mor\u001b[39;00m group[\u001b[39m'\u001b[39m\u001b[39mfused\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    108\u001b[0m     \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(\u001b[39m0.0\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    110\u001b[0m \u001b[39m# Exponential moving average of gradient values\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m state[\u001b[39m'\u001b[39m\u001b[39mexp_avg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros_like(p, memory_format\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mpreserve_format)\n\u001b[1;32m    112\u001b[0m \u001b[39m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[1;32m    113\u001b[0m state[\u001b[39m'\u001b[39m\u001b[39mexp_avg_sq\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(p, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpreserve_format)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 40.06 MiB is free. Including non-PyTorch memory, this process has 23.65 GiB memory in use. Of the allocated memory 22.07 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "global diffusion_hyperparams\n",
    "diffusion_hyperparams = calc_diffusion_hyperparams(**diffusion_config_SSSDS4)\n",
    "\n",
    "train_new(\n",
    "    output_directory=\"/home/liranc6/ecg/ecg_forecasting/liran_project/results/icentia11k/SSSDS4_copy\", #train_config_SSSDS4[\"output_directory\"],\n",
    "    ckpt_iter=\"-1\",\n",
    "    n_iters= 2, # train_config_SSSDS4['n_iters'],\n",
    "    iters_per_ckpt=train_config_SSSDS4['iters_per_ckpt'],\n",
    "    iters_per_logging=train_config_SSSDS4['iters_per_logging'],\n",
    "    learning_rate=train_config_SSSDS4['learning_rate'],\n",
    "    only_generate_missing=train_config_SSSDS4['only_generate_missing'],\n",
    "    masking= 'pred', #train_config_SSSDS4['masking'],\n",
    "    missing_k=train_config_SSSDS4['missing_k'],\n",
    "    net=net_SSSDS4,\n",
    "    diffusion_config=diffusion_config_SSSDS4,\n",
    "    diffusion_hyperparams = calc_diffusion_hyperparams(**diffusion_config_SSSDS4),\n",
    "    trainset_config = trainset_config_SSSDS4,\n",
    "    context_size=context_window_size,\n",
    "    label_size=label_window_size\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f6569d653e280",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-25T20:15:36.528554100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train(train_loader_SSSDS4, net_SSSDS4, optimizer_SSSDS4, calc_diffusion_hyperparams(**diffusion_config_SSSDS4),\n",
    "#       train_config_SSSDS4, iters_per_logging=train_config_SSSDS4['iters_per_logging'],\n",
    "#       iters_per_ckpt=train_config_SSSDS4['iters_per_ckpt'],\n",
    "#       output_directory=train_config_SSSDS4[\"output_directory\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e9bd9dc963ac1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-25T20:15:36.530544300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Test the train function for SSSDSA\n",
    "# train(train_loader_SSSDSA, net_SSSDSA, optimizer_SSSDSA, calc_diffusion_hyperparams(**diffusion_config_SSSDSA),\n",
    "#       train_config_SSSDSA, iters_per_logging=trainset_config_SSSDSA['iters_per_logging'],\n",
    "#       iters_per_ckpt=trainset_config_SSSDSA['iters_per_ckpt'],\n",
    "#       output_directory=trainset_config_SSSDSA[\"output_directory\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2862732f813c6d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-25T20:15:36.571995200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158874be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
